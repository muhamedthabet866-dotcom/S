import streamlit as st
import pandas as pd
import numpy as np
import re
import base64
from datetime import datetime
import io

# ุฅุนุฏุงุฏ ุตูุญุฉ Streamlit
st.set_page_config(
    page_title="Universal SPSS Code Generator",
    page_icon="๐",
    layout="wide"
)

st.title("๐ ูููุฏ ุฃููุงุฏ SPSS ุงูุดุงูู")
st.markdown("### ุจุฑูุงูุฌ ุฐูู ูุชูููุฏ ุฃููุงุฏ SPSS ูุฃู ุงูุชุญุงู ุฅุญุตุงุฆู")

class UniversalSPSSGenerator:
    def __init__(self):
        self.analysis_templates = self._load_analysis_templates()
        self.variable_mapping = {}
    
    def _load_analysis_templates(self):
        """ุชุญููู ููุงูุจ ุงูุชุญููู ุงููุฎุชููุฉ"""
        return {
            'descriptive': {
                'title': 'ุงูุฅุญุตุงุกุงุช ุงููุตููุฉ',
                'syntax': 'DESCRIPTIVES VARIABLES={vars}\n  /STATISTICS=MEAN STDDEV MIN MAX.',
                'keywords': ['mean', 'average', 'median', 'mode', 'standard deviation', 'variance']
            },
            'frequency': {
                'title': 'ุงูุฌุฏุงูู ุงูุชูุฑุงุฑูุฉ',
                'syntax': 'FREQUENCIES VARIABLES={vars}\n  /ORDER=ANALYSIS\n  /BARCHART.',
                'keywords': ['frequency', 'frequency table', 'distribution', 'count']
            },
            't_test': {
                'title': 'ุงุฎุชุจุงุฑ T',
                'syntax': 'T-TEST GROUPS={group_var}\n  /VARIABLES={test_vars}\n  /CRITERIA=CI(.95).',
                'keywords': ['t-test', 'compare means', 'independent samples', 'paired']
            },
            'anova': {
                'title': 'ุชุญููู ุงูุชุจุงูู (ANOVA)',
                'syntax': 'ONEWAY {dv} BY {iv}\n  /STATISTICS DESCRIPTIVES\n  /MISSING ANALYSIS.',
                'keywords': ['anova', 'analysis of variance', 'f-test', 'one-way']
            },
            'correlation': {
                'title': 'ุงูุงุฑุชุจุงุท',
                'syntax': 'CORRELATIONS\n  /VARIABLES={vars}\n  /PRINT=TWOTAIL NOSIG.',
                'keywords': ['correlation', 'relationship', 'association', 'correlate']
            },
            'regression': {
                'title': 'ุงูุงูุญุฏุงุฑ',
                'syntax': 'REGRESSION\n  /DEPENDENT {dv}\n  /METHOD=ENTER {iv_list}.',
                'keywords': ['regression', 'predict', 'linear model', 'multiple regression']
            },
            'chi_square': {
                'title': 'ุงุฎุชุจุงุฑ ูุฑุจุน ูุงู',
                'syntax': 'CROSSTABS\n  /TABLES={var1} BY {var2}\n  /STATISTICS=CHISQ.',
                'keywords': ['chi-square', 'chi squared', 'contingency', 'association']
            },
            'graph': {
                'title': 'ุงูุฑุณูู ุงูุจูุงููุฉ',
                'syntax': 'GRAPH /{type}={vars}\n  /TITLE="{title}".',
                'keywords': ['graph', 'chart', 'histogram', 'bar chart', 'pie chart', 'scatter']
            },
            'confidence': {
                'title': 'ูุชุฑุงุช ุงูุซูุฉ',
                'syntax': 'EXAMINE VARIABLES={var}\n  /CINTERVAL {level}\n  /PLOT NONE.',
                'keywords': ['confidence interval', 'ci', '95%', '99%', 'interval estimate']
            },
            'normality': {
                'title': 'ุงุฎุชุจุงุฑุงุช ุงูุทุจูุนูุฉ',
                'syntax': 'EXAMINE VARIABLES={var}\n  /PLOT NPPLOT\n  /STATISTICS NONE.',
                'keywords': ['normality', 'normal distribution', 'shapiro-wilk', 'kolmogorov']
            }
        }
    
    def analyze_data_structure(self, df):
        """ุชุญููู ูููู ุงูุจูุงูุงุช ูุชุญุฏูุฏ ุฃููุงุน ุงููุชุบูุฑุงุช"""
        variable_info = {}
        
        for column in df.columns:
            col_data = df[column]
            
            # ุชุญุฏูุฏ ููุน ุงููุชุบูุฑ
            try:
                numeric_check = pd.to_numeric(col_data.dropna())
                unique_count = col_data.nunique()
                
                if unique_count <= 10:
                    # ุฅุฐุง ูุงู ุนุฏุฏ ุงูููู ุงููุฑูุฏุฉ ููููุ ูุฏ ูููู ูุฆูู
                    variable_info[column] = {
                        'type': 'categorical',
                        'unique_values': unique_count,
                        'missing': col_data.isna().sum(),
                        'sample_values': list(col_data.dropna().unique())[:5]
                    }
                else:
                    # ูุชุบูุฑ ููู
                    variable_info[column] = {
                        'type': 'numeric',
                        'min': float(numeric_check.min()),
                        'max': float(numeric_check.max()),
                        'mean': float(numeric_check.mean()),
                        'missing': col_data.isna().sum()
                    }
            except:
                # ูุชุบูุฑ ูุตู
                variable_info[column] = {
                    'type': 'text',
                    'unique_values': col_data.nunique(),
                    'missing': col_data.isna().sum(),
                    'sample_values': list(col_data.dropna().unique())[:3]
                }
        
        return variable_info
    
    def detect_variables_from_question(self, question, variable_info):
        """ุงูุชุดุงู ุงููุชุบูุฑุงุช ุงููุฐููุฑุฉ ูู ุงูุณุคุงู"""
        detected_vars = []
        question_lower = question.lower()
        
        for var in variable_info.keys():
            var_lower = var.lower()
            
            # ุงูุจุญุซ ุนู ุงุณู ุงููุชุบูุฑ ูู ุงูุณุคุงู
            if var_lower in question_lower:
                detected_vars.append(var)
            # ุงูุจุญุซ ุนู ุงุฎุชุตุงุฑุงุช ุดุงุฆุนุฉ
            elif any(term in question_lower for term in [f' {var} ', f'{var},', f'{var}.']):
                detected_vars.append(var)
        
        return detected_vars
    
    def classify_question(self, question):
        """ุชุตููู ุงูุณุคุงู ุจูุงุกู ุนูู ูุญุชูุงู"""
        question_lower = question.lower()
        
        # ุงููููุงุช ุงูููุชุงุญูุฉ ููู ููุน ูู ุงูุชุญูููุงุช
        classifications = []
        
        if any(keyword in question_lower for keyword in ['mean', 'average', 'median', 'mode', 'standard deviation', 'descriptive']):
            classifications.append('descriptive')
        
        if any(keyword in question_lower for keyword in ['frequency', 'distribution', 'count', 'table']):
            classifications.append('frequency')
        
        if any(keyword in question_lower for keyword in ['t-test', 't test', 'compare means', 'independent', 'paired']):
            classifications.append('t_test')
        
        if any(keyword in question_lower for keyword in ['anova', 'analysis of variance', 'f-test']):
            classifications.append('anova')
        
        if any(keyword in question_lower for keyword in ['correlation', 'relationship', 'association']):
            classifications.append('correlation')
        
        if any(keyword in question_lower for keyword in ['regression', 'predict', 'linear model']):
            classifications.append('regression')
        
        if any(keyword in question_lower for keyword in ['chi-square', 'chi square', 'contingency']):
            classifications.append('chi_square')
        
        if any(keyword in question_lower for keyword in ['graph', 'chart', 'histogram', 'bar', 'pie', 'scatter']):
            classifications.append('graph')
        
        if any(keyword in question_lower for keyword in ['confidence interval', 'ci', '95%', '99%']):
            classifications.append('confidence')
        
        if any(keyword in question_lower for keyword in ['normality', 'normal distribution', 'shapiro', 'kolmogorov']):
            classifications.append('normality')
        
        return classifications if classifications else ['general']
    
    def generate_spss_syntax(self, question, var_info, detected_vars, q_num):
        """ุชูููุฏ ููุฏ SPSS ุจูุงุกู ุนูู ุงูุณุคุงู ูุงููุชุบูุฑุงุช"""
        classifications = self.classify_question(question)
        syntax_lines = []
        comment_lines = []
        
        # ุนููุงู ุงูุณุคุงู
        title = f"* {'='*70}.\n* QUESTION {q_num}: {question[:60]}...\n* {'='*70}."
        syntax_lines.append(title)
        
        for classification in classifications:
            if classification == 'descriptive':
                if detected_vars:
                    vars_str = ' '.join(detected_vars[:3])
                    syntax = f"DESCRIPTIVES VARIABLES={vars_str}\n  /STATISTICS=MEAN STDDEV MIN MAX SEMEAN KURTOSIS SKEWNESS."
                    syntax_lines.append(syntax)
                    comment = f"* Descriptive statistics for: {vars_str}"
                    comment_lines.append(comment)
            
            elif classification == 'frequency':
                # ุงูุจุญุซ ุนู ูุชุบูุฑุงุช ูุฆููุฉ
                categorical_vars = [v for v in detected_vars if var_info.get(v, {}).get('type') == 'categorical']
                if categorical_vars:
                    vars_str = ' '.join(categorical_vars[:3])
                    syntax = f"FREQUENCIES VARIABLES={vars_str}\n  /ORDER=ANALYSIS\n  /BARCHART\n  /PIECHART."
                    syntax_lines.append(syntax)
                    comment = f"* Frequency distribution for categorical variables: {vars_str}"
                    comment_lines.append(comment)
            
            elif classification == 't_test':
                if len(detected_vars) >= 2:
                    group_var = detected_vars[0]
                    test_vars = ' '.join(detected_vars[1:3])
                    syntax = f"T-TEST GROUPS={group_var}\n  /VARIABLES={test_vars}\n  /CRITERIA=CI(.95)\n  /MISSING=ANALYSIS."
                    syntax_lines.append(syntax)
                    comment = f"* T-test comparing {test_vars} by {group_var}"
                    comment_lines.append(comment)
            
            elif classification == 'anova':
                if len(detected_vars) >= 2:
                    dv = detected_vars[0]
                    iv = detected_vars[1]
                    syntax = f"ONEWAY {dv} BY {iv}\n  /STATISTICS DESCRIPTIVES HOMOGENEITY\n  /MISSING ANALYSIS\n  /POSTHOC=TUKEY ALPHA(0.05)."
                    syntax_lines.append(syntax)
                    comment = f"* One-way ANOVA: {dv} by {iv}"
                    comment_lines.append(comment)
            
            elif classification == 'correlation':
                if len(detected_vars) >= 2:
                    vars_str = ' '.join(detected_vars[:4])
                    syntax = f"CORRELATIONS\n  /VARIABLES={vars_str}\n  /PRINT=TWOTAIL NOSIG\n  /MISSING=PAIRWISE."
                    syntax_lines.append(syntax)
                    comment = f"* Correlation analysis between: {vars_str}"
                    comment_lines.append(comment)
            
            elif classification == 'regression':
                if len(detected_vars) >= 2:
                    dv = detected_vars[0]
                    iv_list = ' '.join(detected_vars[1:4])
                    syntax = f"REGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN\n  /DEPENDENT {dv}\n  /METHOD=ENTER {iv_list}."
                    syntax_lines.append(syntax)
                    comment = f"* Regression analysis: {dv} predicted by {iv_list}"
                    comment_lines.append(comment)
            
            elif classification == 'chi_square':
                if len(detected_vars) >= 2:
                    var1, var2 = detected_vars[:2]
                    syntax = f"CROSSTABS\n  /TABLES={var1} BY {var2}\n  /FORMAT=AVALUE TABLES\n  /STATISTICS=CHISQ PHI\n  /CELLS=COUNT EXPECTED."
                    syntax_lines.append(syntax)
                    comment = f"* Chi-square test of independence: {var1} ร {var2}"
                    comment_lines.append(comment)
            
            elif classification == 'graph':
                if detected_vars:
                    # ุชุญุฏูุฏ ููุน ุงูุฑุณู ุงูุจูุงูู
                    if 'histogram' in question.lower():
                        for var in detected_vars[:2]:
                            if var_info.get(var, {}).get('type') == 'numeric':
                                syntax = f"GRAPH /HISTOGRAM(NORMAL)={var}\n  /TITLE='Histogram of {var}'."
                                syntax_lines.append(syntax)
                    elif 'bar' in question.lower():
                        if len(detected_vars) >= 2:
                            syntax = f"GRAPH /BAR(SIMPLE)=MEAN({detected_vars[0]}) BY {detected_vars[1]}\n  /TITLE='Bar Chart: {detected_vars[0]} by {detected_vars[1]}'."
                            syntax_lines.append(syntax)
                    elif 'scatter' in question.lower():
                        if len(detected_vars) >= 2:
                            syntax = f"GRAPH /SCATTERPLOT(BIVAR)={detected_vars[0]} WITH {detected_vars[1]}\n  /TITLE='Scatter Plot: {detected_vars[0]} vs {detected_vars[1]}'."
                            syntax_lines.append(syntax)
            
            elif classification == 'confidence':
                if detected_vars:
                    var = detected_vars[0]
                    if '95%' in question.lower():
                        syntax = f"EXAMINE VARIABLES={var}\n  /CINTERVAL 95\n  /PLOT NONE."
                    elif '99%' in question.lower():
                        syntax = f"EXAMINE VARIABLES={var}\n  /CINTERVAL 99\n  /PLOT NONE."
                    else:
                        syntax = f"EXAMINE VARIABLES={var}\n  /CINTERVAL 95\n  /PLOT NONE."
                    syntax_lines.append(syntax)
            
            elif classification == 'normality':
                if detected_vars:
                    var = detected_vars[0]
                    syntax = f"EXAMINE VARIABLES={var}\n  /PLOT NPPLOT\n  /STATISTICS DESCRIPTIVES."
                    syntax_lines.append(syntax)
            
            elif classification == 'general':
                if detected_vars:
                    vars_str = ' '.join(detected_vars[:3])
                    syntax = f"DESCRIPTIVES VARIABLES={vars_str}\n  /STATISTICS=MEAN STDDEV MIN MAX.\nFREQUENCIES VARIABLES={vars_str}\n  /ORDER=ANALYSIS."
                    syntax_lines.append(syntax)
                    comment = f"* General analysis for variables: {vars_str}"
                    comment_lines.append(comment)
        
        # ุฅุฐุง ูู ูุชู ุงูุชุดุงู ุฃู ูุชุบูุฑุงุช
        if not syntax_lines[1:]:  # ุฅุฐุง ูุงู ุงูุนููุงู ููุท
            syntax_lines.append("* Please specify which variables to analyze.")
            syntax_lines.append("DESCRIPTIVES VARIABLES=ALL\n  /STATISTICS=MEAN STDDEV.")
        
        # ุฏูุฌ ุงูุชุนูููุงุช ูุน ุงูุตูุบุฉ
        if comment_lines:
            syntax_lines.insert(1, '\n'.join(comment_lines))
        
        return '\n'.join(syntax_lines) + '\n\n'
    
    def create_variable_labels(self, df):
        """ุฅูุดุงุก ุชุณููุงุช ูููุชุบูุฑุงุช"""
        labels = []
        for col in df.columns:
            # ุชุญููู ุงุณู ุงููุชุบูุฑ ุฅูู ุชุณููุฉ ููุฑูุกุฉ
            label = col.replace('_', ' ').title()
            labels.append(f"{col} '{label}'")
        
        return "VARIABLE LABELS\n    " + " /".join(labels) + ".\n\n"
    
    def create_value_labels(self, df, var_info):
        """ุฅูุดุงุก ุชุณููุงุช ุงูููู ูููุชุบูุฑุงุช ุงููุฆููุฉ"""
        value_labels = []
        
        for var, info in var_info.items():
            if info['type'] == 'categorical' and info['unique_values'] <= 10:
                # ูุญุงููุฉ ุฅุนุทุงุก ุชุณููุงุช ุฐููุฉ
                values = info['sample_values']
                labels_line = f"    /{var} "
                for i, val in enumerate(values[:5]):
                    if isinstance(val, (int, float)):
                        labels_line += f"{val} 'Value {val}' "
                    else:
                        labels_line += f"{i+1} '{val}' "
                value_labels.append(labels_line.strip())
        
        if value_labels:
            return "VALUE LABELS\n" + "\n".join(value_labels) + ".\n\n"
        return ""
    
    def parse_questions(self, text_content):
        """ุชุญููู ุงูุฃุณุฆูุฉ ูู ููู ุงููุต"""
        questions = []
        lines = text_content.split('\n')
        current_question = ""
        
        for line in lines:
            line = line.strip()
            
            # ุงูุชุนุฑู ุนูู ุจุฏุงูุฉ ุณุคุงู ุฌุฏูุฏ
            if (re.match(r'^\d+[\.\)]', line) or 
                re.match(r'^Q\d+:', line, re.IGNORECASE) or
                re.match(r'^Question \d+:', line, re.IGNORECASE)):
                
                if current_question:
                    questions.append(current_question.strip())
                current_question = re.sub(r'^\d+[\.\)]\s*', '', line)
                current_question = re.sub(r'^Q\d+:\s*', '', current_question, flags=re.IGNORECASE)
                current_question = re.sub(r'^Question \d+:\s*', '', current_question, flags=re.IGNORECASE)
            
            elif current_question and line:
                current_question += " " + line
        
        if current_question:
            questions.append(current_question.strip())
        
        return [q for q in questions if q and len(q) > 5]

# ุงูุชุทุจูู ุงูุฑุฆูุณู
def main():
    st.sidebar.title("โ๏ธ ุฅุนุฏุงุฏุงุช ุงููููุฏ")
    
    # ุฅุถุงูุฉ ุตูุฑุฉ ุฃู ุดุนุงุฑ
    st.sidebar.image("https://cdn-icons-png.flaticon.com/512/2103/2103655.png", width=100)
    
    # ุฅุนุฏุงุฏุงุช ุงูุชูููุฏ
    st.sidebar.subheader("ุฎูุงุฑุงุช ุงูุชูููุฏ")
    include_comments = st.sidebar.checkbox("ุฅุถุงูุฉ ุชุนูููุงุช ุชูุถูุญูุฉ", value=True)
    auto_detect_vars = st.sidebar.checkbox("ุงููุดู ุงูุชููุงุฆู ุนู ุงููุชุบูุฑุงุช", value=True)
    generate_all = st.sidebar.checkbox("ุชูููุฏ ุฌููุน ุฃููุงุน ุงูุชุญูููุงุช", value=False)
    
    st.sidebar.subheader("ุชูุณูู ุงูุฅุฎุฑุงุฌ")
    output_format = st.sidebar.selectbox(
        "ููุน ุงูุฅุฎุฑุงุฌ",
        ["SPSS Syntax (.sps)", "Text File (.txt)", "Both"]
    )
    
    generator = UniversalSPSSGenerator()
    
    # ุงููุณู ุงูุฑุฆูุณู
    st.markdown("---")
    
    # ุชุญููู ุงููููุงุช
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("๐ ุชุญููู ููู ุงูุจูุงูุงุช")
        data_file = st.file_uploader(
            "ุงุฎุชุฑ ููู Excel ุฃู CSV",
            type=['xlsx', 'xls', 'csv'],
            key="data_file"
        )
    
    with col2:
        st.subheader("๐ ุชุญููู ููู ุงูุฃุณุฆูุฉ")
        questions_file = st.file_uploader(
            "ุงุฎุชุฑ ููู ูุตู ููุฃุณุฆูุฉ",
            type=['txt', 'docx', 'pdf'],
            key="questions_file"
        )
    
    if data_file and questions_file:
        try:
            # ูุฑุงุกุฉ ุงูุจูุงูุงุช
            if data_file.name.endswith('.csv'):
                df = pd.read_csv(data_file)
            else:
                df = pd.read_excel(data_file)
            
            # ูุฑุงุกุฉ ุงูุฃุณุฆูุฉ
            if questions_file.name.endswith('.txt'):
                questions_text = questions_file.getvalue().decode('utf-8')
            else:
                # ูุญุงููุฉ ูุฑุงุกุฉ ุฃููุงุน ุงููููุงุช ุงูุฃุฎุฑู
                questions_text = str(questions_file.getvalue())
            
            questions = generator.parse_questions(questions_text)
            
            # ุชุญููู ูููู ุงูุจูุงูุงุช
            var_info = generator.analyze_data_structure(df)
            
            st.success(f"""
            โ ุชู ุชุญููู ุงูุจูุงูุงุช ุจูุฌุงุญ:
            - ุนุฏุฏ ุงูุฃุณุฆูุฉ: {len(questions)}
            - ุนุฏุฏ ุงููุชุบูุฑุงุช: {len(df.columns)}
            - ุนุฏุฏ ุงูุตููู: {len(df)}
            """)
            
            # ุนุฑุถ ูุนูููุงุช ุงูุจูุงูุงุช
            with st.expander("๐ ูุนุงููุฉ ุงูุจูุงูุงุช ูุชุญููู ุงููุชุบูุฑุงุช"):
                tab1, tab2 = st.tabs(["ูุนุงููุฉ ุงูุจูุงูุงุช", "ุชุญููู ุงููุชุบูุฑุงุช"])
                
                with tab1:
                    st.dataframe(df.head(10))
                    st.caption(f"ุงูุฃุจุนุงุฏ: {df.shape[0]} ุตู ร {df.shape[1]} ุนููุฏ")
                
                with tab2:
                    for var, info in list(var_info.items())[:10]:
                        st.write(f"**{var}**")
                        st.json(info, expanded=False)
                        st.write("---")
            
            # ุนุฑุถ ุงูุฃุณุฆูุฉ
            with st.expander("๐ ุงูุฃุณุฆูุฉ ุงููุญููุฉ"):
                for i, q in enumerate(questions, 1):
                    classifications = generator.classify_question(q)
                    detected_vars = generator.detect_variables_from_question(q, var_info)
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"**{i}.** {q}")
                    with col2:
                        st.caption(f"ุงูููุน: {', '.join(classifications)}")
                    
                    if detected_vars:
                        st.caption(f"ุงููุชุบูุฑุงุช ุงูููุชุดูุฉ: {', '.join(detected_vars)}")
                    
                    st.write("---")
            
            # ุฒุฑ ุชูููุฏ ุงูููุฏ
            st.markdown("---")
            if st.button("๐ ุชูููุฏ ููุฏ SPSS", type="primary", use_container_width=True):
                with st.spinner("ุฌุงุฑู ุชูููุฏ ููุฏ SPSS ุงููุชุฎุตุต..."):
                    
                    # ุฅูุดุงุก ุฑุฃุณ ุงูููุฏ
                    header = f"""* ========================================================================
* SPSS SYNTAX GENERATED BY UNIVERSAL SPSS GENERATOR
* Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
* Dataset: {data_file.name}
* Questions: {len(questions)}
* Variables: {len(df.columns)}
* ========================================================================

* SETUP AND DATA DEFINITION
"""
                    
                    # ุฅุถุงูุฉ ุชุณููุงุช ุงููุชุบูุฑุงุช
                    header += generator.create_variable_labels(df)
                    
                    # ุฅุถุงูุฉ ุชุณููุงุช ุงูููู
                    value_labels = generator.create_value_labels(df, var_info)
                    if value_labels:
                        header += value_labels
                    
                    header += "EXECUTE.\n\n"
                    
                    # ุชูููุฏ ููุฏ ููู ุณุคุงู
                    spss_code = header
                    
                    for i, question in enumerate(questions, 1):
                        detected_vars = generator.detect_variables_from_question(question, var_info)
                        question_code = generator.generate_spss_syntax(question, var_info, detected_vars, i)
                        spss_code += question_code
                    
                    # ุฅุถุงูุฉ ูุณู ุงูุฅุฎุฑุงุฌ
                    spss_code += """* ========================================================================
* OUTPUT MANAGEMENT
* ========================================================================

* Save output to file
OUTPUT SAVE OUTFILE='SPSS_Output.spv'
  /KEEP=ALL.

* Save modified dataset
SAVE OUTFILE='Analyzed_Data.sav'
  /COMPRESSED.

* Clear output viewer (optional)
OUTPUT CLOSE ALL.
"""
                    
                    # ุนุฑุถ ุงูููุฏ
                    st.subheader("๐ ููุฏ SPSS ุงูููุงุฆู")
                    
                    # ุฎูุงุฑุงุช ุนุฑุถ ุงูููุฏ
                    show_full = st.checkbox("ุนุฑุถ ุงูููุฏ ูุงููุงู", value=False)
                    
                    if show_full:
                        st.code(spss_code, language='text')
                    else:
                        # ุนุฑุถ ุนููุฉ ูู ุงูููุฏ
                        code_lines = spss_code.split('\n')
                        st.code('\n'.join(code_lines[:100]), language='text')
                        if len(code_lines) > 100:
                            st.info(f"ุนุฑุถ 100 ุณุทุฑ ูู ุฃุตู {len(code_lines)} ุณุทุฑ. ุชูุนูู 'ุนุฑุถ ุงูููุฏ ูุงููุงู' ูุฑุคูุฉ ุงูููุฏ ูุงููุงู.")
                    
                    # ุชุญููู ุงููููุงุช
                    st.markdown("---")
                    st.subheader("๐ฅ ุชุญููู ุงููููุงุช")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        # ููู SPSS Syntax
                        b64_sps = base64.b64encode(spss_code.encode()).decode()
                        href_sps = f'<a href="data:file/sps;base64,{b64_sps}" download="SPSS_Analysis.sps" style="text-decoration: none; padding: 10px 20px; background-color: #4CAF50; color: white; border-radius: 5px; font-weight: bold;">๐ฅ ุชูุฒูู ููู SPSS (.sps)</a>'
                        st.markdown(href_sps, unsafe_allow_html=True)
                    
                    with col2:
                        # ููู ูุตู
                        b64_txt = base64.b64encode(spss_code.encode()).decode()
                        href_txt = f'<a href="data:file/txt;base64,{b64_txt}" download="Analysis_Code.txt" style="text-decoration: none; padding: 10px 20px; background-color: #2196F3; color: white; border-radius: 5px; font-weight: bold;">๐ฅ ุชูุฒูู ููู ูุตู (.txt)</a>'
                        st.markdown(href_txt, unsafe_allow_html=True)
                    
                    with col3:
                        # ููู ุชุนูููุงุช
                        instructions = f"""# ุชุนูููุงุช ุงุณุชุฎุฏุงู ููุฏ SPSS
ุชุงุฑูุฎ ุงูุฅูุดุงุก: {datetime.now().strftime('%Y-%m-%d')}
ุนุฏุฏ ุงูุฃุณุฆูุฉ: {len(questions)}

## ุฎุทูุงุช ุงูุชูููุฐ:
1. ุงูุชุญ ุจุฑูุงูุฌ SPSS
2. ูู ุจุชุญููู ุจูุงูุงุชู (ููู ุงูุจูุงูุงุช ุงูุฃุตูู)
3. ุงูุชูู ุฅูู Window โ Syntax Editor
4. ุงูุตู ุงูููุฏ ุงููุฑูู
5. ุญุฏุฏ ุงูููุฏ ูุงููุงู (Ctrl+A)
6. ุงุถุบุท F5 ุฃู ุงููุฑ ุนูู Run (ุงูุณูู ุงูุฃุฎุถุฑ)

## ููุงุญุธุงุช ูููุฉ:
- ุชุฃูุฏ ูู ุชุทุงุจู ุฃุณูุงุก ุงููุชุบูุฑุงุช
- ูู ุจุญูุธ ุงููููุงุช ูุจู ุงูุจุฏุก
- ุฑุงุฌุน ุงูุฅุฎุฑุงุฌ (Output) ูููุชุงุฆุฌ
"""
                        b64_inst = base64.b64encode(instructions.encode()).decode()
                        href_inst = f'<a href="data:file/txt;base64,{b64_inst}" download="Instructions.txt" style="text-decoration: none; padding: 10px 20px; background-color: #FF9800; color: white; border-radius: 5px; font-weight: bold;">๐ฅ ุชุนูููุงุช ุงูุงุณุชุฎุฏุงู</a>'
                        st.markdown(href_inst, unsafe_allow_html=True)
                    
                    # ูุตุงุฆุญ ูุฃููุงุฑ
                    with st.expander("๐ก ูุตุงุฆุญ ูุชุญุณููุงุช"):
                        st.markdown("""
                        ### ูุชุญุณูู ุงููุชุงุฆุฌ:
                        1. **ุชุณููุฉ ุงููุชุบูุฑุงุช ุจุดูู ูุงุถุญ**: ุงุณุชุฎุฏู ุฃุณูุงุก ุฏุงูุฉ ุนูู ุงููุญุชูู
                        2. **ุชุญุฏูุฏ ุงููุชุบูุฑุงุช ูู ุงูุฃุณุฆูุฉ**: ุงุฐูุฑ ุฃุณูุงุก ุงููุชุบูุฑุงุช ุตุฑุงุญุฉ ูู ุงูุฃุณุฆูุฉ
                        3. **ุงูุชูุธูู**: ุฑุชุจ ุงูุฃุณุฆูุฉ ุจุดูู ููุทูู
                        
                        ### ููุชุญูููุงุช ุงููุชูุฏูุฉ:
                        - ุฅุฐุง ูุงู ุงูุณุคุงู ุนู ููุงุฑูุฉ ุงููุฌููุนุงุชุ ุงุฐูุฑ ุงุณู ูุชุบูุฑ ุงููุฌููุนุฉ
                        - ุฅุฐุง ูุงู ุนู ุงูุงุฑุชุจุงุทุ ุงุฐูุฑ ุงููุชุบูุฑูู ุงููุฑุงุฏ ููุงุณ ุงูุนูุงูุฉ ุจููููุง
                        - ุฅุฐุง ูุงู ุนู ุงูุงูุญุฏุงุฑุ ุญุฏุฏ ุงููุชุบูุฑ ุงูุชุงุจุน ูุงููุณุชูู
                        
                        ### ุฃูุซูุฉ ุนูู ุตูุงุบุฉ ุงูุฃุณุฆูุฉ:
                        - "ุงุญุณุจ ุงููุชูุณุท ูุงูุงูุญุฑุงู ุงููุนูุงุฑู ููุชุบูุฑ ุงูุฏุฎู (Income)"
                        - "ุงุฑุณู ูุฎุทุทุงู ุดุฑูุทูุงู ููุถุญ ุชูุฒูุน ุงูููุน (Gender)"
                        - "ุงุฎุชุจุฑ ุฅุฐุง ูุงู ููุงู ูุฑู ุฐู ุฏูุงูุฉ ูู ุงูุนูุฑ (Age) ุจูู ุงููุฌููุนุชูู (Group)"
                        """)
        
        except Exception as e:
            st.error(f"ุญุฏุซ ุฎุทุฃ: {str(e)}")
            st.exception(e)
    
    else:
        # ูุงุฌูุฉ ุงูุชุฑุญูุจ
        st.info("""
        ## ๐ฏ ูุฑุญุจุงู ุจู ูู ูููุฏ ุฃููุงุฏ SPSS ุงูุดุงูู
        
        **ููููุฉ ุงูุงุณุชุฎุฏุงู:**
        1. **ูู ุจุชุญููู ููู ุงูุจูุงูุงุช** (Excel ุฃู CSV)
        2. **ูู ุจุชุญููู ููู ุงูุฃุณุฆูุฉ** (ููู ูุตู)
        3. **ุงุถุบุท ุนูู ุฒุฑ "ุชูููุฏ ููุฏ SPSS"**
        4. **ุญูู ุงููููุงุช ุงููุงุชุฌุฉ**
        
        **ุงููููุฒุงุช:**
        - โ ูุฏุนู ุฃู ููุน ูู ุงูุงูุชุญุงูุงุช ุงูุฅุญุตุงุฆูุฉ
        - โ ูุญูู ุงูุจูุงูุงุช ุชููุงุฆูุงู
        - โ ูุชุนุฑู ุนูู ุฃููุงุน ุงูุฃุณุฆูุฉ ุงููุฎุชููุฉ
        - โ ููุชุดู ุงููุชุบูุฑุงุช ุงููุฐููุฑุฉ ูู ุงูุฃุณุฆูุฉ
        - โ ูููุฏ ููุฏ SPSS ุฌุงูุฒ ููุชูููุฐ
        - โ ูุฏุนู ุฌููุน ุฃููุงุน ุงูุชุญูููุงุช ุงูุฅุญุตุงุฆูุฉ
        
        **ุฃููุงุน ุงูุชุญูููุงุช ุงููุฏุนููุฉ:**
        - ุงูุฅุญุตุงุกุงุช ุงููุตููุฉ
        - ุงูุฌุฏุงูู ุงูุชูุฑุงุฑูุฉ
        - ุงุฎุชุจุงุฑุงุช T
        - ุชุญููู ุงูุชุจุงูู (ANOVA)
        - ุงูุงุฑุชุจุงุท ูุงูุงูุญุฏุงุฑ
        - ุงุฎุชุจุงุฑุงุช ูุฑุจุน ูุงู
        - ุงูุฑุณูู ุงูุจูุงููุฉ ุจุฃููุงุนูุง
        - ูุชุฑุงุช ุงูุซูุฉ
        - ุงุฎุชุจุงุฑุงุช ุงูุทุจูุนูุฉ
        """)
        
        # ุฃูุซูุฉ ุนูู ุชูุณูู ุงูุฃุณุฆูุฉ
        with st.expander("๐ ุฃูุซูุฉ ุนูู ุชูุณูู ุงูุฃุณุฆูุฉ"):
            st.markdown("""
            ### ูุซุงู 1: ุฃุณุฆูุฉ ูุตููุฉ
            ```
            1. ุงุญุณุจ ุงููุชูุณุท ูุงูุงูุญุฑุงู ุงููุนูุงุฑู ููุนูุฑ ูุงูุฏุฎู
            2. ุฃูุดุฆ ุฌุฏููุงู ุชูุฑุงุฑูุงู ููููุน ูุงูุชุนููู
            3. ุงุฑุณู ูุฎุทุทุงู ุดุฑูุทูุงู ููุถุญ ุชูุฒูุน ุงูููุงุตุจ
            ```
            
            ### ูุซุงู 2: ุฃุณุฆูุฉ ุงุณุชุฏูุงููุฉ
            ```
            4. ุงุฎุชุจุฑ ุฅุฐุง ูุงู ููุงู ูุฑู ูู ุงูุฑุงุชุจ ุจูู ุงูุฐููุฑ ูุงูุฅูุงุซ
            5. ุงูุญุต ุงูุนูุงูุฉ ุจูู ุณููุงุช ุงูุฎุจุฑุฉ ูุงูุฏุฎู
            6. ุญูู ุชุฃุซูุฑ ุงูุนูุฑ ูุงูุชุนููู ุนูู ุงูุฑุงุชุจ
            ```
            
            ### ูุซุงู 3: ุฃุณุฆูุฉ ุจูุงููุฉ
            ```
            7. ุงุฑุณู ูุฎุทุทุงู ุฏุงุฆุฑูุงู ูุชูุฒูุน ุงูููุน
            8. ุฃูุดุฆ ูุฎุทุทุงู ูุจุนุซุฑุงู ููุนูุงูุฉ ุจูู ุงูุนูุฑ ูุงูุฏุฎู
            9. ุงุฑุณู ูุฎุทุทุงู ุตูุฏูููุงู ููุฑูุงุชุจ ุญุณุจ ุงููุณู
            ```
            """)
        
        # ูุซุงู ุชุฌุฑูุจู
        with st.expander("๐ฌ ุฌุฑุจ ูุซุงูุงู ุชุฌุฑูุจูุงู"):
            if st.button("ุชุญููู ุจูุงูุงุช ุชุฌุฑูุจูุฉ"):
                # ุฅูุดุงุก ุจูุงูุงุช ุชุฌุฑูุจูุฉ
                np.random.seed(42)
                sample_data = pd.DataFrame({
                    'Age': np.random.randint(20, 60, 100),
                    'Salary': np.random.normal(5000, 1500, 100),
                    'Gender': np.random.choice(['Male', 'Female'], 100),
                    'Education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], 100),
                    'Experience': np.random.randint(1, 30, 100),
                    'Department': np.random.choice(['Sales', 'IT', 'HR', 'Finance'], 100)
                })
                
                sample_questions = """1. Calculate descriptive statistics for Age and Salary
2. Create frequency tables for Gender and Education
3. Test if there is a significant difference in Salary between genders
4. Examine the relationship between Experience and Salary
5. Draw a bar chart showing average Salary by Department
6. Create a scatter plot of Age vs Salary
7. Perform regression analysis with Salary as dependent variable"""
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**ุงูุจูุงูุงุช ุงูุชุฌุฑูุจูุฉ:**")
                    st.dataframe(sample_data.head())
                with col2:
                    st.write("**ุงูุฃุณุฆูุฉ ุงูุชุฌุฑูุจูุฉ:**")
                    st.text(sample_questions)

if __name__ == "__main__":
    main()
