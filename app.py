import streamlit as st
import pandas as pd
import numpy as np
import re
import math

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="MBA SPSS Genius", layout="wide", page_icon="ğŸ“")
st.title("ğŸ“ Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø­Ù…Ø¯ - SPSS Engine (Advanced Logic)")

# --- 1. Ø¯ÙˆØ§Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ ---

def get_sturges_syntax(var_code, var_name, n_rows, data_series=None):
    """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙƒÙˆÙŠØ¯ Ù„Ù„ÙØ¦Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
    if n_rows == 0: # Ù„Ùˆ Ù…ÙÙŠØ´ Ø¯Ø§ØªØ§ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        k = 5
        width = 1000
        min_val = 0
    else:
        # Sturges Rule: k = 1 + 3.322 log(n)
        k = math.ceil(1 + 3.322 * math.log10(n_rows))
        if data_series is not None:
            min_val = math.floor(data_series.min())
            max_val = math.ceil(data_series.max())
            width = math.ceil((max_val - min_val) / k)
        else:
            return f"* Note: Load Excel file to calculate exact intervals for {var_name}.\n", var_code

    new_var = f"{var_code}_Cat"
    syntax = f"\n* --- RECODE Logic for {var_name} (Sturges k={k}) ---.\n"
    syntax += f"RECODE {var_code} "
    
    current = min_val
    for i in range(1, k+1):
        end = current + width
        if i == k: 
            syntax += f"({current} THRU HIGHEST={i}) " # Ø¢Ø®Ø± ÙØ¦Ø© Ù…ÙØªÙˆØ­Ø©
        else:
            syntax += f"({current} THRU {end}={i}) "
        current = end
    
    syntax += f"INTO {new_var}.\n"
    syntax += f"VARIABLE LABELS {new_var} 'Classes of {var_name}'.\n"
    syntax += f"EXECUTE.\n"
    return syntax, new_var

def fill_template_advanced(template, found_vars, split_var=None):
    """Ù…Ù„Ø¡ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø¨Ø°ÙƒØ§Ø¡ Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„ØªØ§Ø¨Ø¹ ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ù„"""
    syntax = template
    
    # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
    scale_vars = [v['code'] for v in found_vars if v['type'] == 'Scale']
    nom_vars = [v['code'] for v in found_vars if v['type'] == 'Nominal']
    all_codes = [v['code'] for v in found_vars]

    # 1. Ø§Ø³ØªØ¨Ø¯Ø§Ù„ {var} Ø¨Ø§Ù„ÙƒÙ„
    if '{var}' in syntax:
        syntax = syntax.replace('{var}', " ".join(all_codes))
        # ØªØµØ­ÙŠØ­ Ø®Ø·Ø£ Ø´Ø§Ø¦Ø¹: Ù„Ùˆ Ø§Ù„Ù‚Ø§Ù„Ø¨ ÙÙŠÙ‡ var Ø¨Ø¯ÙˆÙ† Ø£Ù‚ÙˆØ§Ø³
    if '=var' in syntax: 
         syntax = syntax.replace('=var', f"={' '.join(all_codes)}")

    # 2. Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ {group} (Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù…ÙÙ‚Ø³Ù‘ÙÙ…)
    if '{group}' in syntax:
        # Ù„Ùˆ Ø¹Ù†Ø¯Ù†Ø§ split_var (Ø²ÙŠ Ø³Ø¤Ø§Ù„ for each city) Ù†Ø³ØªØ®Ø¯Ù…Ù‡ Ù‡Ùˆ
        if split_var:
            syntax = syntax.replace('{group}', split_var)
        elif nom_vars:
            syntax = syntax.replace('{group}', nom_vars[0])
        else:
            syntax = syntax.replace('{group}', "MISSING_GROUP")

    # 3. Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ {y} (Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø±Ù‚Ù…ÙŠ/Ø§Ù„ØªØ§Ø¨Ø¹)
    if '{y}' in syntax:
        # Ù†Ø®ØªØ§Ø± Ø£ÙˆÙ„ Ù…ØªØºÙŠØ± Scale ÙƒÙ…ØªØºÙŠØ± ØªØ§Ø¨Ø¹
        target = scale_vars[0] if scale_vars else (all_codes[0] if all_codes else "MISSING_Y")
        syntax = syntax.replace('{y}', target)

    return syntax

# --- 2. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.header("ğŸ“‚ 1. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù‚ÙˆØ§Ø¹Ø¯")
    rules_file = st.file_uploader("Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ (CSV)", type=['csv'])
    rules_df = None
    if rules_file:
        rules_df = pd.read_csv(rules_file)

    data_file = st.file_uploader("Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel/CSV)", type=['xlsx', 'csv'])
    df = None
    df_vars = {} 
    
    # Mapping Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù…Ø­Ø¯Ø« Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¨Ù†Ùƒ
    default_mapping = """
x1 = account balance
x2 = atm transaction
x2 = number of atm
x3 = age
x4 = city
x4 = where banking is done
x5 = debit card
x6 = interest
x6 = receive interest
"""
    if data_file:
        try:
            if data_file.name.endswith('.csv'): df = pd.read_csv(data_file)
            else: df = pd.read_excel(data_file)
            st.success(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} ØµÙ")
            # ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„Ø¯Ø§ØªØ§
            for i, col in enumerate(df.columns):
                 # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø§Ø³Ù…
                clean_name = col.strip().lower()
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹
                if pd.api.types.is_numeric_dtype(df[col]) and df[col].nunique() > 10:
                    v_type = 'Scale'
                else:
                    v_type = 'Nominal'
                
                # Ø±Ø¨Ø· Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ ÙˆØ§Ù„Ø¯Ø§ØªØ§
                # Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ù†Ø§ Ø³Ù†Ø­Ø§ÙˆÙ„ Ø±Ø¨Ø· Ø§Ù„ÙƒÙˆØ¯ X Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù€ Mapping Ù„Ø§Ø­Ù‚Ø§Ù‹
                # Ù„Ù„ØªØ³Ù‡ÙŠÙ„ Ø³Ù†Ø®Ø²Ù† Ø§Ù„Ø¯Ø§ØªØ§ Ø¨Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯
                df_vars[clean_name] = {'data': df[col], 'type': v_type}
                
        except Exception as e:
            st.error(e)

    v_mapping_text = st.text_area("ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª:", value=default_mapping.strip(), height=200)

# --- 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù€ Mapping ---
mapping_list = [] 
for line in v_mapping_text.split('\n'):
    if '=' in line:
        parts = line.split('=')
        code = parts[0].strip().upper()
        phrase = parts[1].strip().lower()
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
        v_type = 'Scale' if any(x in phrase for x in ['balance', 'transaction', 'age']) else 'Nominal'
        mapping_list.append({'code': code, 'phrase': phrase, 'type': v_type, 'real_name': phrase})

# --- 4. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---
st.header("ğŸ“ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©")
questions_input = st.text_area("Ø§Ù„ØµÙ‚ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:", height=300)

if st.button("ğŸš€ Run Analysis"):
    final_syntax = ["* Encoding: UTF-8.", "SET SEED=12345.", "OUTPUT MODIFY /SELECT ALL /REPORT PRINT LOG.", ""]
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
    questions = re.split(r'(?:\n|\d+\.\s)', questions_input)
    
    q_num = 0
    for q in questions:
        q_clean = q.strip()
        if len(q_clean) < 5: continue
        q_num += 1
        q_lower = q_clean.lower()
        
        final_syntax.append(f"\n* ---------------- Q{q_num} ----------------.")
        final_syntax.append(f"* Question: {q_clean}")

        # Ø£) Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        found_vars = []
        for item in mapping_list:
            # Ø¨Ø­Ø« Ø¯Ù‚ÙŠÙ‚ Ø¹Ù† Ø§Ù„Ø¬Ù…Ù„Ø©
            if item['phrase'] in q_lower:
                found_vars.append(item)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
        unique = []
        seen = set()
        for v in found_vars:
            if v['code'] not in seen:
                unique.append(v)
                seen.add(v['code'])
        found_vars = unique

        if not found_vars:
            final_syntax.append("* Warning: No variables found defined in Mapping.")
            continue

        # Ø¨) Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù†ÙŠØ© Ø§Ù„Ø®Ø§ØµØ© (Logic Detection)
        
        # 1. Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ø·Ù„Ø¨ "For Each" Ø£Ùˆ "Per" (Split File)ØŸ
        split_code = None
        if 'for each' in q_lower or 'per ' in q_lower:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø§Ø³Ù…ÙŠ Ø§Ù„Ø°ÙŠ Ø¬Ø§Ø¡ Ø¨Ø¹Ø¯ for each
            # Ù†ÙØªØ±Ø¶ Ø£Ù†Ù‡ Ø£Ø­Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù€ Nominal Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„
            nominals = [v for v in found_vars if v['type'] == 'Nominal']
            if nominals:
                split_code = nominals[0]['code'] # Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ Ù…ØªØºÙŠØ± Ø§Ø³Ù…ÙŠ ÙˆØ¬Ø¯Ù†Ø§Ù‡
                final_syntax.append(f"\n* --- SPLIT FILE BY {split_code} ---.")
                final_syntax.append(f"SORT CASES BY {split_code}.")
                final_syntax.append(f"SPLIT FILE SEPARATE BY {split_code}.")

        # 2. Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ø·Ù„Ø¨ "Classes" Ø£Ùˆ "Groups" Ù„Ù…ØªØºÙŠØ± Ø±Ù‚Ù…ÙŠØŸ (Recode)
        needs_recode = False
        recode_var = None
        if 'class' in q_lower or 'group' in q_lower:
            scales = [v for v in found_vars if v['type'] == 'Scale']
            if scales:
                needs_recode = True
                recode_var = scales[0] # Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø°ÙŠ Ø³Ù†Ø­ÙˆÙ„Ù‡ Ù„ÙØ¦Ø§Øª
        
        # Ø¬) Ø§Ø®ØªÙŠØ§Ø± ÙˆØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
        code_generated = ""
        rule_applied = False
        
        if rules_df is not None:
             # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø§Ù„Ø£Ø·ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„
            sorted_rules = rules_df.sort_values(by="Keyword", key=lambda x: x.str.len(), ascending=False)
            
            for idx, row in sorted_rules.iterrows():
                if str(row['Keyword']).lower() in q_lower:
                    template = row['Syntax_Template']
                    
                    # Ø­Ø§Ù„Ø© Ø®Ø§ØµØ©: Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ·Ù„Ø¨ ÙØ¦Ø§Øª (Classes)ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯
                    if needs_recode and recode_var:
                        # ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„Ù€ Recode
                        n_rows = len(df) if df is not None else 0
                        data_col = df_vars.get(recode_var['real_name'], {}).get('data') if df is not None else None
                        
                        rec_syntax, new_var_code = get_sturges_syntax(recode_var['code'], recode_var['phrase'], n_rows, data_col)
                        final_syntax.append(rec_syntax)
                        
                        # Ù†Ø¹Ø¯Ù„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø±Ø³Ù„Ø© Ù„Ù„Ù‚Ø§Ù„Ø¨ Ù„ØªØ´Ù…Ù„ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù‚Ø¯ÙŠÙ…
                        temp_vars = [v for v in found_vars if v['code'] != recode_var['code']]
                        temp_vars.append({'code': new_var_code, 'type': 'Nominal'}) # Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£ØµØ¨Ø­ Ø§Ø³Ù…ÙŠ
                        
                        code_generated = fill_template_advanced(template, temp_vars, split_code)
                    else:
                        code_generated = fill_template_advanced(template, found_vars, split_code)
                    
                    final_syntax.append(f"* Rule: {row['Category']}")
                    final_syntax.append(code_generated)
                    rule_applied = True
                    break
        
        # Ø¯) Ø§Ù„Ù€ Fallback (Ù„Ùˆ Ù…ÙÙŠØ´ Ù‚Ø§Ø¹Ø¯Ø©)
        if not rule_applied:
            # Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Outliers
            if 'outlier' in q_lower or 'extreme' in q_lower:
                target = found_vars[0]['code']
                final_syntax.append(f"EXAMINE VARIABLES={target} /PLOT BOXPLOT.")
            else:
                vars_str = " ".join([v['code'] for v in found_vars])
                final_syntax.append(f"DESCRIPTIVES VARIABLES={vars_str} /STATISTICS=MEAN STDDEV MIN MAX.")

        # Ù‡Ù€) Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù€ Split File
        if split_code:
            final_syntax.append("SPLIT FILE OFF.")

    st.subheader("ğŸ’» Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
    st.code("\n".join(final_syntax), language='spss')
