import streamlit as st
import pandas as pd
import numpy as np
import re
import math

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="MBA SPSS Genius", layout="wide", page_icon="ğŸ“")

st.title("ğŸ“ Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø­Ù…Ø¯ - Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù€ SPSS (MBA Edition)")
st.markdown("""
### ğŸ’¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù†Ø©:
1. **Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:** ÙŠØ¹Ù…Ù„ Ø­ØªÙ‰ Ø¨Ø¯ÙˆÙ† Ù…Ù„Ù Ø¥ÙƒØ³ÙŠÙ„ (ÙŠÙˆÙ„Ø¯ ÙƒÙˆØ¯Ø§Ù‹ Ø¹Ø§Ù…Ø§Ù‹).
2. **Ø¯Ù‚Ø© Ø§Ù„Ø¨Ø­Ø«:** ÙŠÙ…ÙŠØ² Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© (Ù…Ø«Ù„Ø§Ù‹ Age Ù„Ø§ ØªØ®ØªÙ„Ø· Ø¨Ù€ Average).
3. **Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ù†Ù‡Ø¬:** ÙŠØ·Ø¨Ù‚ Sturges Rule Ù„Ù„ÙØ¦Ø§Øª Ø¹Ù†Ø¯ ØªÙˆÙØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
""")

# --- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…Ù†Ù‡Ø¬ (MBA Logic) ---
def determine_measure(series):
    """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØºÙŠØ±: Scale Ø£Ùˆ Nominal Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    if pd.api.types.is_numeric_dtype(series):
        # Ù„Ùˆ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù‚Ù„ÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ (Ø£Ù‚Ù„ Ù…Ù† 15) Ù†Ø¹ØªØ¨Ø±Ù‡ ÙØ¦Ø§ØªØŒ Ø¥Ù„Ø§ Ù„Ùˆ ÙƒØ§Ù† ÙƒØ³Ø±ÙŠØ§Ù‹
        if series.nunique() < 15 and pd.api.types.is_integer_dtype(series): 
            return "Nominal"
        return "Scale"
    return "Nominal"

def sturges_rule(n):
    """Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ"""
    if n <= 0: return 5
    return math.ceil(1 + 3.322 * math.log10(n))

def generate_recode_syntax(var_code, series, n):
    """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙƒÙˆÙŠØ¯ (Recode) Ù„Ø¹Ù…Ù„ ÙØ¦Ø§Øª"""
    try:
        k = sturges_rule(n)
        min_val = math.floor(series.min())
        max_val = math.ceil(series.max())
        
        # ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ± Ù„Ùˆ ÙƒÙ„ Ø§Ù„Ù‚ÙŠÙ… Ù…ØªØ³Ø§ÙˆÙŠØ©
        if max_val == min_val:
            k = 1
            width = 1
        else:
            width = math.ceil((max_val - min_val) / k)
        
        syntax = f"\n* --- RECODING LOGIC (Sturges Rule: k={k}) ---.\n"
        syntax += f"* Recoding {var_code} into {k} classes (Width approx {width}).\n"
        syntax += f"RECODE {var_code} "
        
        current = min_val
        for i in range(1, k+1):
            end = current + width
            # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù„ØªØ´Ù…Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¹Ù„ÙŠØ§ (Lowest thru ... thru Highest)
            if i == 1:
                chunk = f"(Lowest THRU {end}={i})"
            elif i == k:
                chunk = f"({current} THRU Highest={i})"
            else:
                chunk = f"({current} THRU {end}={i})"
            
            syntax += f"\n  {chunk}"
            current = end
            
        syntax += f"\n  INTO {var_code}_Cat.\n"
        syntax += f"VARIABLE LABELS {var_code}_Cat 'Categorized {var_code}'.\n"
        syntax += f"EXECUTE.\n" # Ø£Ù…Ø± Ù…Ù‡Ù… Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù€ Recode ÙÙˆØ±Ø§Ù‹
        return syntax, f"{var_code}_Cat"
    except Exception as e:
        return f"* Error generating recode: {str(e)}", var_code

# --- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.header("ğŸ“‚ 1. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ¹Ø±ÙŠÙØ§Øª")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel/CSV)", type=['xlsx', 'csv'])
    
    default_mapping = "x1=Gender\nx2=Education\nx3=Salary\nx4=Age\nx5=Satisfaction"
    
    df = None
    df_vars = {} 
    detected_map = []

    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.success(f"âœ… ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„: {len(df)} ØµÙ")
            
            st.subheader("ğŸ“Š Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            for i, col in enumerate(df.columns):
                # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
                clean_col_name = col.strip()
                m_type = determine_measure(df[col])
                code = f"X{i+1}"
                # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø§Ø³Ù… lowercase Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
                df_vars[clean_col_name.lower()] = {'code': code, 'type': m_type, 'data': df[col], 'real_name': clean_col_name}
                detected_map.append(f"{code}={clean_col_name}")
                st.caption(f"**{clean_col_name}** â {code} ({m_type})")
            
            if st.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ù…Ù† Ø§Ù„Ù…Ù„ÙØŸ", value=True):
                default_mapping = "\n".join(detected_map)
                
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù„Ù: {e}")

    v_mapping_text = st.text_area("ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù€ Mapping (X=Name):", value=default_mapping, height=200, help="Ø§ÙƒØªØ¨ Ø§Ù„ÙƒÙˆØ¯=Ø§Ù„Ø§Ø³Ù… (ÙƒÙ„ ÙˆØ§Ø­Ø¯ ÙÙŠ Ø³Ø·Ø±)")

# --- Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
mapping_dict = {} # Name -> Code
code_to_type = {} # Code -> Type
code_to_realname = {} # Code -> Original Name (for labels)

for line in v_mapping_text.split('\n'):
    if '=' in line:
        code, name = line.split('=')
        c = code.strip().upper()
        n = name.strip().lower() # Ø§Ù„Ø§Ø³Ù… Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        real_n = name.strip()    # Ø§Ù„Ø§Ø³Ù… Ù„Ù„Ø¹Ø±Ø¶
        
        mapping_dict[n] = c
        code_to_realname[c] = real_n
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ (Logic fallback)
        if df is not None and n in df_vars:
            code_to_type[c] = df_vars[n]['type']
        else:
            # ØªØ®Ù…ÙŠÙ† Ø°ÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù… Ù„Ùˆ Ù…ÙÙŠØ´ Ø¯Ø§ØªØ§
            if any(x in n for x in ['salary', 'age', 'income', 'score', 'sales', 'height', 'weight']):
                code_to_type[c] = 'Scale'
            else:
                code_to_type[c] = 'Nominal'

st.header("ğŸ“ 2. Ø§Ù„ØµÙ‚ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ù…ØªØ­Ø§Ù†")
questions_input = st.text_area("Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:", height=150, placeholder="Ù…Ø«Ø§Ù„:\n1. Check the normality of Salary.\n2. Predict Satisfaction based on Salary and Age.")

if st.button("ğŸš€ ØªØ­Ù„ÙŠÙ„ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³Ù†ØªØ§ÙƒØ³"):
    if not questions_input:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø£ÙˆÙ„Ø§Ù‹.")
    else:
        final_syntax = [
            "* Encoding: UTF-8.", 
            "SET SEED=12345.", 
            "OUTPUT MODIFY /SELECT ALL /REPORT PRINT LOG.", # Ù„ØªØ­Ø³ÙŠÙ† Ø´ÙƒÙ„ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
            ""
        ]
        
        questions = re.split(r'(?:\n|\. )', questions_input)
        
        for q_idx, q in enumerate(questions):
            q_clean = q.strip()
            if not q_clean: continue
            
            final_syntax.append(f"\n* ---------------------------------------------.")
            final_syntax.append(f"* QUESTION {q_idx+1}: {q_clean}.")
            final_syntax.append(f"* ---------------------------------------------.")
            q_lower = q_clean.lower()
            
            # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª (Regex Word Boundary Fix)
            found_vars = [] 
            for name, code in mapping_dict.items():
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Regex Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ ÙƒÙ„Ù…Ø© ÙƒØ§Ù…Ù„Ø© ÙˆÙ„ÙŠØ³Øª Ø¬Ø²Ø¡Ø§Ù‹ Ù…Ù† ÙƒÙ„Ù…Ø©
                # re.escape(name) ÙŠØ­Ù…ÙŠ Ù„Ùˆ Ø§Ù„Ø§Ø³Ù… ÙÙŠÙ‡ Ø±Ù…ÙˆØ² ØºØ±ÙŠØ¨Ø©
                if re.search(r'\b' + re.escape(name) + r'\b', q_lower):
                    v_type = code_to_type.get(code, 'Scale')
                    found_vars.append({'name': name, 'code': code, 'type': v_type})
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±ØªÙŠØ¨
            # (Ù‚Ø¯ ÙŠØ¸Ù‡Ø± Ø§Ù„Ù…ØªØºÙŠØ± Ù…Ø±ØªÙŠÙ† Ù„Ùˆ Ø°ÙƒØ± Ø§Ù„Ø§Ø³Ù… Ù…Ø±ØªÙŠÙ†)
            unique_vars = []
            seen_codes = set()
            for v in found_vars:
                if v['code'] not in seen_codes:
                    unique_vars.append(v)
                    seen_codes.add(v['code'])
            found_vars = unique_vars

            if not found_vars:
                final_syntax.append("* Note: No variables detected in this question based on Mapping.")
                continue

            # 2. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ (Logic Engine)
            
            # --- A: Regression ---
            if any(w in q_lower for w in ['predict', 'impact', 'effect', 'regression', 'depend']):
                if len(found_vars) >= 2:
                    # Ø§ÙØªØ±Ø§Ø¶: Ø§Ù„Ø£ÙˆÙ„ Ù‡Ùˆ Ø§Ù„ØªØ§Ø¨Ø¹ØŒ Ù„ÙƒÙ† Ù†Ø¶Ø¹ ØªØ­Ø°ÙŠØ±
                    dep = found_vars[0]['code']
                    indep = " ".join([v['code'] for v in found_vars[1:]])
                    final_syntax.append(f"* ASSUMPTION: '{found_vars[0]['name']}' is the DEPENDENT variable.")
                    final_syntax.append(f"* If incorrect, swap {dep} with one of the independent variables.")
                    final_syntax.append(f"REGRESSION /MISSING LISTWISE /STATISTICS COEFF OUTS R ANOVA")
                    final_syntax.append(f" /DEPENDENT {dep} /METHOD=ENTER {indep}.")
                    final_syntax.append(f"* Check Anova Sig < 0.05 => Model is Significant.")
                else:
                    final_syntax.append("* Error: Need at least 2 variables for regression.")

            # --- B: Normality & Distribution ---
            elif any(w in q_lower for w in ['distribution', 'normality', 'skewness', 'describe', 'normal']):
                for v in found_vars:
                    if v['type'] == 'Scale':
                        final_syntax.append(f"DESCRIPTIVES VARIABLES={v['code']} /STATISTICS=MEAN STDDEV SKEWNESS KURTOSIS MIN MAX.")
                        final_syntax.append(f"* RULE (Empirical): Skewness between -1 & +1 implies Normal Distribution.")
                        final_syntax.append(f"* RULE (Chebyshev): If Skewness < -1 or > +1 implies Skewed Data.")
                        final_syntax.append(f"EXAMINE VARIABLES={v['code']} /PLOT BOXPLOT NPPLOT.") # NPPLOT gives QQ Plot

            # --- C: Frequencies & Classes (Sturges Rule) ---
            elif any(w in q_lower for w in ['frequency', 'class', 'group', 'table', 'range']):
                for v in found_vars:
                    if v['type'] == 'Scale':
                        # Ù‡Ù†Ø§ Check Ù…Ù‡Ù…: Ù‡Ù„ Ø§Ù„Ø¯Ø§ØªØ§ Ù…ÙˆØ¬ÙˆØ¯Ø©ØŸ
                        if df is not None and v['name'] in df_vars:
                            rec_syntax, new_var = generate_recode_syntax(v['code'], df_vars[v['name']]['data'], len(df))
                            final_syntax.append(rec_syntax)
                            final_syntax.append(f"FREQUENCIES VARIABLES={new_var} /ORDER=ANALYSIS.")
                        else:
                            final_syntax.append(f"* Note: Upload Excel file to enable automatic Sturges Rule Recoding for {v['name']}.")
                            final_syntax.append(f"FREQUENCIES VARIABLES={v['code']} /FORMAT=NOTABLE /STATISTICS=STDDEV MEAN.")
                    else:
                        final_syntax.append(f"FREQUENCIES VARIABLES={v['code']} /ORDER=ANALYSIS.")

            # --- D: Comparisons (T-Test / ANOVA) ---
            elif any(w in q_lower for w in ['difference', 'compare', 'mean of', 'test']):
                scale_v = next((v for v in found_vars if v['type'] == 'Scale'), None)
                nom_v = next((v for v in found_vars if v['type'] == 'Nominal'), None)
                
                if scale_v and nom_v:
                    final_syntax.append(f"* Comparing Mean of {scale_v['name']} (Scale) across groups of {nom_v['name']} (Nominal).")
                    final_syntax.append(f"MEANS TABLES={scale_v['code']} BY {nom_v['code']} /CELLS=MEAN COUNT STDDEV.")
                    final_syntax.append(f"ONEWAY {scale_v['code']} BY {nom_v['code']} /STATISTICS DESCRIPTIVES /POSTHOC=TUKEY ALPHA(0.05).")
                else:
                    final_syntax.append("* Hint: For comparisons, ensure you mentioned one Metric (Scale) and one Grouping (Nominal) variable.")
                    final_syntax.append(f"* Detected: {[v['code'] for v in found_vars]}")

            # --- E: Charts ---
            elif any(w in q_lower for w in ['chart', 'plot', 'graph', 'draw']):
                for v in found_vars:
                    if v['type'] == 'Scale':
                        final_syntax.append(f"GRAPH /HISTOGRAM={v['code']}.")
                        final_syntax.append(f"* Add /NORMAL to overlay curve if needed.")
                    else:
                        final_syntax.append(f"GRAPH /BAR(SIMPLE)=COUNT BY {v['code']}.")

            # --- Fallback (General) ---
            else:
                vars_str = " ".join([v['code'] for v in found_vars])
                final_syntax.append(f"DESCRIPTIVES VARIABLES={vars_str} /STATISTICS=MEAN STDDEV.")

        st.subheader("ğŸ“ ÙƒÙˆØ¯ Ø§Ù„Ø­Ù„ (Copy & Paste to SPSS Syntax Editor):")
        full_text = "\n".join(final_syntax)
        st.code(full_text, language='spss')
        st.success("ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯! Ø§Ù†Ø³Ø®Ù‡ ÙˆØ§Ù„ØµÙ‚Ù‡ ÙÙŠ Ù†Ø§ÙØ°Ø© Syntax ÙÙŠ Ø¨Ø±Ù†Ø§Ù…Ø¬ SPSS Ø«Ù… Ø§Ø¶ØºØ· Run (Ø§Ù„Ø³Ù‡Ù… Ø§Ù„Ø£Ø®Ø¶Ø±).")
