import streamlit as st
import pandas as pd
import numpy as np
from docx import Document
import tempfile
import os
import re
import math
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="Dynamic SPSS Solver",
    page_icon="ğŸ§ ",
    layout="wide"
)

st.title("ğŸ§  Ù…Ø­Ù„Ù„ SPSS Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
st.markdown("### Ø­Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø£ÙŠ Ø§Ù…ØªØ­Ø§Ù† Ø¥Ø­ØµØ§Ø¦ÙŠ Ù…Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª")

# ===== Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ =====

class DynamicSPSSAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ£ÙŠ Ø£Ø³Ø¦Ù„Ø©"""
    
    def __init__(self, df: pd.DataFrame, questions_text: str):
        self.df = df
        self.questions_text = questions_text
        self.variable_info = self._analyze_variables()
        self.questions = self._parse_questions()
        self.question_mappings = self._build_question_mappings()
        
    def _analyze_variables(self) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"""
        variable_info = {}
        
        for col in self.df.columns:
            col_str = str(col).strip()
            var_data = self.df[col].dropna()
            
            info = {
                'name': col_str,
                'original_name': col_str,
                'dtype': str(self.df[col].dtype),
                'n_unique': len(var_data.unique()),
                'missing': self.df[col].isna().sum(),
                'total': len(self.df[col]),
                'unique_values': sorted(var_data.unique().tolist()) if len(var_data.unique()) <= 20 else [],
                'is_numeric': pd.api.types.is_numeric_dtype(self.df[col])
            }
            
            # Ø§Ù„ØªØ®Ù…ÙŠÙ† Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØºÙŠØ±
            if info['is_numeric']:
                if info['n_unique'] <= 10 and max(var_data.unique()) <= 10:
                    info['stat_type'] = 'CATEGORICAL'
                    info['measurement_level'] = 'NOMINAL'
                else:
                    info['stat_type'] = 'CONTINUOUS'
                    info['measurement_level'] = 'SCALE'
                    info['stats'] = {
                        'mean': float(var_data.mean()),
                        'std': float(var_data.std()),
                        'min': float(var_data.min()),
                        'max': float(var_data.max()),
                        'median': float(var_data.median())
                    }
            else:
                info['stat_type'] = 'STRING'
                info['measurement_level'] = 'NOMINAL'
            
            # ØªØ®Ù…ÙŠÙ† Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…ØªØºÙŠØ± Ù…Ù† Ø§Ø³Ù…Ù‡
            info['inferred_meaning'] = self._infer_variable_meaning(col_str, info)
            
            # ØªØ®Ù…ÙŠÙ† ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù‚ÙŠÙ…
            if info['stat_type'] == 'CATEGORICAL' and info['unique_values']:
                info['value_labels'] = self._guess_value_labels(col_str, info['unique_values'])
            
            variable_info[col_str] = info
        
        return variable_info
    
    def _infer_variable_meaning(self, var_name: str, info: Dict) -> str:
        """ØªØ®Ù…ÙŠÙ† Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…ØªØºÙŠØ± Ù…Ù† Ø§Ø³Ù…Ù‡ ÙˆÙ‚ÙŠÙ…Ù‡"""
        var_lower = var_name.lower()
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
        patterns = {
            'age': ['age', 'Ø¹Ù…Ø±', 'Ø³Ù†', 'Ø§Ù„Ø¹Ù…Ø±'],
            'salary': ['salary', 'Ù…Ø±ØªØ¨', 'Ø±Ø§ØªØ¨', 'Ø¯Ø®Ù„', 'income'],
            'gender': ['gender', 'Ø¬Ù†Ø³', 'sex', 'Ø°ÙƒØ±', 'Ø£Ù†Ø«Ù‰'],
            'city': ['city', 'Ù…Ø¯ÙŠÙ†Ø©', 'Ù…Ø­Ø§ÙØ¸Ø©', 'region'],
            'year': ['year', 'Ø³Ù†Ø©', 'Ø¹Ø§Ù…', 'ØªØ§Ø±ÙŠØ®'],
            'balance': ['balance', 'Ø±ØµÙŠØ¯', 'account'],
            'transaction': ['transaction', 'Ù…Ø¹Ø§Ù…Ù„Ø©', 'Ø¹Ù…Ù„ÙŠØ©'],
            'service': ['service', 'Ø®Ø¯Ù…Ø©'],
            'card': ['card', 'Ø¨Ø·Ø§Ù‚Ø©', 'debit'],
            'interest': ['interest', 'ÙØ§Ø¦Ø¯Ø©'],
            'score': ['score', 'Ø¯Ø±Ø¬Ø©', 'mark'],
            'count': ['count', 'Ø¹Ø¯Ø¯', 'number'],
            'percentage': ['percentage', 'Ù†Ø³Ø¨Ø©', 'percent'],
            'rate': ['rate', 'Ù…Ø¹Ø¯Ù„', 'Ù†Ø³Ø¨Ø©'],
            'category': ['category', 'ÙØ¦Ø©', 'type']
        }
        
        for meaning, keywords in patterns.items():
            for keyword in keywords:
                if keyword in var_lower:
                    return meaning
        
        # Ø§Ù„ØªØ®Ù…ÙŠÙ† Ù…Ù† Ø§Ù„Ù‚ÙŠÙ…
        if info['is_numeric']:
            if info['n_unique'] == 2 and set(info['unique_values']) == {0, 1}:
                return 'binary_indicator'
            elif 0 <= info['n_unique'] <= 5:
                return 'categorical_code'
        
        return 'unknown'
    
    def _guess_value_labels(self, var_name: str, values: List) -> Dict:
        """ØªØ®Ù…ÙŠÙ† ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ¦ÙˆÙŠØ©"""
        var_lower = var_name.lower()
        labels = {}
        
        for val in values:
            if isinstance(val, (int, float)):
                # Ø£Ù†Ù…Ø§Ø· Ø«Ù†Ø§Ø¦ÙŠØ© (Ù†Ø¹Ù…/Ù„Ø§)
                if val == 0:
                    labels[val] = "No/False/Female"
                elif val == 1:
                    labels[val] = "Yes/True/Male"
                elif val == 2:
                    labels[val] = "Other/Sometimes"
                # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¬Ù†Ø³
                elif 'gender' in var_lower or 'sex' in var_lower:
                    if val == 1:
                        labels[val] = "Male"
                    elif val == 2:
                        labels[val] = "Female"
                # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©
                elif any(word in var_lower for word in ['agree', 'satisfy', 'rate']):
                    if val == 1:
                        labels[val] = "Strongly Disagree"
                    elif val == 2:
                        labels[val] = "Disagree"
                    elif val == 3:
                        labels[val] = "Neutral"
                    elif val == 4:
                        labels[val] = "Agree"
                    elif val == 5:
                        labels[val] = "Strongly Agree"
                else:
                    labels[val] = f"Category {val}"
            else:
                labels[val] = str(val)
        
        return labels
    
    def _parse_questions(self) -> List[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ù„Ø£Ø³Ø¦Ù„Ø©"""
        questions = []
        
        # Ø£Ù†Ù…Ø§Ø· Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        patterns = [
            r'(\d+)[\.\)]\s*(.*?)(?=\d+[\.\)]|$)',  # 1. Ø£Ùˆ 1)
            r'Q(\d+)[:\-]\s*(.*?)(?=Q\d+[:\.\-]|$)',  # Q1: Ø£Ùˆ Q1-
            r'Question\s*(\d+)[:\-]\s*(.*?)(?=Question\s*\d+[:\.\-]|$)',  # Question 1:
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, self.questions_text, re.DOTALL | re.IGNORECASE)
            for match in matches:
                q_num = match.group(1).strip()
                q_text = match.group(2).strip()
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
                q_text = re.sub(r'\s+', ' ', q_text)
                q_text = q_text.replace('\n', ' ').strip()
                
                if q_text and len(q_text) > 5:
                    questions.append({
                        'number': int(q_num),
                        'text': q_text[:200],
                        'full_text': q_text,
                        'detected_type': 'unknown'
                    })
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø£Ø³Ø¦Ù„Ø© Ù…Ø±Ù‚Ù…Ø©ØŒ Ù†Ù‚Ø³Ù… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙÙ‚Ø±Ø§Øª
        if not questions:
            paragraphs = self.questions_text.split('\n')
            for i, para in enumerate(paragraphs):
                para = para.strip()
                if para and len(para) > 20:
                    questions.append({
                        'number': i + 1,
                        'text': para[:150],
                        'full_text': para,
                        'detected_type': 'unknown'
                    })
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ ÙƒÙ„ Ø³Ø¤Ø§Ù„
        for q in questions:
            q['detected_type'] = self._detect_question_type(q['full_text'])
            q['variables'] = self._extract_variables_from_text(q['full_text'])
            q['conditions'] = self._extract_conditions(q['full_text'])
            q['analysis_method'] = self._determine_analysis_method(q)
        
        return sorted(questions, key=lambda x: x['number'])
    
    def _detect_question_type(self, text: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        text_lower = text.lower()
        
        type_patterns = {
            'frequency': ['frequency table', 'Ø¬Ø¯ÙˆÙ„ ØªÙƒØ±Ø§Ø±ÙŠ', 'ØªÙˆØ²ÙŠØ¹ ØªÙƒØ±Ø§Ø±ÙŠ', 'construct frequency'],
            'descriptive': ['mean', 'median', 'mode', 'standard deviation', 'Ù…Ù‚Ø§ÙŠÙŠØ³', 'calculate', 'Ø§Ø­Ø³Ø¨'],
            'bar_chart': ['bar chart', 'Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¹Ù…ÙˆØ¯ÙŠ', 'Ù…Ø®Ø·Ø· Ø¹Ù…ÙˆØ¯ÙŠ', 'draw bar'],
            'pie_chart': ['pie chart', 'Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±ÙŠ', 'Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ', 'draw pie'],
            'histogram': ['histogram', 'Ù…Ø¯Ø±Ø¬ ØªÙƒØ±Ø§Ø±ÙŠ', 'Ø±Ø³Ù… Ù…Ø¯Ø±Ø¬'],
            'scatter': ['scatter plot', 'Ù…Ø®Ø·Ø· Ø§Ù†ØªØ´Ø§Ø±', 'Ø±Ø³Ù… Ø§Ù†ØªØ´Ø§Ø±'],
            'boxplot': ['box plot', 'Ù…Ø®Ø·Ø· Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚', 'ØµÙ†Ø¯ÙˆÙ‚ÙŠ'],
            'confidence': ['confidence interval', 'ÙØªØ±Ø© Ø«Ù‚Ø©', 'confidence'],
            't_test': ['t-test', 'Ø§Ø®ØªØ¨Ø§Ø± ØªÙŠ', 't test', 'Ø§Ø®ØªØ¨Ø§Ø± t'],
            'anova': ['anova', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†', 'analysis of variance'],
            'correlation': ['correlation', 'Ø§Ø±ØªØ¨Ø§Ø·', 'Ø¹Ù„Ø§Ù‚Ø©'],
            'regression': ['regression', 'Ø§Ù†Ø­Ø¯Ø§Ø±', 'linear model'],
            'chi_square': ['chi-square', 'ÙƒØ§ÙŠ Ù…Ø±Ø¨Ø¹', 'chi square'],
            'normality': ['normality', 'Ø·Ø¨ÙŠØ¹ÙŠØ©', 'shapiro', 'kolmogorov'],
            'outliers': ['outliers', 'Ù‚ÙŠÙ… Ù…ØªØ·Ø±ÙØ©', 'extreme values'],
            'cross_tab': ['cross tabulation', 'Ø¬Ø¯ÙˆÙ„ Ù…ØªÙ‚Ø§Ø·Ø¹', 'crosstab'],
            'clustering': ['cluster', 'ØªØ¬Ù…ÙŠØ¹', 'grouping'],
            'factor': ['factor analysis', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„'],
            'reliability': ['reliability', 'Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©', 'cronbach'],
        }
        
        for q_type, keywords in type_patterns.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return q_type
        
        return 'descriptive'  # Ø¥ÙØªØ±Ø§Ø¶ÙŠ
    
    def _extract_variables_from_text(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù†Øµ"""
        found_vars = []
        text_lower = text.lower()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø©
        for var_name in self.variable_info.keys():
            var_lower = var_name.lower()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø§Ø³Ù…
            if var_lower in text_lower:
                found_vars.append(var_name)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…Ø³ØªÙ†ØªØ¬
            elif self.variable_info[var_name]['inferred_meaning'] != 'unknown':
                meaning = self.variable_info[var_name]['inferred_meaning']
                meaning_keywords = {
                    'age': ['age', 'Ø¹Ù…Ø±', 'Ø³Ù†'],
                    'salary': ['salary', 'Ù…Ø±ØªØ¨', 'Ø±Ø§ØªØ¨'],
                    'gender': ['gender', 'Ø¬Ù†Ø³', 'Ø°ÙƒØ±', 'Ø£Ù†Ø«Ù‰'],
                    'city': ['city', 'Ù…Ø¯ÙŠÙ†Ø©', 'Ù…Ø­Ø§ÙØ¸Ø©'],
                    'balance': ['balance', 'Ø±ØµÙŠØ¯', 'account'],
                    'transaction': ['transaction', 'Ù…Ø¹Ø§Ù…Ù„Ø©'],
                    'service': ['service', 'Ø®Ø¯Ù…Ø©'],
                    'card': ['card', 'Ø¨Ø·Ø§Ù‚Ø©'],
                    'interest': ['interest', 'ÙØ§Ø¦Ø¯Ø©']
                }
                
                if meaning in meaning_keywords:
                    for keyword in meaning_keywords[meaning]:
                        if keyword in text_lower:
                            found_vars.append(var_name)
                            break
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ù…ØªØºÙŠØ±Ø§ØªØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        if not found_vars:
            # Ù†Ø®ØªØ§Ø± Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
            q_type = self._detect_question_type(text)
            
            if q_type in ['frequency', 'categorical']:
                # Ù…ØªØºÙŠØ±Ø§Øª ÙØ¦ÙˆÙŠØ©
                found_vars = [v for v, info in self.variable_info.items() 
                            if info['stat_type'] == 'CATEGORICAL'][:3]
            elif q_type in ['descriptive', 'continuous']:
                # Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø³ØªÙ…Ø±Ø©
                found_vars = [v for v, info in self.variable_info.items() 
                            if info['stat_type'] == 'CONTINUOUS'][:3]
            else:
                # Ù…Ø²ÙŠØ¬
                categorical_vars = [v for v, info in self.variable_info.items() 
                                  if info['stat_type'] == 'CATEGORICAL'][:2]
                continuous_vars = [v for v, info in self.variable_info.items() 
                                 if info['stat_type'] == 'CONTINUOUS'][:2]
                found_vars = categorical_vars + continuous_vars
        
        return list(set(found_vars))[:5]  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 5 Ù…ØªØºÙŠØ±Ø§Øª
    
    def _extract_conditions(self, text: str) -> List[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ø±ÙˆØ· Ù…Ù† Ø§Ù„Ù†Øµ"""
        conditions = []
        text_lower = text.lower()
        
        # Ø´Ø±ÙˆØ· Ø²Ù…Ù†ÙŠØ©
        time_patterns = [
            (r'before (\d{4})', 'before_year'),
            (r'after (\d{4})', 'after_year'),
            (r'in (\d{4})', 'in_year'),
            (r'from (\d{4}) to (\d{4})', 'between_years')
        ]
        
        # Ø´Ø±ÙˆØ· Ù…Ù‚Ø§Ø±Ù†Ø©
        comp_patterns = [
            (r'greater than (\d+)', 'greater_than'),
            (r'less than (\d+)', 'less_than'),
            (r'equal to (\d+)', 'equal_to'),
            (r'between (\d+) and (\d+)', 'between'),
            (r'more than (\d+)', 'greater_than'),
            (r'at least (\d+)', 'at_least'),
            (r'at most (\d+)', 'at_most')
        ]
        
        # Ø´Ø±ÙˆØ· ÙØ¦ÙˆÙŠØ©
        cat_patterns = [
            (r'male', 'gender_male'),
            (r'female', 'gender_female'),
            (r'yes', 'yes'),
            (r'no', 'no'),
            (r'urban', 'urban'),
            (r'rural', 'rural')
        ]
        
        for pattern, cond_type in time_patterns + comp_patterns + cat_patterns:
            match = re.search(pattern, text_lower)
            if match:
                condition = {'type': cond_type}
                
                if cond_type == 'between_years':
                    condition['value'] = [int(match.group(1)), int(match.group(2))]
                elif cond_type == 'between':
                    condition['value'] = [int(match.group(1)), int(match.group(2))]
                elif match.groups():
                    condition['value'] = int(match.group(1))
                else:
                    condition['value'] = match.group(0)
                
                conditions.append(condition)
        
        return conditions
    
    def _determine_analysis_method(self, question: Dict) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©"""
        q_type = question['detected_type']
        variables = question['variables']
        
        if not variables:
            return 'DESCRIPTIVES'
        
        # Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        var_types = [self.variable_info[v]['stat_type'] for v in variables if v in self.variable_info]
        
        if q_type == 'frequency':
            return 'FREQUENCIES'
        elif q_type == 'descriptive':
            return 'DESCRIPTIVES'
        elif q_type == 'bar_chart':
            if len(variables) >= 2:
                return 'GRAPH_BAR_GROUPED'
            else:
                return 'GRAPH_BAR_SIMPLE'
        elif q_type == 'pie_chart':
            return 'GRAPH_PIE'
        elif q_type == 'histogram':
            return 'GRAPH_HISTOGRAM'
        elif q_type == 't_test':
            if len(variables) >= 2:
                return 'T_TEST_INDEPENDENT'
            else:
                return 'T_TEST_ONE_SAMPLE'
        elif q_type == 'anova':
            return 'ONEWAY_ANOVA'
        elif q_type == 'correlation':
            return 'CORRELATIONS'
        elif q_type == 'regression':
            return 'REGRESSION'
        elif q_type == 'chi_square':
            return 'CROSSTABS_CHISQ'
        else:
            # Ø§Ù„ØªØ®Ù…ÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
            if all(t == 'CONTINUOUS' for t in var_types):
                return 'CORRELATIONS'
            elif all(t == 'CATEGORICAL' for t in var_types):
                return 'CROSSTABS'
            else:
                return 'MEANS'
    
    def _build_question_mappings(self) -> Dict:
        """Ø¨Ù†Ø§Ø¡ Ø®Ø±Ø§Ø¦Ø· Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
        mappings = {
            'frequency_tables': {
                'keywords': ['frequency', 'ØªÙƒØ±Ø§Ø±ÙŠ', 'Ø¬Ø¯ÙˆÙ„'],
                'method': 'FREQUENCIES',
                'template': 'FREQUENCIES VARIABLES={vars}\n  /ORDER=ANALYSIS.'
            },
            'descriptive_stats': {
                'keywords': ['mean', 'median', 'mode', 'Ù…ØªÙˆØ³Ø·', 'ÙˆØ³ÙŠØ·', 'Ù…Ù†ÙˆØ§Ù„'],
                'method': 'DESCRIPTIVES',
                'template': 'DESCRIPTIVES VARIABLES={vars}\n  /STATISTICS=MEAN MEDIAN MODE STDDEV MIN MAX.'
            },
            'compare_groups': {
                'keywords': ['compare', 'Ù…Ù‚Ø§Ø±Ù†Ø©', 'between groups', 'Ø¨ÙŠÙ† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª'],
                'method': 'MEANS',
                'template': 'MEANS TABLES={dv} BY {iv}\n  /CELLS=MEAN COUNT STDDEV.'
            },
            'relationship': {
                'keywords': ['relationship', 'Ø¹Ù„Ø§Ù‚Ø©', 'correlation', 'Ø§Ø±ØªØ¨Ø§Ø·'],
                'method': 'CORRELATIONS',
                'template': 'CORRELATIONS\n  /VARIABLES={vars}\n  /PRINT=TWOTAIL NOSIG.'
            }
        }
        return mappings
    
    def generate_spss_syntax(self) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ"""
        
        syntax = f"""* =========================================================================
* DYNAMIC SPSS SOLUTION GENERATOR
* Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
* Dataset: {len(self.df.columns)} variables, {len(self.df)} cases
* Questions analyzed: {len(self.questions)}
* =========================================================================

DATASET NAME DynamicData WINDOW=FRONT.
DATASET ACTIVATE DynamicData.

* -------------------------------------------------------------------------
* VARIABLE DEFINITION AND PREPARATION
* -------------------------------------------------------------------------

* Variable labels based on inferred meanings\n"""
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        for var_name, info in self.variable_info.items():
            label = info.get('inferred_meaning', var_name).title()
            syntax += f'VARIABLE LABELS {var_name} "{label}".\n'
            syntax += f'VARIABLE LEVEL {var_name} ({info["measurement_level"]}).\n'
            
            if 'value_labels' in info and info['value_labels']:
                syntax += f'VALUE LABELS {var_name}\n'
                for val, lbl in info['value_labels'].items():
                    syntax += f'  {val} "{lbl}"\n'
                syntax += '.\n'
        
        syntax += "\nEXECUTE.\n"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø´ØªÙ‚Ø© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        syntax += self._generate_derived_variables()
        
        # Ø­Ù„ ÙƒÙ„ Ø³Ø¤Ø§Ù„
        syntax += "\n* -------------------------------------------------------------------------"
        syntax += "\n* QUESTION SOLUTIONS"
        syntax += "\n* -------------------------------------------------------------------------\n"
        
        for q in self.questions:
            syntax += self._generate_question_solution(q)
        
        # ØªØ­Ù„ÙŠÙ„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
        syntax += self._generate_auto_analyses()
        
        # Ø¥Ù†Ù‡Ø§Ø¡
        syntax += """
* -------------------------------------------------------------------------
* CLEANUP AND SAVE
* -------------------------------------------------------------------------

DATASET CLOSE ALL.
SAVE OUTFILE='Dynamic_Analysis_Results.sav'
  /COMPRESSED.
EXECUTE.

* ==================== END OF DYNAMIC SOLUTION ====================
"""
        
        return syntax
    
    def _generate_derived_variables(self) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø´ØªÙ‚Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        syntax = "\n* Derived variables for analysis\n"
        
        for var_name, info in self.variable_info.items():
            if info['stat_type'] == 'CONTINUOUS':
                # Ø¥Ù†Ø´Ø§Ø¡ ÙØ¦Ø§Øª Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©
                syntax += f"\n* Creating categories for {var_name}\n"
                syntax += f"IF ({var_name} < {info['stats']['mean']}) {var_name}_Cat = 1.\n"
                syntax += f"IF ({var_name} >= {info['stats']['mean']}) {var_name}_Cat = 2.\n"
                syntax += f"VARIABLE LABELS {var_name}_Cat 'Categories of {var_name}'.\n"
                syntax += f"VALUE LABELS {var_name}_Cat\n"
                syntax += f"  1 'Below Average'\n"
                syntax += f"  2 'Above Average'\n"
                syntax += f".\n"
        
        syntax += "EXECUTE.\n"
        return syntax
    
    def _generate_question_solution(self, question: Dict) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø­Ù„ Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ÙŠÙ†"""
        q_num = question['number']
        q_text = question['text']
        q_type = question['detected_type']
        variables = question['variables']
        method = question['analysis_method']
        
        syntax = f"\n* QUESTION {q_num}: {q_text}\n"
        syntax += f"* Detected Type: {q_type}\n"
        syntax += f"* Variables: {', '.join(variables) if variables else 'Auto-selected'}\n"
        syntax += f"* Method: {method}\n"
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        if method == 'FREQUENCIES':
            if variables:
                syntax += f"FREQUENCIES VARIABLES={' '.join(variables)}\n"
                syntax += "  /BARCHART FREQ\n"
                syntax += "  /ORDER=ANALYSIS.\n"
        
        elif method == 'DESCRIPTIVES':
            if variables:
                syntax += f"DESCRIPTIVES VARIABLES={' '.join(variables)}\n"
                syntax += "  /STATISTICS=MEAN MEDIAN MODE STDDEV MIN MAX SKEWNESS.\n"
        
        elif method == 'GRAPH_BAR_SIMPLE':
            if variables:
                syntax += f"GRAPH\n"
                syntax += f"  /BAR(SIMPLE)=COUNT BY {variables[0]}\n"
                syntax += f"  /TITLE='Bar Chart of {variables[0]}'.\n"
        
        elif method == 'GRAPH_BAR_GROUPED':
            if len(variables) >= 2:
                syntax += f"GRAPH\n"
                syntax += f"  /BAR(GROUPED)=MEAN({variables[1]}) BY {variables[0]}\n"
                syntax += f"  /TITLE='Grouped Bar: {variables[1]} by {variables[0]}'.\n"
        
        elif method == 'GRAPH_PIE':
            if variables:
                syntax += f"GRAPH\n"
                syntax += f"  /PIE=PCT BY {variables[0]}\n"
                syntax += f"  /TITLE='Pie Chart of {variables[0]}'.\n"
        
        elif method == 'GRAPH_HISTOGRAM':
            if variables:
                for var in variables[:2]:
                    if self.variable_info[var]['stat_type'] == 'CONTINUOUS':
                        syntax += f"GRAPH\n"
                        syntax += f"  /HISTOGRAM={var}\n"
                        syntax += f"  /TITLE='Histogram of {var}'.\n"
        
        elif method == 'T_TEST_ONE_SAMPLE':
            if variables:
                syntax += f"T-TEST\n"
                syntax += f"  /TESTVAL=0\n"
                syntax += f"  /VARIABLES={variables[0]}\n"
                syntax += f"  /CRITERIA=CI(.95).\n"
        
        elif method == 'T_TEST_INDEPENDENT':
            if len(variables) >= 2:
                syntax += f"T-TEST GROUPS={variables[0]}\n"
                syntax += f"  /VARIABLES={variables[1]}\n"
                syntax += f"  /CRITERIA=CI(.95).\n"
        
        elif method == 'ONEWAY_ANOVA':
            if len(variables) >= 2:
                syntax += f"ONEWAY {variables[1]} BY {variables[0]}\n"
                syntax += f"  /STATISTICS DESCRIPTIVES\n"
                syntax += f"  /MISSING ANALYSIS.\n"
        
        elif method == 'CORRELATIONS':
            if len(variables) >= 2:
                syntax += f"CORRELATIONS\n"
                syntax += f"  /VARIABLES={' '.join(variables[:4])}\n"
                syntax += f"  /PRINT=TWOTAIL NOSIG.\n"
        
        elif method == 'REGRESSION':
            if len(variables) >= 2:
                syntax += f"REGRESSION\n"
                syntax += f"  /DEPENDENT {variables[0]}\n"
                syntax += f"  /METHOD=ENTER {' '.join(variables[1:3])}\n"
                syntax += f"  /STATISTICS COEFF R ANOVA.\n"
        
        elif method == 'CROSSTABS':
            if len(variables) >= 2:
                syntax += f"CROSSTABS\n"
                syntax += f"  /TABLES={variables[0]} BY {variables[1]}\n"
                syntax += f"  /CELLS=COUNT ROW COLUMN.\n"
        
        elif method == 'MEANS':
            if len(variables) >= 2:
                syntax += f"MEANS TABLES={variables[1]} BY {variables[0]}\n"
                syntax += f"  /CELLS=MEAN COUNT STDDEV.\n"
        
        else:
            # Ø­Ù„ Ø¹Ø§Ù…
            if variables:
                syntax += f"DESCRIPTIVES VARIABLES={' '.join(variables[:3])}\n"
                syntax += f"  /STATISTICS=MEAN STDDEV MIN MAX.\n"
        
        syntax += "EXECUTE.\n"
        return syntax
    
    def _generate_auto_analyses(self) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ©"""
        syntax = "\n* -------------------------------------------------------------------------"
        syntax += "\n* AUTOMATIC ADDITIONAL ANALYSES"
        syntax += "\n* -------------------------------------------------------------------------\n"
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø© ÙˆØ§Ù„ÙØ¦ÙˆÙŠØ©
        continuous_vars = [v for v, info in self.variable_info.items() 
                         if info['stat_type'] == 'CONTINUOUS']
        categorical_vars = [v for v, info in self.variable_info.items() 
                          if info['stat_type'] == 'CATEGORICAL']
        
        # 1. ØªØ­Ù„ÙŠÙ„ ÙˆØµÙÙŠ Ø´Ø§Ù…Ù„
        if continuous_vars:
            syntax += "\n* Comprehensive descriptive analysis\n"
            syntax += f"DESCRIPTIVES VARIABLES={' '.join(continuous_vars[:5])}\n"
            syntax += "  /STATISTICS=MEAN STDDEV MIN MAX SKEWNESS KURTOSIS.\n"
            syntax += "EXECUTE.\n"
        
        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª
        if len(continuous_vars) >= 2:
            syntax += "\n* Correlation matrix\n"
            syntax += f"CORRELATIONS\n"
            syntax += f"  /VARIABLES={' '.join(continuous_vars[:4])}\n"
            syntax += "  /PRINT=TWOTAIL NOSIG.\n"
            syntax += "EXECUTE.\n"
        
        # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        if categorical_vars:
            syntax += "\n* Frequency analysis for categorical variables\n"
            syntax += f"FREQUENCIES VARIABLES={' '.join(categorical_vars[:3])}\n"
            syntax += "  /BARCHART FREQ\n"
            syntax += "  /ORDER=ANALYSIS.\n"
            syntax += "EXECUTE.\n"
        
        # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        if continuous_vars and categorical_vars:
            syntax += "\n* Means comparison by categories\n"
            syntax += f"MEANS TABLES={continuous_vars[0]} BY {categorical_vars[0]}\n"
            syntax += "  /CELLS=MEAN COUNT STDDEV.\n"
            syntax += "EXECUTE.\n"
        
        # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ©
        if continuous_vars:
            syntax += "\n* Outlier detection\n"
            syntax += f"EXAMINE VARIABLES={continuous_vars[0]}\n"
            syntax += "  /PLOT=BOXPLOT\n"
            syntax += "  /STATISTICS=EXTREME\n"
            syntax += "  /NOTOTAL.\n"
            syntax += "EXECUTE.\n"
        
        return syntax

# ===== ÙˆØ§Ø¬Ù‡Ø© Streamlit =====

def main():
    # Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.header("ğŸ“ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª")
        
        # Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©
        uploaded_files = st.file_uploader(
            "Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø©",
            type=['xls', 'xlsx', 'csv', 'docx', 'doc', 'txt'],
            accept_multiple_files=True,
            help="ÙŠÙ…ÙƒÙ†Ùƒ Ø±ÙØ¹ Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª: Excel Ù„Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Word Ù„Ù„Ø£Ø³Ø¦Ù„Ø©"
        )
        
        st.markdown("---")
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù„ÙØ§Øª
        data_file = None
        questions_file = None
        
        if uploaded_files:
            for file in uploaded_files:
                if file.name.lower().endswith(('.xls', '.xlsx', '.csv')):
                    data_file = file
                elif file.name.lower().endswith(('.docx', '.doc', '.txt')):
                    questions_file = file
        
        if data_file:
            st.success(f"ğŸ“Š Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {data_file.name}")
        if questions_file:
            st.success(f"ğŸ“ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©: {questions_file.name}")
        
        st.markdown("---")
        
        # Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
        with st.expander("âš™ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"):
            auto_detect = st.checkbox("Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø·", value=True)
            generate_summary = st.checkbox("ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù…Ù„Ø®Øµ", value=True)
            debug_mode = st.checkbox("ÙˆØ¶Ø¹ Ø§Ù„ØªØµØ­ÙŠØ­", value=False)
        
        analyze_btn = st.button(
            "ğŸ§  ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒØ§Ù…Ù„",
            type="primary",
            use_container_width=True
        )
    
    # Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    st.markdown("""
    ## ğŸ¯ Ù…Ø­Ù„Ù„ SPSS Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
    
    ### ğŸ“‹ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
    
    1. **Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„**: ÙŠØ­Ù„ Ø£ÙŠ Ø£Ø³Ø¦Ù„Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ù…Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª
    2. **ØªØ®Ù…ÙŠÙ† Ø°ÙƒÙŠ**: ÙŠØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙˆÙ…Ø¹Ø§Ù†ÙŠÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    3. **ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ**: ÙŠØ­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„ÙƒÙ„ Ø³Ø¤Ø§Ù„
    4. **Ø¯Ø¹Ù… ÙƒØ§Ù…Ù„**: ÙŠØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
    5. **ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ ÙƒØ§Ù…Ù„**: ÙŠÙˆÙ„Ø¯ ÙƒÙˆØ¯ SPSS Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ´ØºÙŠÙ„
    
    ### ğŸ“Š Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:
    - Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ù‚Ù…ÙŠØ© Ø£Ùˆ ÙØ¦ÙˆÙŠØ©
    - Ø£ÙŠ Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
    - Ø£ÙŠ Ø­Ø¬Ù… Ù„Ù„Ø¹ÙŠÙ†Ø©
    
    ### â“ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:
    - Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙˆØ§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª
    - Ø§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
    - Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
    - Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
    - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±
    - ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
    - Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙƒØ§ÙŠ Ù…Ø±Ø¨Ø¹
    - ÙˆØ§Ù„Ø¹Ø¯ÙŠØ¯ ØºÙŠØ±Ù‡Ø§...
    """)
    
    if uploaded_files and analyze_btn:
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if data_file:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
                    tmp.write(data_file.getvalue())
                    data_path = tmp.name
                
                # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                if data_file.name.lower().endswith('.csv'):
                    df = pd.read_csv(data_path)
                else:
                    df = pd.read_excel(data_path)
                
                os.unlink(data_path)
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
                questions_text = ""
                if questions_file:
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:
                        tmp.write(questions_file.getvalue())
                        questions_path = tmp.name
                    
                    if questions_file.name.lower().endswith(('.docx', '.doc')):
                        doc = Document(questions_path)
                        questions_text = "\n".join([para.text for para in doc.paragraphs])
                    else:
                        with open(questions_path, 'r', encoding='utf-8') as f:
                            questions_text = f.read()
                    
                    os.unlink(questions_path)
                else:
                    questions_text = "No questions file provided. Using automatic question generation."
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ù„Ù„
                with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø©..."):
                    analyzer = DynamicSPSSAnalyzer(df, questions_text)
                    
                    st.success(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ {len(df)} Ø­Ø§Ù„Ø© Ùˆ{len(df.columns)} Ù…ØªØºÙŠØ±")
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª", len(df.columns))
                    with col2:
                        st.metric("Ø§Ù„Ø­Ø§Ù„Ø§Øª", len(df))
                    with col3:
                        st.metric("Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", len(analyzer.questions))
                    
                    # Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
                    with st.expander("ğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"):
                        var_table = []
                        for var_name, info in analyzer.variable_info.items():
                            var_table.append({
                                'Ø§Ù„Ù…ØªØºÙŠØ±': var_name,
                                'Ø§Ù„Ù…Ø¹Ù†Ù‰': info.get('inferred_meaning', 'unknown'),
                                'Ø§Ù„Ù†ÙˆØ¹': info['stat_type'],
                                'Ø§Ù„Ù…Ø³ØªÙˆÙ‰': info['measurement_level'],
                                'Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©': info['n_unique']
                            })
                        st.table(pd.DataFrame(var_table))
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§
                    with st.expander("ğŸ“ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"):
                        for q in analyzer.questions[:10]:
                            st.markdown(f"**{q['number']}. {q['text']}**")
                            st.caption(f"Ø§Ù„Ù†ÙˆØ¹: {q['detected_type']} | Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©: {q['analysis_method']}")
                            if q['variables']:
                                st.caption(f"Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª: {', '.join(q['variables'])}")
                            st.markdown("---")
                    
                    # ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS
                    st.markdown("---")
                    st.subheader("âš™ï¸ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ")
                    
                    with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø­Ù„ Ø§Ù„ÙƒØ§Ù…Ù„..."):
                        spss_code = analyzer.generate_spss_syntax()
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯
                        st.code(spss_code, language='spss')
                        
                        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯
                        st.download_button(
                            label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù SPSS (.sps)",
                            data=spss_code,
                            file_name="Dynamic_SPSS_Solution.sps",
                            mime="text/plain",
                            use_container_width=True
                        )
                        
                        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
                        with st.expander("ğŸ” Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ„Ø¯Ø©"):
                            lines = spss_code.split('\n')
                            analysis_samples = []
                            
                            for line in lines:
                                if any(keyword in line for keyword in [
                                    'FREQUENCIES', 'DESCRIPTIVES', 'GRAPH', 
                                    'T-TEST', 'CORRELATIONS', 'REGRESSION',
                                    'ONEWAY', 'CROSSTABS', 'MEANS'
                                ]):
                                    analysis_samples.append(line.strip())
                                    if len(analysis_samples) >= 15:
                                        break
                            
                            for sample in analysis_samples:
                                st.code(sample, language='spss')
            
            else:
                st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª (Excel/CSV)")
        
        except Exception as e:
            st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
            import traceback
            if st.checkbox("Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ Ù„Ù„ØªØµØ­ÙŠØ­"):
                st.code(traceback.format_exc())

if __name__ == "__main__":
    main()
