import streamlit as st
import pandas as pd
from docx import Document
import re
import io

# Ø¯Ø§Ù„Ø© Ø°ÙƒÙŠØ© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø­ØªÙ‰ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø£Ùˆ Ø§Ù„ØªØ§Ù„ÙØ©
def extract_text_from_upload(doc_upload):
    doc_bytes = doc_upload.read()
    try:
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© Document Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø© docx
        doc = Document(io.BytesIO(doc_bytes))
        return "\n".join([p.text for p in doc.paragraphs])
    except:
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø³Ø­Ø¨ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø®Ø§Ù… Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© doc
        return " ".join(re.findall(r'[ -~]{5,}', doc_bytes.decode('ascii', errors='ignore')))

def master_spss_engine_v20(word_file):
    text = extract_text_from_upload(word_file)
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    
    # Ø¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª X1-X12
    mapping = {}
    var_matches = re.findall(r"([Xx]\d+)\s*=\s*([^(\n\r.]+)", text, re.IGNORECASE)
    for v_name, v_label in var_matches:
        mapping[v_name.upper()] = v_label.strip()

    syntax = ["* --- Final Scientific Solution for SPSS v26 (Universal DS 1,3,4) --- *.\n"]
    for var, lbl in mapping.items():
        syntax.append(f"VARIABLE LABELS {var} '{lbl}'.")
    
    # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø´Ù‡ÙˆØ±Ø©
    syntax.append("VALUE LABELS X4 0 'No' 1 'Yes' /X5 0 'No' 1 'Yes' /X11 1 'Far East' 2 'Europe' 3 'North America'.")
    syntax.append("SET DECIMAL=DOT.\n")

    for line in lines:
        l_low = line.lower()
        if re.search(r"X\d+\s*=", line): continue
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„
        found_vars = [v for v in mapping.keys() if v in line.upper() or mapping[v].lower()[:10] in l_low]
        # ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø±Ø¨Ø· Ù„Ù„Ø±ØµÙŠØ¯ ÙˆØ§Ù„Ø±Ø§ØªØ¨ ÙˆØ§Ù„Ø³Ø¹Ø§Ø¯Ø© (Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© ÙÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬)
        if "balance" in l_low: found_vars.append("X1")
        if "salary" in l_low: found_vars.append("X3")
        if "happiness" in l_low: found_vars.append("X5")
        found_vars = list(dict.fromkeys(found_vars))

        if not found_vars and "normality" not in l_low and "regression" not in l_low: continue
        
        syntax.append(f"\n* QUESTION: {line}.")

        # 1. ÙØªØ±Ø§Øª Ø§Ù„Ø«Ù‚Ø© (95% Ùˆ 99% - Ø·Ù„Ø¨ Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø­Ù…Ø¯)
        if "confidence interval" in l_low:
            for val in ["95", "99"]:
                syntax.append(f"EXAMINE VARIABLES={' '.join(found_vars) if found_vars else 'X1'} /STATISTICS DESCRIPTIVES /CINTERVAL {val} /PLOT NONE.")

        # 2. ØªØµØ­ÙŠØ­ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© (Ù…Ù†Ø¹ Ø§Ù„Ø®Ø·Ø£ 701)
        elif "bar chart" in l_low:
            stat = "MEAN" if "average" in l_low else "MAX" if "maximum" in l_low else "PCT" if "percentage" in l_low else "COUNT"
            if len(found_vars) >= 2:
                syntax.append(f"GRAPH /BAR(SIMPLE)={stat}({found_vars[0]}) BY {found_vars[1]}.")
            else:
                syntax.append(f"GRAPH /BAR(SIMPLE)={stat} BY {found_vars[0] if found_vars else 'X1'}.")

        # 3. Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± ÙˆØ§Ù„Ø§Ø±ØªØ¨Ø§Ø· (Ù†Ù…Ø§Ø°Ø¬ DS 3, 4)
        elif "regression" in l_low or "y = f(" in l_low:
            syntax.append("REGRESSION /STATISTICS COEFF OUTS R ANOVA /DEPENDENT X5 /METHOD=ENTER X1 X2 X3 X4 X6 X7 X8 X9 X10 X11 X12.")
        elif "correlation" in l_low:
            syntax.append(f"CORRELATIONS /VARIABLES={' '.join(found_vars[:2])} /PRINT=TWOTAIL NOSIG.")

        # 4. Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Classes & K-rule)
        elif "classes" in l_low or "k rule" in l_low:
            target = "X1" if "balance" in l_low else "X3" if "salary" in l_low else found_vars[0]
            syntax.append(f"RECODE {target} (LO thru HI=COPY) INTO {target}_Classes.\nFREQUENCIES VARIABLES={target}_Classes.")

        # 5. Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ ÙˆØ§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©
        elif "normality" in l_low:
            syntax.append(f"EXAMINE VARIABLES={' '.join(found_vars)} /PLOT NPPLOT /STATISTICS DESCRIPTIVES.")
        elif "outliers" in l_low:
            syntax.append(f"EXAMINE VARIABLES={found_vars[0] if found_vars else 'X1'} /PLOT BOXPLOT /STATISTICS DESCRIPTIVES /EXTREME(5).")

        # 6. Ø§Ù„ÙˆØµÙ Ø§Ù„Ø¹Ø§Ù… ÙˆØ§Ù„ØªÙ‚Ø³ÙŠÙ…
        elif "for each" in l_low or "split" in l_low:
            split_v = found_vars[-1] if found_vars else "X6"
            syntax.append(f"SORT CASES BY {split_v}.\nSPLIT FILE SEPARATE BY {split_v}.\nFREQUENCIES VARIABLES={' '.join(found_vars[:-1]) if len(found_vars)>1 else 'X1 X2'} /STATISTICS=MEAN MEDIAN MODE.\nSPLIT FILE OFF.")
        elif any(w in l_low for w in ["mean", "median", "frequency table"]):
            syntax.append(f"FREQUENCIES VARIABLES={' '.join(found_vars)} /STATISTICS=MEAN MEDIAN MODE STDDEV SKEWNESS.")

    syntax.append("\nEXECUTE.")
    return "\n".join(syntax)

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.set_page_config(page_title="SPSS Master Engine", layout="wide")
st.title("ğŸ“Š Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø­Ù…Ø¯ (DS 1, 3, 4)")

u_excel = st.file_uploader("1. Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³ÙŠÙ„", type=['xlsx', 'xls', 'csv'])
u_word = st.file_uploader("2. Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„ÙˆÙˆØ±Ø¯ (Ø§Ù„Ø£Ø³Ø¦Ù„Ø©)", type=['docx', 'doc'])

if u_excel and u_word:
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ø¹Ø§ÙŠÙ†Ø© ÙÙ‚Ø·
        df = pd.read_csv(u_excel) if u_excel.name.endswith('.csv') else pd.read_excel(u_excel)
        st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ({len(df)} Ø³Ø¬Ù„).")
        
        final_syntax = master_spss_engine_v20(u_word)
        st.subheader("Ø§Ù„Ø³ÙŠÙ†ØªØ§ÙƒØ³ Ø§Ù„Ù†Ø§ØªØ¬:")
        st.code(final_syntax, language='spss')
        
        st.download_button("ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†ØªØ§ÙƒØ³ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (.sps)", final_syntax, "Final_Analysis_Ready.sps")
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
