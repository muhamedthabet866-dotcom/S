import streamlit as st
import pandas as pd
import numpy as np
import re
import base64
from datetime import datetime
from io import BytesIO

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="Ù…ÙˆÙ„Ø¯ Ø£ÙƒÙˆØ§Ø¯ SPSS Ø§Ù„Ø¹Ø§Ù…",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Ù…Ø®ØµØµ
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .success-box {
        background-color: #D1FAE5;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #10B981;
        margin-bottom: 1rem;
    }
    .code-box {
        background-color: #1E293B;
        color: #E2E8F0;
        padding: 1rem;
        border-radius: 5px;
        font-family: 'Courier New', monospace;
        overflow-x: auto;
        white-space: pre-wrap;
    }
    .stButton>button {
        background-color: #3B82F6;
        color: white;
        font-weight: bold;
        border-radius: 5px;
        border: none;
        padding: 0.5rem 1rem;
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

class UniversalSPSSGenerator:
    def __init__(self):
        self.analysis_templates = {
            'frequency': self._generate_frequency_code,
            'descriptive': self._generate_descriptive_code,
            'histogram': self._generate_histogram_code,
            'bar_chart': self._generate_bar_chart_code,
            'pie_chart': self._generate_pie_chart_code,
            'confidence': self._generate_confidence_code,
            't_test': self._generate_ttest_code,
            'anova': self._generate_anova_code,
            'correlation': self._generate_correlation_code,
            'regression': self._generate_regression_code,
            'outliers': self._generate_outliers_code,
            'normality': self._generate_normality_code
        }
    
    def detect_analysis_type(self, question):
        """Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['frequency', 'ØªÙƒØ±Ø§Ø±', 'Ø¬Ø¯ÙˆÙ„ ØªÙƒØ±Ø§Ø±', 'distribution']):
            return 'frequency'
        elif any(word in question_lower for word in ['mean', 'median', 'mode', 'standard deviation', 'Ø¥Ø­ØµØ§Ø¡Ø§Øª', 'Ù…ØªÙˆØ³Ø·', 'ÙˆØ³ÙŠØ·', 'Ù…Ù†ÙˆØ§Ù„']):
            return 'descriptive'
        elif any(word in question_lower for word in ['histogram', 'Ù‡ÙŠØ³ØªÙˆØ¬Ø±Ø§Ù…', 'Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ']):
            return 'histogram'
        elif any(word in question_lower for word in ['bar chart', 'Ø±Ø³Ù… Ø¹Ù…ÙˆØ¯ÙŠ', 'Ø±Ø³Ù… Ø£Ø¹Ù…Ø¯Ø©', 'Ø¹Ù…ÙˆØ¯ÙŠ']):
            return 'bar_chart'
        elif any(word in question_lower for word in ['pie chart', 'Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±ÙŠ', 'Ø¯Ø§Ø¦Ø±ÙŠ', 'Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©']):
            return 'pie_chart'
        elif any(word in question_lower for word in ['confidence interval', 'ÙØªØ±Ø© Ø«Ù‚Ø©', 'Ø«Ù‚Ø©']):
            return 'confidence'
        elif any(word in question_lower for word in ['t-test', 't test', 'Ø§Ø®ØªØ¨Ø§Ø± t', 'Ø§Ø®ØªØ¨Ø§Ø± ÙØ±Ø¶ÙŠØ©', 'hypothesis']):
            return 't_test'
        elif any(word in question_lower for word in ['anova', 'Ø£Ù†ÙˆÙØ§', 'ØªØ­Ù„ÙŠÙ„ ØªØ¨Ø§ÙŠÙ†']):
            return 'anova'
        elif any(word in question_lower for word in ['correlation', 'Ø§Ø±ØªØ¨Ø§Ø·', 'Ø¹Ù„Ø§Ù‚Ø©']):
            return 'correlation'
        elif any(word in question_lower for word in ['regression', 'Ø§Ù†Ø­Ø¯Ø§Ø±', 'Ø®Ø·ÙŠ']):
            return 'regression'
        elif any(word in question_lower for word in ['outliers', 'Ù‚ÙŠÙ… Ù…ØªØ·Ø±ÙØ©', 'Ø´Ø§Ø°Ø©']):
            return 'outliers'
        elif any(word in question_lower for word in ['normality', 'Ø·Ø¨ÙŠØ¹ÙŠ', 'Ø´Ø§Ø¨ÙŠØ±Ùˆ', 'Ù†ÙˆØ±Ù…']):
            return 'normality'
        
        return 'descriptive'  # Ø§ÙØªØ±Ø§Ø¶ÙŠ
    
    def analyze_dataframe(self, df):
        """ØªØ­Ù„ÙŠÙ„ DataFrame Ù„ØªØ­Ø¯ÙŠØ¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"""
        variable_info = []
        
        for col in df.columns:
            var_info = {
                'name': col,
                'dtype': str(df[col].dtype),
                'unique_values': df[col].nunique(),
                'missing': df[col].isnull().sum(),
                'type': self._detect_variable_type(df[col])
            }
            variable_info.append(var_info)
        
        return variable_info
    
    def _detect_variable_type(self, series):
        """Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØºÙŠØ±"""
        n_unique = series.nunique()
        
        if series.dtype in ['int64', 'float64']:
            if n_unique <= 10:
                return 'categorical_numeric'
            else:
                return 'continuous'
        elif series.dtype == 'object':
            if n_unique <= 10:
                return 'categorical_text'
            else:
                return 'text'
        elif series.dtype == 'bool':
            return 'binary'
        else:
            return 'other'
    
    def parse_questions(self, text_content):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"""
        questions = []
        lines = text_content.split('\n')
        current_q = ""
        
        for line in lines:
            line = line.strip()
            # Ø§ÙƒØªØ´Ø§Ù Ø³Ø¤Ø§Ù„ Ù…Ø±Ù‚Ù…
            if re.match(r'^\d+[\.\)]', line) or re.match(r'^\d+\.\s+', line):
                if current_q:
                    questions.append(current_q.strip())
                current_q = line
            elif current_q and line and not line.startswith('*'):
                current_q += " " + line
        
        if current_q:
            questions.append(current_q.strip())
        
        return [q for q in questions if q and len(q) > 5]
    
    def generate_spss_code(self, questions, df, dataset_name="Dataset"):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS Ø¹Ø§Ù…"""
        code = f"""* Encoding: UTF-8.
* =========================================================================.
* SPSS Syntax for: {dataset_name}
* Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
* Total Questions: {len(questions)}
* Total Variables: {len(df.columns)}
* Software: IBM SPSS Statistics
* =========================================================================.

"""
        
        # ØªÙˆÙ„ÙŠØ¯ ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        code += self._generate_variable_labels(df)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø³Ø¤Ø§Ù„
        for i, question in enumerate(questions, 1):
            code += self._process_question(i, question, df)
        
        return code
    
    def _generate_variable_labels(self, df):
        """ØªÙˆÙ„ÙŠØ¯ ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        code = "* --- [VARIABLE LABELS] --- .\n"
        code += "* Auto-generated variable labels based on column names\n"
        code += "VARIABLE LABELS\n"
        
        for i, col in enumerate(df.columns):
            label = col.replace('_', ' ').title()
            code += f"    {col} '{label}'"
            if i < len(df.columns) - 1:
                code += " /"
            code += "\n"
        
        # ØªÙˆÙ„ÙŠØ¯ ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù‚ÙŠÙ… Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©
        categorical_vars = []
        for col in df.columns:
            if df[col].nunique() <= 10 and df[col].dtype in ['int64', 'float64']:
                categorical_vars.append(col)
        
        if categorical_vars:
            code += "\n* Value labels for categorical variables\n"
            for var in categorical_vars:
                code += f"* VALUE LABELS {var} ...\n"
                code += f"*   (Add specific value labels for {var})\n"
        
        code += "\nEXECUTE.\n\n"
        return code
    
    def _process_question(self, q_num, question, df):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø¤Ø§Ù„ Ù…Ø­Ø¯Ø¯"""
        code = f"""* -------------------------------------------------------------------------.
* QUESTION {q_num}: {question[:80]}{'...' if len(question) > 80 else ''}
* -------------------------------------------------------------------------.

"""
        
        analysis_type = self.detect_analysis_type(question)
        
        if analysis_type in self.analysis_templates:
            code += self.analysis_templates[analysis_type](question, df)
        else:
            code += self._generate_default_code(question, df)
        
        return code
    
    def _generate_frequency_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±"""
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„
        vars_to_analyze = self._extract_variables_from_question(question, df)
        
        if not vars_to_analyze:
            vars_to_analyze = list(df.columns)[:3]  # Ø£ÙˆÙ„ 3 Ù…ØªØºÙŠØ±Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
        
        code = f"""* Frequency tables for: {', '.join(vars_to_analyze[:3])}
FREQUENCIES VARIABLES={', '.join(vars_to_analyze[:3])}
  /ORDER=ANALYSIS
  /BARCHART FREQ
  /PIECHART PERCENT
  /FORMAT=AVALUE
  /STATISTICS=MEAN MEDIAN MODE.

"""
        return code
    
    def _generate_descriptive_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©"""
        vars_to_analyze = self._extract_variables_from_question(question, df)
        
        if not vars_to_analyze:
            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
            numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
            vars_to_analyze = numeric_vars[:3] if numeric_vars else list(df.columns)[:3]
        
        code = f"""* Descriptive statistics for: {', '.join(vars_to_analyze[:3])}
DESCRIPTIVES VARIABLES={', '.join(vars_to_analyze[:3])}
  /STATISTICS=MEAN MEDIAN MODE STDDEV VARIANCE RANGE MIN MAX 
  KURTOSIS SKEWNESS SEMEAN.

"""
        return code
    
    def _generate_histogram_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„Ù‡ÙŠØ³ØªÙˆØ¬Ø±Ø§Ù…"""
        vars_to_analyze = self._extract_variables_from_question(question, df)
        
        if not vars_to_analyze:
            numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
            vars_to_analyze = numeric_vars[:2] if numeric_vars else list(df.columns)[:2]
        
        code = ""
        for var in vars_to_analyze[:2]:
            code += f"""GRAPH /HISTOGRAM(NORMAL)={var}
  /TITLE='Histogram of {var}'.

"""
        return code
    
    def _generate_bar_chart_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠØ©"""
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªØºÙŠØ± Ù…Ø³ØªÙ‚Ù„ ÙˆÙ…ØªØºÙŠØ± ØªØ§Ø¨Ø¹
        parts = question.lower().split()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø±Ù†Ø©
        compare_words = ['by', 'per', 'for each', 'across', 'between']
        categorical_vars = [col for col in df.columns if df[col].nunique() <= 10]
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if categorical_vars and numeric_vars:
            cat_var = categorical_vars[0]
            num_var = numeric_vars[0]
            
            code = f"""* Bar chart: {num_var} by {cat_var}
GRAPH /BAR(SIMPLE)=MEAN({num_var}) BY {cat_var}
  /TITLE='Average {num_var} by {cat_var}'.

"""
        else:
            code = "* Bar chart analysis\n"
            code += "* GRAPH /BAR(SIMPLE)=MEAN(Variable) BY CategoryVariable.\n\n"
        
        return code
    
    def _generate_pie_chart_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¯Ø§Ø¦Ø±ÙŠØ©"""
        categorical_vars = [col for col in df.columns if df[col].nunique() <= 10]
        
        if categorical_vars:
            var = categorical_vars[0]
            code = f"""* Pie chart for {var}
GRAPH /PIE=PCT BY {var}
  /TITLE='Percentage Distribution of {var}'.

"""
        else:
            code = "* Pie chart analysis\n"
            code += "* GRAPH /PIE=PCT BY CategoryVariable.\n\n"
        
        return code
    
    def _generate_confidence_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ ÙØªØ±Ø§Øª Ø§Ù„Ø«Ù‚Ø©"""
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if numeric_vars:
            var = numeric_vars[0]
            code = f"""* 95% and 99% Confidence Intervals for {var}
EXAMINE VARIABLES={var}
  /PLOT NONE
  /STATISTICS DESCRIPTIVES
  /CINTERVAL 95.

EXAMINE VARIABLES={var}
  /PLOT NONE
  /STATISTICS DESCRIPTIVES
  /CINTERVAL 99.

"""
        else:
            code = "* Confidence interval analysis\n"
            code += "* EXAMINE VARIABLES=Variable /STATISTICS DESCRIPTIVES /CINTERVAL 95 99.\n\n"
        
        return code
    
    def _generate_ttest_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ø®ØªØ¨Ø§Ø± t"""
        question_lower = question.lower()
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù„Ø¹ÙŠÙ†Ø© ÙˆØ§Ø­Ø¯Ø©
        if any(word in question_lower for word in ['equal', '=', 'Ù…Ù‚Ø§Ø±Ù†Ø©', 'Ù‚ÙŠÙ…Ø©']):
            numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_vars:
                var = numeric_vars[0]
                code = f"""* One-sample t-test for {var}
* H0: Î¼ = TestValue, H1: Î¼ â‰  TestValue
T-TEST /TESTVAL=TestValue /VARIABLES={var}
  /MISSING=ANALYSIS /CRITERIA=CI(.95).

* Replace 'TestValue' with actual hypothesized value

"""
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù„Ø¹ÙŠÙ†ØªÙŠÙ† Ù…Ø³ØªÙ‚Ù„ØªÙŠÙ†
        elif any(word in question_lower for word in ['between', 'groups', 'Ù…Ù‚Ø§Ø±Ù†Ø©', 'Ù…Ø¬Ù…ÙˆØ¹ØªÙŠÙ†']):
            categorical_vars = [col for col in df.columns if df[col].nunique() == 2]
            numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
            
            if categorical_vars and numeric_vars:
                group_var = categorical_vars[0]
                test_var = numeric_vars[0]
                
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©
                unique_vals = df[group_var].dropna().unique()
                if len(unique_vals) >= 2:
                    val1, val2 = unique_vals[:2]
                    code = f"""* Independent samples t-test
* Comparing {test_var} between {group_var} groups
T-TEST GROUPS={group_var}({val1} {val2})
  /VARIABLES={test_var}
  /MISSING=ANALYSIS /CRITERIA=CI(.95).

"""
        
        return code if 'code' in locals() else "* T-test analysis required\n"
    
    def _generate_anova_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ ANOVA"""
        categorical_vars = [col for col in df.columns if df[col].nunique() > 2 and df[col].nunique() <= 10]
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if categorical_vars and numeric_vars:
            group_var = categorical_vars[0]
            test_var = numeric_vars[0]
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ…
            unique_vals = df[group_var].dropna().unique()
            min_val, max_val = min(unique_vals), max(unique_vals)
            
            code = f"""* One-way ANOVA
* Testing differences in {test_var} across {group_var} groups
ONEWAY {test_var} BY {group_var}({min_val}, {max_val})
  /STATISTICS DESCRIPTIVES HOMOGENEITY
  /MISSING ANALYSIS
  /POSTHOC=TUKEY LSD ALPHA(0.05).

"""
        else:
            code = "* ANOVA analysis\n"
            code += "* ONEWAY DependentVar BY GroupVar(1, N) /STATISTICS DESCRIPTIVES.\n\n"
        
        return code
    
    def _generate_correlation_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·"""
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_vars) >= 2:
            vars_list = numeric_vars[:3]
            code = f"""* Correlation analysis between {', '.join(vars_list)}
CORRELATIONS /VARIABLES={', '.join(vars_list)}
  /PRINT=TWOTAIL NOSIG
  /MISSING=PAIRWISE.

"""
        else:
            code = "* Correlation analysis\n"
            code += "* CORRELATIONS /VARIABLES=Var1 Var2 /PRINT=TWOTAIL.\n\n"
        
        return code
    
    def _generate_regression_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±"""
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_vars) >= 2:
            dependent = numeric_vars[0]
            independents = numeric_vars[1:min(5, len(numeric_vars))]
            
            code = f"""* Multiple Linear Regression
* Dependent variable: {dependent}
* Independent variables: {', '.join(independents)}
REGRESSION
  /MISSING LISTWISE
  /STATISTICS COEFF OUTS R ANOVA
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN
  /DEPENDENT {dependent}
  /METHOD=ENTER {' '.join(independents)}.

"""
        else:
            code = "* Regression analysis\n"
            code += "* REGRESSION /DEPENDENT Y /METHOD=ENTER X1 X2.\n\n"
        
        return code
    
    def _generate_outliers_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ©"""
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if numeric_vars:
            var = numeric_vars[0]
            code = f"""* Outlier detection for {var}
EXAMINE VARIABLES={var}
  /PLOT=BOXPLOT
  /STATISTICS=EXTREME
  /MISSING LISTWISE
  /NOTOTAL.

* Z-scores method
DESCRIPTIVES VARIABLES={var}
  /SAVE.
* This creates Z{var} variable (Z-scores)
* Cases with |Z{var}| > 3 are extreme outliers

"""
        else:
            code = "* Outlier detection analysis\n"
            code += "* EXAMINE VARIABLES=Variable /PLOT=BOXPLOT /STATISTICS=EXTREME.\n\n"
        
        return code
    
    def _generate_normality_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª normality"""
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if numeric_vars:
            var = numeric_vars[0]
            code = f"""* Normality tests for {var}
EXAMINE VARIABLES={var}
  /PLOT=NPPLOT HISTOGRAM
  /STATISTICS DESCRIPTIVES.

* Interpretation:
* - If Shapiro-Wilk p > 0.05: Data is normally distributed
* - If Shapiro-Wilk p â‰¤ 0.05: Data is not normally distributed

"""
        else:
            code = "* Normality test analysis\n"
            code += "* EXAMINE VARIABLES=Variable /PLOT=NPPLOT.\n\n"
        
        return code
    
    def _generate_default_code(self, question, df):
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§ÙØªØ±Ø§Ø¶ÙŠ"""
        code = f"""* Analysis for: {question[:50]}...
* Automatic analysis based on question content

"""
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ø£ÙØ¶Ù„ ØªØ­Ù„ÙŠÙ„
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_vars = [col for col in df.columns if df[col].nunique() <= 10]
        
        if numeric_vars:
            code += "* Suggested analysis for numeric variables:\n"
            code += f"DESCRIPTIVES VARIABLES={', '.join(numeric_vars[:3])}\n"
            code += "  /STATISTICS=MEAN STDDEV MIN MAX.\n\n"
        
        if categorical_vars:
            code += "* Suggested analysis for categorical variables:\n"
            code += f"FREQUENCIES VARIABLES={', '.join(categorical_vars[:3])}\n"
            code += "  /ORDER=ANALYSIS /BARCHART FREQ.\n\n"
        
        return code
    
    def _extract_variables_from_question(self, question, df):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„"""
        question_lower = question.lower()
        found_vars = []
        
        for col in df.columns:
            col_lower = col.lower()
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„
            if col_lower in question_lower or col in question:
                found_vars.append(col)
        
        return found_vars

# ØªØ·Ø¨ÙŠÙ‚ Streamlit Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
def main():
    st.title("ğŸŒ Ù…ÙˆÙ„Ø¯ Ø£ÙƒÙˆØ§Ø¯ SPSS Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ")
    st.markdown("### Ù„Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ£ÙŠ Ø£Ø³Ø¦Ù„Ø© - Ù„ÙƒÙ„ Ø§Ù„Ù†Ø§Ø³ ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…!")
    
    generator = UniversalSPSSGenerator()
    
    # Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
    st.markdown("---")
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)")
        excel_file = st.file_uploader(
            "Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel Ø¨Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª",
            type=['xls', 'xlsx', 'csv'],
            key="excel_uploader"
        )
    
    with col2:
        st.subheader("ğŸ“ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Text)")
        questions_file = st.file_uploader(
            "Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø£ÙŠ Ù„ØºØ©",
            type=['txt', 'doc', 'docx'],
            key="questions_uploader"
        )
    
    # Ø¥Ø°Ø§ ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
    if excel_file and questions_file:
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if excel_file.name.endswith('.csv'):
                df = pd.read_csv(excel_file)
            else:
                df = pd.read_excel(excel_file)
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
            if questions_file.name.endswith('.txt'):
                questions_text = questions_file.getvalue().decode('utf-8', errors='ignore')
            else:
                # Ù„Ù…Ù„ÙØ§Øª WordØŒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù…
                questions_text = str(questions_file.getvalue())
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
            questions = generator.parse_questions(questions_text)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
            
            col_info1, col_info2, col_info3 = st.columns(3)
            with col_info1:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", len(questions))
            with col_info2:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª", len(df.columns))
            with col_info3:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ", len(df))
            
            # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with st.expander("ğŸ‘ï¸ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (5 ØµÙÙˆÙ Ø£ÙˆÙ„Ù‰)"):
                st.dataframe(df.head())
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
            with st.expander("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"):
                var_info = generator.analyze_dataframe(df)
                for info in var_info:
                    st.write(f"**{info['name']}**: {info['type']} ({info['dtype']}) - Ù‚ÙŠÙ… ÙØ±ÙŠØ¯Ø©: {info['unique_values']}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
            with st.expander("ğŸ“‹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø­Ù„Ù„Ø©"):
                for i, q in enumerate(questions[:10], 1):
                    st.write(f"**{i}.** {q}")
                if len(questions) > 10:
                    st.write(f"... Ùˆ{len(questions)-10} Ø£Ø³Ø¦Ù„Ø© Ø£Ø®Ø±Ù‰")
            
            # Ø²Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯
            st.markdown("---")
            if st.button("ğŸš€ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS ÙƒØ§Ù…Ù„", type="primary", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯..."):
                    dataset_name = excel_file.name.split('.')[0]
                    spss_code = generator.generate_spss_code(questions, df, dataset_name)
                    
                    # Ø­ÙØ¸ Ø§Ù„ÙƒÙˆØ¯
                    generator.generated_code = spss_code
                    
                    st.success(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS Ù„Ù€ {len(questions)} Ø³Ø¤Ø§Ù„!")
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯
                    st.subheader("ğŸ“‹ ÙƒÙˆØ¯ SPSS Ø§Ù„Ù…ÙÙ†Ø´Ø£")
                    st.code(spss_code, language='text')
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø§Ù„ØªÙ†Ø²ÙŠÙ„
                    b64 = base64.b64encode(spss_code.encode()).decode()
                    download_link = f'<a href="data:file/txt;base64,{b64}" download="SPSS_Universal_Code.sps" style="color: white; background-color: #3B82F6; padding: 10px 20px; border-radius: 5px; text-decoration: none; font-weight: bold;">ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ÙƒÙˆØ¯ SPSS</a>'
                    st.markdown(download_link, unsafe_allow_html=True)
                    
                    # Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
                    with st.expander("ğŸ’¡ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙˆØ¯"):
                        st.markdown("""
                        **Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ´ØºÙŠÙ„:**
                        1. **Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù** Ø¨Ø§Ù…ØªØ¯Ø§Ø¯ `.sps`
                        2. **ÙØªØ­ SPSS** ÙˆØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ
                        3. **Ù†Ø³Ø® Ø§Ù„ÙƒÙˆØ¯** Ø¥Ù„Ù‰ Ù…Ø­Ø±Ø± Ø¨Ù†Ø§Ø¡ Ø¬Ù…Ù„Ø© SPSS
                        4. **ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯** ÙƒØ§Ù…Ù„Ø§Ù‹ (Ctrl+A Ø«Ù… F5)
                        5. **Ø§Ù„ØªØ­Ù‚Ù‚** Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù†Ø§ÙØ°Ø© Viewer
                        
                        **Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©:**
                        - Ø§Ù„ÙƒÙˆØ¯ ÙŠØ¹Ù…Ù„ Ù…Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ£ÙŠ Ø£Ø³Ø¦Ù„Ø©
                        - ÙŠØªÙƒÙŠÙ Ù…Ø¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
                        - ÙŠÙˆÙØ± ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…Ù†Ø§Ø³Ø¨Ø© Ù„ÙƒÙ„ Ø³Ø¤Ø§Ù„
                        - Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ SPSS V20+
                        """)
        
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª: {str(e)}")
            st.info("ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ù„ÙØ§Øª (Excel/CSV Ù„Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ù†Øµ Ù„Ù„Ø£Ø³Ø¦Ù„Ø©)")
    
    else:
        # ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨
        st.info("""
        ## ğŸŒŸ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ Ø§Ù„Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ù„Ø£ÙƒÙˆØ§Ø¯ SPSS
        
        **ÙƒÙŠÙ ÙŠØ¹Ù…Ù„:**
        1. **Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª** (Excel Ø£Ùˆ CSV)
        2. **Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø£Ø³Ø¦Ù„Ø©** (Ù†Øµ Ø£Ùˆ Word)
        3. **Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± "ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS"**
        4. **Ù‚Ù… Ø¨ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯** ÙˆØ§ÙØªØ­Ù‡ ÙÙŠ SPSS
        
        **Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø¯:**
        - âœ… ÙŠØ¹Ù…Ù„ Ù…Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø£ÙŠ Ù…ØµØ¯Ø±
        - âœ… ÙŠÙÙ‡Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø£ÙŠ Ù„ØºØ©
        - âœ… ÙŠÙˆÙ„Ø¯ Ø£ÙƒÙˆØ§Ø¯ SPSS ØµØ­ÙŠØ­Ø© 100%
        - âœ… Ù…Ø¬Ø§Ù†ÙŠ ÙˆØ³Ù‡Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        - âœ… Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Ø®Ø¨Ø±Ø© ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©
        
        **Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:**
        - Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
        - Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© (Ø£Ø¹Ù…Ø¯Ø©ØŒ Ø¯Ø§Ø¦Ø±ÙŠØŒ Ù‡ÙŠØ³ØªÙˆØ¬Ø±Ø§Ù…)
        - Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª (t-test, ANOVA)
        - Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ
        - Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ©
        - Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª normality
        """)
        
        # Ø£Ù…Ø«Ù„Ø©
        with st.expander("ğŸ“š Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©"):
            col_ex1, col_ex2 = st.columns(2)
            
            with col_ex1:
                st.markdown("**Ù…Ø«Ø§Ù„ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª (Excel):**")
                st.code("""Customer_ID, Age, Income, Gender, City
1, 25, 35000, M, Cairo
2, 32, 45000, F, Alexandria
3, 41, 52000, M, Giza
4, 28, 38000, F, Luxor
5, 35, 49000, M, Aswan""")
            
            with col_ex2:
                st.markdown("**Ù…Ø«Ø§Ù„ Ù…Ù„Ù Ø£Ø³Ø¦Ù„Ø© (Text):**")
                st.code("""1. Calculate mean and standard deviation of Income
2. Create frequency table for Gender
3. Draw histogram for Age
4. Compare Income between males and females
5. Test if average Age is 30 years
6. Check correlation between Age and Income""")
        
        with st.expander("ğŸŒ Ù„ØºØ§Øª Ù…Ø¯Ø¹ÙˆÙ…Ø©"):
            st.markdown("""
            **Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ø£ÙŠ Ù„ØºØ©:**
            - Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© âœ“
            - Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© âœ“
            - Ø§Ù„ÙØ±Ù†Ø³ÙŠØ© âœ“
            - Ø§Ù„Ø£Ø³Ø¨Ø§Ù†ÙŠØ© âœ“
            - Ø£ÙŠ Ù„ØºØ© Ø£Ø®Ø±Ù‰ âœ“
            
            **Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙÙˆÙ„Ø¯ ÙŠÙƒÙˆÙ† Ø¯Ø§Ø¦Ù…Ø§Ù‹:** Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ù„ØºØ© SPSS Ø§Ù„Ø±Ø³Ù…ÙŠØ©)
            """)

if __name__ == "__main__":
    main()
