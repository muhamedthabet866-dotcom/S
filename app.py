import streamlit as st
import pandas as pd
import numpy as np
from docx import Document
import tempfile
import os
import re
import math
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="Dynamic SPSS Solver",
    page_icon="ğŸ§ ",
    layout="wide"
)

st.title("ğŸ§  Ù…Ø­Ù„Ù„ SPSS Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
st.markdown("### Ø­Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø£ÙŠ Ø§Ù…ØªØ­Ø§Ù† Ø¥Ø­ØµØ§Ø¦ÙŠ Ù…Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª")

# ===== Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ =====

class DynamicSPSSAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ£ÙŠ Ø£Ø³Ø¦Ù„Ø©"""
    
    def __init__(self, df: pd.DataFrame, questions_text: str):
        self.df = df
        self.questions_text = questions_text
        self.variable_info = self._analyze_variables()
        self.questions = self._parse_questions()
        self.question_mappings = self._build_question_mappings()
        
    def _analyze_variables(self) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"""
        variable_info = {}
        
        for col in self.df.columns:
            col_str = str(col).strip()
            var_data = self.df[col].dropna()
            
            info = {
                'name': col_str,
                'original_name': col_str,
                'dtype': str(self.df[col].dtype),
                'n_unique': len(var_data.unique()),
                'missing': self.df[col].isna().sum(),
                'total': len(self.df[col]),
                'unique_values': sorted(var_data.unique().tolist()) if len(var_data.unique()) <= 20 else [],
                'is_numeric': pd.api.types.is_numeric_dtype(self.df[col])
            }
            
            # Ø§Ù„ØªØ®Ù…ÙŠÙ† Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØºÙŠØ±
            if info['is_numeric']:
                if info['n_unique'] <= 10:
                    info['stat_type'] = 'CATEGORICAL'
                    info['measurement_level'] = 'NOMINAL'
                else:
                    info['stat_type'] = 'CONTINUOUS'
                    info['measurement_level'] = 'SCALE'
                    info['stats'] = {
                        'mean': float(var_data.mean()) if not var_data.empty else 0,
                        'std': float(var_data.std()) if not var_data.empty else 0,
                        'min': float(var_data.min()) if not var_data.empty else 0,
                        'max': float(var_data.max()) if not var_data.empty else 0,
                        'median': float(var_data.median()) if not var_data.empty else 0
                    }
            else:
                info['stat_type'] = 'STRING'
                info['measurement_level'] = 'NOMINAL'
            
            # ØªØ®Ù…ÙŠÙ† Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…ØªØºÙŠØ± Ù…Ù† Ø§Ø³Ù…Ù‡
            info['inferred_meaning'] = self._infer_variable_meaning(col_str, info)
            
            # ØªØ®Ù…ÙŠÙ† ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù‚ÙŠÙ…
            if info['stat_type'] == 'CATEGORICAL' and info['unique_values']:
                info['value_labels'] = self._guess_value_labels(col_str, info['unique_values'])
            
            variable_info[col_str] = info
        
        return variable_info
    
    def _infer_variable_meaning(self, var_name: str, info: Dict) -> str:
        """ØªØ®Ù…ÙŠÙ† Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…ØªØºÙŠØ± Ù…Ù† Ø§Ø³Ù…Ù‡ ÙˆÙ‚ÙŠÙ…Ù‡"""
        var_lower = var_name.lower()
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
        patterns = {
            'age': ['age', 'Ø¹Ù…Ø±', 'Ø³Ù†', 'Ø§Ù„Ø¹Ù…Ø±'],
            'salary': ['salary', 'Ù…Ø±ØªØ¨', 'Ø±Ø§ØªØ¨', 'Ø¯Ø®Ù„', 'income'],
            'gender': ['gender', 'Ø¬Ù†Ø³', 'sex', 'Ø°ÙƒØ±', 'Ø£Ù†Ø«Ù‰'],
            'city': ['city', 'Ù…Ø¯ÙŠÙ†Ø©', 'Ù…Ø­Ø§ÙØ¸Ø©', 'region'],
            'year': ['year', 'Ø³Ù†Ø©', 'Ø¹Ø§Ù…', 'ØªØ§Ø±ÙŠØ®'],
            'balance': ['balance', 'Ø±ØµÙŠØ¯', 'account'],
            'transaction': ['transaction', 'Ù…Ø¹Ø§Ù…Ù„Ø©', 'Ø¹Ù…Ù„ÙŠØ©'],
            'service': ['service', 'Ø®Ø¯Ù…Ø©'],
            'card': ['card', 'Ø¨Ø·Ø§Ù‚Ø©', 'debit'],
            'interest': ['interest', 'ÙØ§Ø¦Ø¯Ø©'],
            'score': ['score', 'Ø¯Ø±Ø¬Ø©', 'mark'],
            'count': ['count', 'Ø¹Ø¯Ø¯', 'number'],
            'percentage': ['percentage', 'Ù†Ø³Ø¨Ø©', 'percent'],
            'rate': ['rate', 'Ù…Ø¹Ø¯Ù„', 'Ù†Ø³Ø¨Ø©'],
            'category': ['category', 'ÙØ¦Ø©', 'type'],
            'team': ['team', 'ÙØ±ÙŠÙ‚'],
            'league': ['league', 'Ø¯ÙˆØ±ÙŠ', 'Ø±Ø§Ø¨Ø·Ø©'],
            'built': ['built', 'Ø¨Ù†Ø§Ø¡', 'ØªØ£Ø³ÙŠØ³'],
            'size': ['size', 'Ø­Ø¬Ù…', 'Ø³Ø¹Ø©'],
            'attendance': ['attendance', 'Ø­Ø¶ÙˆØ±', 'Ù…Ø´Ø§Ù‡Ø¯ÙŠÙ†'],
            'wins': ['wins', 'Ø§Ù†ØªØµØ§Ø±Ø§Øª', 'ÙÙˆØ²'],
            'country': ['country', 'Ø¯ÙˆÙ„Ø©', 'Ø¨Ù„Ø¯'],
            'population': ['population', 'Ø³ÙƒØ§Ù†', 'ØªØ¹Ø¯Ø§Ø¯'],
            'area': ['area', 'Ù…Ø³Ø§Ø­Ø©'],
            'gdp': ['gdp', 'Ù†Ø§ØªØ¬', 'Ø§Ù‚ØªØµØ§Ø¯'],
            'happiness': ['happiness', 'Ø³Ø¹Ø§Ø¯Ø©'],
            'education': ['education', 'ØªØ¹Ù„ÙŠÙ…', 'Ù…Ø¯Ø±Ø³Ø©'],
            'occupation': ['occupation', 'ÙˆØ¸ÙŠÙØ©', 'Ù…Ù‡Ù†Ø©']
        }
        
        for meaning, keywords in patterns.items():
            for keyword in keywords:
                if keyword in var_lower:
                    return meaning
        
        # Ø§Ù„ØªØ®Ù…ÙŠÙ† Ù…Ù† Ø§Ù„Ù‚ÙŠÙ…
        if info['is_numeric']:
            if info['n_unique'] == 2:
                return 'binary_indicator'
            elif 3 <= info['n_unique'] <= 7:
                return 'categorical_code'
        
        return 'unknown'
    
    def _guess_value_labels(self, var_name: str, values: List) -> Dict:
        """ØªØ®Ù…ÙŠÙ† ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ¦ÙˆÙŠØ©"""
        var_lower = var_name.lower()
        labels = {}
        
        for val in values:
            if isinstance(val, (int, float)):
                # Ø£Ù†Ù…Ø§Ø· Ø«Ù†Ø§Ø¦ÙŠØ© (Ù†Ø¹Ù…/Ù„Ø§)
                if val == 0:
                    labels[val] = "No/False/Female"
                elif val == 1:
                    labels[val] = "Yes/True/Male"
                elif val == 2:
                    labels[val] = "Other/Sometimes"
                # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¬Ù†Ø³
                elif 'gender' in var_lower or 'sex' in var_lower:
                    if val == 1:
                        labels[val] = "Male"
                    elif val == 2:
                        labels[val] = "Female"
                # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© (Ù…Ù‚ÙŠØ§Ø³ Ù„ÙŠÙƒØ±Øª)
                elif any(word in var_lower for word in ['agree', 'satisfy', 'rate', 'happy']):
                    if val == 1:
                        labels[val] = "Strongly Disagree/Very Unhappy"
                    elif val == 2:
                        labels[val] = "Disagree/Unhappy"
                    elif val == 3:
                        labels[val] = "Neutral"
                    elif val == 4:
                        labels[val] = "Agree/Happy"
                    elif val == 5:
                        labels[val] = "Strongly Agree/Very Happy"
                # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¯Ù†/Ø§Ù„Ù…Ù†Ø§Ø·Ù‚
                elif any(word in var_lower for word in ['city', 'region', 'area']):
                    if val == 1:
                        labels[val] = "North/North East"
                    elif val == 2:
                        labels[val] = "South/South East"
                    elif val == 3:
                        labels[val] = "West"
                    elif val == 4:
                        labels[val] = "East"
                else:
                    labels[val] = f"Category {val}"
            else:
                labels[val] = str(val)
        
        return labels
    
    def _parse_questions(self) -> List[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ù„Ø£Ø³Ø¦Ù„Ø©"""
        questions = []
        
        if not self.questions_text or self.questions_text.strip() == "":
            # Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø£Ø³Ø¦Ù„Ø©
            return self._generate_default_questions()
        
        # Ø£Ù†Ù…Ø§Ø· Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        patterns = [
            r'(\d+)[\.\)]\s+(.*?)(?=\n\d+[\.\)]|\n\n|$)',  # 1. Ø£Ùˆ 1)
            r'Q(\d+)[:\-]\s+(.*?)(?=\nQ\d+[:\.\-]|\n\n|$)',  # Q1: Ø£Ùˆ Q1-
            r'Question\s+(\d+)[:\-]\s+(.*?)(?=\nQuestion\s+\d+[:\.\-]|\n\n|$)',  # Question 1:
            r'^\s*(\d+)\.\s+(.*)$',  # Ø£Ø³Ø·Ø± ØªØ¨Ø¯Ø£ Ø¨Ø±Ù‚Ù…
        ]
        
        lines = self.questions_text.split('\n')
        full_text = ' '.join(lines)  # Ø¯Ù…Ø¬ ÙƒÙ„ Ø§Ù„Ù†Øµ Ù„Ù„Ø¨Ø­Ø«
        
        for pattern in patterns:
            matches = re.finditer(pattern, full_text, re.MULTILINE | re.IGNORECASE)
            for match in matches:
                q_num = match.group(1).strip()
                q_text = match.group(2).strip()
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
                q_text = re.sub(r'\s+', ' ', q_text)
                
                if q_text and len(q_text) > 5:
                    try:
                        questions.append({
                            'number': int(q_num),
                            'text': q_text[:200],
                            'full_text': q_text,
                            'detected_type': 'unknown'
                        })
                    except ValueError:
                        continue
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø£Ø³Ø¦Ù„Ø© Ù…Ø±Ù‚Ù…Ø©ØŒ Ù†Ø¨Ø­Ø« Ø¹Ù† ÙÙ‚Ø±Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ©
        if not questions:
            for i, line in enumerate(lines):
                line = line.strip()
                if line and len(line) > 20:
                    # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ©
                    stats_keywords = [
                        'construct', 'calculate', 'draw', 'test', 'find',
                        'create', 'build', 'analyze', 'compare', 'determine',
                        'Ø¬Ø¯ÙˆÙ„', 'Ø§Ø­Ø³Ø¨', 'Ø§Ø±Ø³Ù…', 'Ø§Ø®ØªØ¨Ø§Ø±', 'Ø£ÙˆØ¬Ø¯',
                        'Ø£Ù†Ø´Ø¦', 'Ø­Ù„Ù„', 'Ù‚Ø§Ø±Ù†', 'Ø§ÙƒØªØ´Ù'
                    ]
                    
                    if any(keyword in line.lower() for keyword in stats_keywords):
                        questions.append({
                            'number': i + 1,
                            'text': line[:150],
                            'full_text': line,
                            'detected_type': 'unknown'
                        })
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ ÙƒÙ„ Ø³Ø¤Ø§Ù„
        for q in questions:
            q['detected_type'] = self._detect_question_type(q['full_text'])
            q['variables'] = self._extract_variables_from_text(q['full_text'])
            q['conditions'] = self._extract_conditions(q['full_text'])
            q['analysis_method'] = self._determine_analysis_method(q)
        
        return sorted(questions, key=lambda x: x['number'])
    
    def _generate_default_questions(self) -> List[Dict]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        questions = []
        
        # Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        default_questions = [
            (1, "Construct frequency tables for categorical variables"),
            (2, "Calculate descriptive statistics for continuous variables"),
            (3, "Draw histograms for numerical variables"),
            (4, "Create bar charts for categorical variables"),
            (5, "Analyze relationships between variables"),
            (6, "Test for normality of continuous variables"),
            (7, "Detect outliers in the data"),
            (8, "Calculate confidence intervals for means"),
            (9, "Perform correlation analysis"),
            (10, "Compare groups using appropriate tests")
        ]
        
        continuous_vars = [v for v, info in self.variable_info.items() 
                         if info['stat_type'] == 'CONTINUOUS']
        categorical_vars = [v for v, info in self.variable_info.items() 
                          if info['stat_type'] == 'CATEGORICAL']
        
        for i, (q_num, q_text) in enumerate(default_questions):
            if (q_num in [1, 4] and categorical_vars) or (q_num in [2, 3, 6, 7, 8] and continuous_vars) or q_num in [5, 9, 10]:
                questions.append({
                    'number': q_num,
                    'text': q_text,
                    'full_text': q_text,
                    'detected_type': self._detect_question_type(q_text),
                    'variables': [],
                    'conditions': [],
                    'analysis_method': 'DESCRIPTIVES'  # Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹
                })
        
        # ØªØ­Ø¯ÙŠØ¯ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„ÙƒÙ„ Ø³Ø¤Ø§Ù„
        for q in questions:
            q['analysis_method'] = self._determine_analysis_method(q)
        
        return questions
    
    def _detect_question_type(self, text: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        text_lower = text.lower()
        
        type_patterns = {
            'frequency': ['frequency table', 'Ø¬Ø¯ÙˆÙ„ ØªÙƒØ±Ø§Ø±ÙŠ', 'ØªÙˆØ²ÙŠØ¹ ØªÙƒØ±Ø§Ø±ÙŠ', 'construct frequency', 'frequency distribution'],
            'descriptive': ['mean', 'median', 'mode', 'standard deviation', 'Ù…Ù‚Ø§ÙŠÙŠØ³', 'calculate', 'Ø§Ø­Ø³Ø¨', 'descriptive statistics'],
            'bar_chart': ['bar chart', 'Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¹Ù…ÙˆØ¯ÙŠ', 'Ù…Ø®Ø·Ø· Ø¹Ù…ÙˆØ¯ÙŠ', 'draw bar', 'bar graph'],
            'pie_chart': ['pie chart', 'Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±ÙŠ', 'Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ', 'draw pie', 'pie graph'],
            'histogram': ['histogram', 'Ù…Ø¯Ø±Ø¬ ØªÙƒØ±Ø§Ø±ÙŠ', 'Ø±Ø³Ù… Ù…Ø¯Ø±Ø¬', 'histogram plot'],
            'scatter': ['scatter plot', 'Ù…Ø®Ø·Ø· Ø§Ù†ØªØ´Ø§Ø±', 'Ø±Ø³Ù… Ø§Ù†ØªØ´Ø§Ø±', 'scatter diagram'],
            'boxplot': ['box plot', 'Ù…Ø®Ø·Ø· Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚', 'ØµÙ†Ø¯ÙˆÙ‚ÙŠ', 'boxplot'],
            'confidence': ['confidence interval', 'ÙØªØ±Ø© Ø«Ù‚Ø©', 'confidence', 'ci'],
            't_test': ['t-test', 'Ø§Ø®ØªØ¨Ø§Ø± ØªÙŠ', 't test', 'Ø§Ø®ØªØ¨Ø§Ø± t', 'student t'],
            'anova': ['anova', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†', 'analysis of variance', 'f-test'],
            'correlation': ['correlation', 'Ø§Ø±ØªØ¨Ø§Ø·', 'Ø¹Ù„Ø§Ù‚Ø©', 'relationship', 'correlate'],
            'regression': ['regression', 'Ø§Ù†Ø­Ø¯Ø§Ø±', 'linear model', 'predict', 'ØªÙ†Ø¨Ø¤'],
            'chi_square': ['chi-square', 'ÙƒØ§ÙŠ Ù…Ø±Ø¨Ø¹', 'chi square', 'Ï‡Â²'],
            'normality': ['normality', 'Ø·Ø¨ÙŠØ¹ÙŠØ©', 'shapiro', 'kolmogorov', 'normal distribution'],
            'outliers': ['outliers', 'Ù‚ÙŠÙ… Ù…ØªØ·Ø±ÙØ©', 'extreme values', 'anomalies'],
            'cross_tab': ['cross tabulation', 'Ø¬Ø¯ÙˆÙ„ Ù…ØªÙ‚Ø§Ø·Ø¹', 'crosstab', 'contingency table'],
            'clustering': ['cluster', 'ØªØ¬Ù…ÙŠØ¹', 'grouping', 'segmentation'],
            'factor': ['factor analysis', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„', 'factor'],
            'reliability': ['reliability', 'Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©', 'cronbach', 'alpha'],
        }
        
        for q_type, keywords in type_patterns.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return q_type
        
        return 'descriptive'  # Ø¥ÙØªØ±Ø§Ø¶ÙŠ
    
    def _extract_variables_from_text(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù†Øµ"""
        found_vars = []
        text_lower = text.lower()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø¨Ø§Ø´Ø±Ø©
        for var_name in self.variable_info.keys():
            var_lower = var_name.lower()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø§Ø³Ù…
            if var_lower in text_lower:
                found_vars.append(var_name)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…Ø³ØªÙ†ØªØ¬
            elif self.variable_info[var_name]['inferred_meaning'] != 'unknown':
                meaning = self.variable_info[var_name]['inferred_meaning']
                meaning_keywords = {
                    'age': ['age', 'Ø¹Ù…Ø±', 'Ø³Ù†'],
                    'salary': ['salary', 'Ù…Ø±ØªØ¨', 'Ø±Ø§ØªØ¨', 'income', 'Ø¯Ø®Ù„'],
                    'gender': ['gender', 'Ø¬Ù†Ø³', 'Ø°ÙƒØ±', 'Ø£Ù†Ø«Ù‰', 'sex'],
                    'city': ['city', 'Ù…Ø¯ÙŠÙ†Ø©', 'Ù…Ø­Ø§ÙØ¸Ø©', 'region', 'Ù…Ù†Ø·Ù‚Ø©'],
                    'balance': ['balance', 'Ø±ØµÙŠØ¯', 'account', 'Ø­Ø³Ø§Ø¨'],
                    'transaction': ['transaction', 'Ù…Ø¹Ø§Ù…Ù„Ø©', 'Ø¹Ù…Ù„ÙŠØ©', 'transactions'],
                    'service': ['service', 'Ø®Ø¯Ù…Ø©', 'services'],
                    'card': ['card', 'Ø¨Ø·Ø§Ù‚Ø©', 'debit', 'credit'],
                    'interest': ['interest', 'ÙØ§Ø¦Ø¯Ø©'],
                    'score': ['score', 'Ø¯Ø±Ø¬Ø©', 'mark', 'Ù†Ù‚Ø§Ø·'],
                    'team': ['team', 'ÙØ±ÙŠÙ‚'],
                    'league': ['league', 'Ø¯ÙˆØ±ÙŠ', 'Ø±Ø§Ø¨Ø·Ø©'],
                    'country': ['country', 'Ø¯ÙˆÙ„Ø©', 'Ø¨Ù„Ø¯'],
                    'population': ['population', 'Ø³ÙƒØ§Ù†', 'ØªØ¹Ø¯Ø§Ø¯'],
                    'happiness': ['happiness', 'Ø³Ø¹Ø§Ø¯Ø©'],
                    'education': ['education', 'ØªØ¹Ù„ÙŠÙ…']
                }
                
                if meaning in meaning_keywords:
                    for keyword in meaning_keywords[meaning]:
                        if keyword in text_lower:
                            found_vars.append(var_name)
                            break
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ù…ØªØºÙŠØ±Ø§ØªØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        if not found_vars:
            # Ù†Ø®ØªØ§Ø± Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
            q_type = self._detect_question_type(text)
            
            if q_type in ['frequency', 'categorical', 'chi_square', 'cross_tab']:
                # Ù…ØªØºÙŠØ±Ø§Øª ÙØ¦ÙˆÙŠØ©
                found_vars = [v for v, info in self.variable_info.items() 
                            if info['stat_type'] == 'CATEGORICAL'][:3]
            elif q_type in ['descriptive', 'continuous', 'histogram', 'normality', 'outliers']:
                # Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø³ØªÙ…Ø±Ø©
                found_vars = [v for v, info in self.variable_info.items() 
                            if info['stat_type'] == 'CONTINUOUS'][:3]
            elif q_type in ['correlation', 'regression']:
                # Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø³ØªÙ…Ø±Ø© Ù„Ù„Ø§Ø±ØªØ¨Ø§Ø·
                found_vars = [v for v, info in self.variable_info.items() 
                            if info['stat_type'] == 'CONTINUOUS'][:4]
            elif q_type in ['t_test', 'anova', 'compare_groups']:
                # Ù…ØªØºÙŠØ± ÙØ¦ÙˆÙŠ + Ù…Ø³ØªÙ…Ø±
                cat_vars = [v for v, info in self.variable_info.items() 
                          if info['stat_type'] == 'CATEGORICAL'][:1]
                cont_vars = [v for v, info in self.variable_info.items() 
                           if info['stat_type'] == 'CONTINUOUS'][:1]
                found_vars = cat_vars + cont_vars
            else:
                # Ù…Ø²ÙŠØ¬
                categorical_vars = [v for v, info in self.variable_info.items() 
                                  if info['stat_type'] == 'CATEGORICAL'][:2]
                continuous_vars = [v for v, info in self.variable_info.items() 
                                 if info['stat_type'] == 'CONTINUOUS'][:2]
                found_vars = categorical_vars + continuous_vars
        
        return list(set(found_vars))[:5]  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 5 Ù…ØªØºÙŠØ±Ø§Øª
    
    def _extract_conditions(self, text: str) -> List[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ø±ÙˆØ· Ù…Ù† Ø§Ù„Ù†Øµ"""
        conditions = []
        text_lower = text.lower()
        
        # Ø´Ø±ÙˆØ· Ø²Ù…Ù†ÙŠØ©
        time_patterns = [
            (r'before (\d{4})', 'before_year'),
            (r'after (\d{4})', 'after_year'),
            (r'in (\d{4})', 'in_year'),
            (r'from (\d{4}) to (\d{4})', 'between_years'),
            (r'(\d{4})-(\d{4})', 'year_range')
        ]
        
        # Ø´Ø±ÙˆØ· Ù…Ù‚Ø§Ø±Ù†Ø©
        comp_patterns = [
            (r'greater than (\d+)', 'greater_than'),
            (r'less than (\d+)', 'less_than'),
            (r'equal to (\d+)', 'equal_to'),
            (r'between (\d+) and (\d+)', 'between'),
            (r'more than (\d+)', 'greater_than'),
            (r'at least (\d+)', 'at_least'),
            (r'at most (\d+)', 'at_most'),
            (r'over (\d+)', 'greater_than'),
            (r'under (\d+)', 'less_than')
        ]
        
        # Ø´Ø±ÙˆØ· ÙØ¦ÙˆÙŠØ©
        cat_patterns = [
            (r'male', 'gender_male'),
            (r'female', 'gender_female'),
            (r'yes', 'yes'),
            (r'no', 'no'),
            (r'urban', 'urban'),
            (r'rural', 'rural'),
            (r'american', 'american'),
            (r'national', 'national'),
            (r'g7', 'g7'),
            (r'white', 'white'),
            (r'black', 'black'),
            (r'far east', 'far_east'),
            (r'europe', 'europe'),
            (r'north america', 'north_america')
        ]
        
        all_patterns = time_patterns + comp_patterns + cat_patterns
        
        for pattern, cond_type in all_patterns:
            match = re.search(pattern, text_lower)
            if match:
                condition = {'type': cond_type}
                
                if cond_type == 'between_years' and len(match.groups()) >= 2:
                    condition['value'] = [int(match.group(1)), int(match.group(2))]
                elif cond_type == 'year_range' and len(match.groups()) >= 2:
                    condition['value'] = [int(match.group(1)), int(match.group(2))]
                elif cond_type == 'between' and len(match.groups()) >= 2:
                    condition['value'] = [int(match.group(1)), int(match.group(2))]
                elif match.groups():
                    try:
                        condition['value'] = int(match.group(1))
                    except:
                        condition['value'] = match.group(1)
                else:
                    condition['value'] = match.group(0)
                
                conditions.append(condition)
        
        return conditions
    
    def _determine_analysis_method(self, question: Dict) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©"""
        q_type = question['detected_type']
        variables = question['variables']
        
        if not variables:
            return 'DESCRIPTIVES'
        
        # Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        var_types = []
        for v in variables:
            if v in self.variable_info:
                var_types.append(self.variable_info[v]['stat_type'])
        
        if q_type == 'frequency':
            return 'FREQUENCIES'
        elif q_type == 'descriptive':
            return 'DESCRIPTIVES'
        elif q_type == 'bar_chart':
            if len(variables) >= 2:
                return 'GRAPH_BAR_GROUPED'
            else:
                return 'GRAPH_BAR_SIMPLE'
        elif q_type == 'pie_chart':
            return 'GRAPH_PIE'
        elif q_type == 'histogram':
            return 'GRAPH_HISTOGRAM'
        elif q_type == 't_test':
            if len(variables) >= 2:
                return 'T_TEST_INDEPENDENT'
            else:
                return 'T_TEST_ONE_SAMPLE'
        elif q_type == 'anova':
            if len(variables) >= 2:
                return 'ONEWAY_ANOVA'
        elif q_type == 'correlation':
            if len(variables) >= 2:
                return 'CORRELATIONS'
        elif q_type == 'regression':
            if len(variables) >= 2:
                return 'REGRESSION'
        elif q_type == 'chi_square':
            if len(variables) >= 2:
                return 'CROSSTABS_CHISQ'
        elif q_type == 'cross_tab':
            if len(variables) >= 2:
                return 'CROSSTABS'
        elif q_type == 'confidence':
            return 'EXAMINE_CI'
        elif q_type == 'normality':
            return 'EXAMINE_NORMALITY'
        elif q_type == 'outliers':
            return 'EXAMINE_OUTLIERS'
        
        # Ø§Ù„ØªØ®Ù…ÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        if all(t == 'CONTINUOUS' for t in var_types):
            return 'CORRELATIONS'
        elif all(t == 'CATEGORICAL' for t in var_types):
            return 'CROSSTABS'
        elif len(var_types) >= 2 and var_types[0] == 'CATEGORICAL' and var_types[1] == 'CONTINUOUS':
            return 'MEANS'
        else:
            return 'DESCRIPTIVES'
    
    def _build_question_mappings(self) -> Dict:
        """Ø¨Ù†Ø§Ø¡ Ø®Ø±Ø§Ø¦Ø· Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
        mappings = {
            'frequency_tables': {
                'keywords': ['frequency', 'ØªÙƒØ±Ø§Ø±ÙŠ', 'Ø¬Ø¯ÙˆÙ„'],
                'method': 'FREQUENCIES',
                'template': 'FREQUENCIES VARIABLES={vars}\n  /ORDER=ANALYSIS.'
            },
            'descriptive_stats': {
                'keywords': ['mean', 'median', 'mode', 'Ù…ØªÙˆØ³Ø·', 'ÙˆØ³ÙŠØ·', 'Ù…Ù†ÙˆØ§Ù„'],
                'method': 'DESCRIPTIVES',
                'template': 'DESCRIPTIVES VARIABLES={vars}\n  /STATISTICS=MEAN MEDIAN MODE STDDEV MIN MAX.'
            },
            'compare_groups': {
                'keywords': ['compare', 'Ù…Ù‚Ø§Ø±Ù†Ø©', 'between groups', 'Ø¨ÙŠÙ† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª'],
                'method': 'MEANS',
                'template': 'MEANS TABLES={dv} BY {iv}\n  /CELLS=MEAN COUNT STDDEV.'
            },
            'relationship': {
                'keywords': ['relationship', 'Ø¹Ù„Ø§Ù‚Ø©', 'correlation', 'Ø§Ø±ØªØ¨Ø§Ø·'],
                'method': 'CORRELATIONS',
                'template': 'CORRELATIONS\n  /VARIABLES={vars}\n  /PRINT=TWOTAIL NOSIG.'
            }
        }
        return mappings
    
    def generate_spss_syntax(self) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ"""
        
        syntax = f"""* =========================================================================
* DYNAMIC SPSS SOLUTION GENERATOR
* Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
* Dataset: {len(self.df.columns)} variables, {len(self.df)} cases
* Questions analyzed: {len(self.questions)}
* =========================================================================

DATASET NAME DynamicData WINDOW=FRONT.
DATASET ACTIVATE DynamicData.

* -------------------------------------------------------------------------
* VARIABLE DEFINITION AND PREPARATION
* -------------------------------------------------------------------------

* Variable labels based on inferred meanings\n"""
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        for var_name, info in self.variable_info.items():
            label = info.get('inferred_meaning', var_name).replace('_', ' ').title()
            syntax += f'VARIABLE LABELS {var_name} "{label}".\n'
            syntax += f'VARIABLE LEVEL {var_name} ({info["measurement_level"]}).\n'
            
            if 'value_labels' in info and info['value_labels']:
                syntax += f'VALUE LABELS {var_name}\n'
                for val, lbl in info['value_labels'].items():
                    syntax += f'  {val} "{lbl}"\n'
                syntax += '.\n'
        
        syntax += "\nEXECUTE.\n"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø´ØªÙ‚Ø© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        syntax += self._generate_derived_variables()
        
        # Ø­Ù„ ÙƒÙ„ Ø³Ø¤Ø§Ù„
        syntax += "\n* -------------------------------------------------------------------------"
        syntax += "\n* QUESTION SOLUTIONS"
        syntax += "\n* -------------------------------------------------------------------------\n"
        
        for q in self.questions:
            syntax += self._generate_question_solution(q)
        
        # ØªØ­Ù„ÙŠÙ„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
        syntax += self._generate_auto_analyses()
        
        # Ø¥Ù†Ù‡Ø§Ø¡
        syntax += """
* -------------------------------------------------------------------------
* CLEANUP AND SAVE
* -------------------------------------------------------------------------

DATASET CLOSE ALL.
SAVE OUTFILE='Dynamic_Analysis_Results.sav'
  /COMPRESSED.
EXECUTE.

* ==================== END OF DYNAMIC SOLUTION ====================
"""
        
        return syntax
    
    def _generate_derived_variables(self) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø´ØªÙ‚Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        syntax = "\n* Derived variables for analysis\n"
        
        for var_name, info in self.variable_info.items():
            if info['stat_type'] == 'CONTINUOUS' and 'stats' in info:
                # Ø¥Ù†Ø´Ø§Ø¡ ÙØ¦Ø§Øª Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©
                syntax += f"\n* Creating categories for {var_name}\n"
                mean_val = info['stats']['mean']
                syntax += f"IF ({var_name} < {mean_val:.2f}) {var_name}_Cat = 1.\n"
                syntax += f"IF ({var_name} >= {mean_val:.2f}) {var_name}_Cat = 2.\n"
                syntax += f"VARIABLE LABELS {var_name}_Cat 'Categories of {var_name}'.\n"
                syntax += f"VALUE LABELS {var_name}_Cat\n"
                syntax += f"  1 'Below Average'\n"
                syntax += f"  2 'Above Average'\n"
                syntax += f".\n"
        
        syntax += "EXECUTE.\n"
        return syntax
    
    def _generate_question_solution(self, question: Dict) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø­Ù„ Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ÙŠÙ†"""
        q_num = question['number']
        q_text = question['text']
        q_type = question['detected_type']
        variables = question['variables']
        method = question['analysis_method']
        
        syntax = f"\n* QUESTION {q_num}: {q_text}\n"
        syntax += f"* Detected Type: {q_type}\n"
        
        if variables:
            syntax += f"* Variables: {', '.join(variables)}\n"
        
        syntax += f"* Method: {method}\n"
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        if method == 'FREQUENCIES':
            if variables:
                syntax += f"FREQUENCIES VARIABLES={' '.join(variables)}\n"
                syntax += "  /BARCHART FREQ\n"
                syntax += "  /ORDER=ANALYSIS.\n"
        
        elif method == 'DESCRIPTIVES':
            if variables:
                syntax += f"DESCRIPTIVES VARIABLES={' '.join(variables)}\n"
                syntax += "  /STATISTICS=MEAN MEDIAN MODE STDDEV MIN MAX SKEWNESS.\n"
        
        elif method == 'GRAPH_BAR_SIMPLE':
            if variables:
                syntax += f"GRAPH\n"
                syntax += f"  /BAR(SIMPLE)=COUNT BY {variables[0]}\n"
                syntax += f"  /TITLE='Bar Chart of {variables[0]}'.\n"
        
        elif method == 'GRAPH_BAR_GROUPED':
            if len(variables) >= 2:
                syntax += f"GRAPH\n"
                syntax += f"  /BAR(GROUPED)=MEAN({variables[1]}) BY {variables[0]}\n"
                syntax += f"  /TITLE='Grouped Bar: {variables[1]} by {variables[0]}'.\n"
        
        elif method == 'GRAPH_PIE':
            if variables:
                syntax += f"GRAPH\n"
                syntax += f"  /PIE=PCT BY {variables[0]}\n"
                syntax += f"  /TITLE='Pie Chart of {variables[0]}'.\n"
        
        elif method == 'GRAPH_HISTOGRAM':
            if variables:
                for var in variables[:2]:
                    if var in self.variable_info and self.variable_info[var]['stat_type'] == 'CONTINUOUS':
                        syntax += f"GRAPH\n"
                        syntax += f"  /HISTOGRAM={var}\n"
                        syntax += f"  /TITLE='Histogram of {var}'.\n"
        
        elif method == 'T_TEST_ONE_SAMPLE':
            if variables:
                syntax += f"T-TEST\n"
                syntax += f"  /TESTVAL=0\n"
                syntax += f"  /VARIABLES={variables[0]}\n"
                syntax += f"  /CRITERIA=CI(.95).\n"
        
        elif method == 'T_TEST_INDEPENDENT':
            if len(variables) >= 2:
                syntax += f"T-TEST GROUPS={variables[0]}\n"
                syntax += f"  /VARIABLES={variables[1]}\n"
                syntax += f"  /CRITERIA=CI(.95).\n"
        
        elif method == 'ONEWAY_ANOVA':
            if len(variables) >= 2:
                syntax += f"ONEWAY {variables[1]} BY {variables[0]}\n"
                syntax += f"  /STATISTICS DESCRIPTIVES\n"
                syntax += f"  /MISSING ANALYSIS.\n"
        
        elif method == 'CORRELATIONS':
            if len(variables) >= 2:
                syntax += f"CORRELATIONS\n"
                syntax += f"  /VARIABLES={' '.join(variables[:4])}\n"
                syntax += f"  /PRINT=TWOTAIL NOSIG.\n"
        
        elif method == 'REGRESSION':
            if len(variables) >= 2:
                syntax += f"REGRESSION\n"
                syntax += f"  /DEPENDENT {variables[0]}\n"
                syntax += f"  /METHOD=ENTER {' '.join(variables[1:3])}\n"
                syntax += f"  /STATISTICS COEFF R ANOVA.\n"
        
        elif method == 'CROSSTABS' or method == 'CROSSTABS_CHISQ':
            if len(variables) >= 2:
                syntax += f"CROSSTABS\n"
                syntax += f"  /TABLES={variables[0]} BY {variables[1]}\n"
                syntax += f"  /CELLS=COUNT ROW COLUMN.\n"
                if method == 'CROSSTABS_CHISQ':
                    syntax += f"  /STATISTICS=CHISQ.\n"
        
        elif method == 'MEANS':
            if len(variables) >= 2:
                syntax += f"MEANS TABLES={variables[1]} BY {variables[0]}\n"
                syntax += f"  /CELLS=MEAN COUNT STDDEV.\n"
        
        elif method == 'EXAMINE_CI':
            if variables:
                syntax += f"EXAMINE VARIABLES={variables[0]}\n"
                syntax += f"  /PLOT NONE\n"
                syntax += f"  /STATISTICS DESCRIPTIVES\n"
                syntax += f"  /CINTERVAL 95.\n"
        
        elif method == 'EXAMINE_NORMALITY':
            if variables:
                syntax += f"EXAMINE VARIABLES={variables[0]}\n"
                syntax += f"  /PLOT NPPLOT\n"
                syntax += f"  /STATISTICS DESCRIPTIVES.\n"
        
        elif method == 'EXAMINE_OUTLIERS':
            if variables:
                syntax += f"EXAMINE VARIABLES={variables[0]}\n"
                syntax += f"  /PLOT BOXPLOT\n"
                syntax += f"  /STATISTICS EXTREME.\n"
        
        else:
            # Ø­Ù„ Ø¹Ø§Ù…
            if variables:
                syntax += f"DESCRIPTIVES VARIABLES={' '.join(variables[:3])}\n"
                syntax += f"  /STATISTICS=MEAN STDDEV MIN MAX.\n"
        
        syntax += "EXECUTE.\n"
        return syntax
    
    def _generate_auto_analyses(self) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ©"""
        syntax = "\n* -------------------------------------------------------------------------"
        syntax += "\n* AUTOMATIC ADDITIONAL ANALYSES"
        syntax += "\n* -------------------------------------------------------------------------\n"
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø© ÙˆØ§Ù„ÙØ¦ÙˆÙŠØ©
        continuous_vars = [v for v, info in self.variable_info.items() 
                         if info['stat_type'] == 'CONTINUOUS']
        categorical_vars = [v for v, info in self.variable_info.items() 
                          if info['stat_type'] == 'CATEGORICAL']
        
        # 1. ØªØ­Ù„ÙŠÙ„ ÙˆØµÙÙŠ Ø´Ø§Ù…Ù„
        if continuous_vars:
            syntax += "\n* Comprehensive descriptive analysis\n"
            syntax += f"DESCRIPTIVES VARIABLES={' '.join(continuous_vars[:5])}\n"
            syntax += "  /STATISTICS=MEAN STDDEV MIN MAX SKEWNESS KURTOSIS.\n"
            syntax += "EXECUTE.\n"
        
        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª
        if len(continuous_vars) >= 2:
            syntax += "\n* Correlation matrix\n"
            syntax += f"CORRELATIONS\n"
            syntax += f"  /VARIABLES={' '.join(continuous_vars[:4])}\n"
            syntax += "  /PRINT=TWOTAIL NOSIG.\n"
            syntax += "EXECUTE.\n"
        
        # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        if categorical_vars:
            syntax += "\n* Frequency analysis for categorical variables\n"
            syntax += f"FREQUENCIES VARIABLES={' '.join(categorical_vars[:3])}\n"
            syntax += "  /BARCHART FREQ\n"
            syntax += "  /ORDER=ANALYSIS.\n"
            syntax += "EXECUTE.\n"
        
        # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        if continuous_vars and categorical_vars:
            syntax += "\n* Means comparison by categories\n"
            syntax += f"MEANS TABLES={continuous_vars[0]} BY {categorical_vars[0]}\n"
            syntax += "  /CELLS=MEAN COUNT STDDEV.\n"
            syntax += "EXECUTE.\n"
        
        return syntax

# ===== ÙˆØ§Ø¬Ù‡Ø© Streamlit =====

def main():
    # Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.header("ğŸ“ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª")
        
        st.subheader("1. Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        data_file = st.file_uploader(
            "Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel/CSV)",
            type=['xls', 'xlsx', 'csv'],
            key="data_uploader"
        )
        
        st.markdown("---")
        
        st.subheader("2. Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©")
        questions_file = st.file_uploader(
            "Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Word/Text)",
            type=['docx', 'doc', 'txt'],
            key="questions_uploader"
        )
        
        st.markdown("---")
        
        # Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
        with st.expander("âš™ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"):
            auto_detect = st.checkbox("Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø·", value=True)
            generate_summary = st.checkbox("ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù…Ù„Ø®Øµ", value=True)
            include_comments = st.checkbox("ØªØ¶Ù…ÙŠÙ† Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©", value=True)
        
        st.markdown("---")
        
        analyze_btn = st.button(
            "ğŸ§  ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒØ§Ù…Ù„",
            type="primary",
            use_container_width=True
        )
    
    # Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    st.markdown("""
    ## ğŸ¯ Ù…Ø­Ù„Ù„ SPSS Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
    
    ### ğŸ“‹ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
    
    1. **Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„**: ÙŠØ­Ù„ Ø£ÙŠ Ø£Ø³Ø¦Ù„Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ù…Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª
    2. **ØªØ®Ù…ÙŠÙ† Ø°ÙƒÙŠ**: ÙŠØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙˆÙ…Ø¹Ø§Ù†ÙŠÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    3. **ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ**: ÙŠØ­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„ÙƒÙ„ Ø³Ø¤Ø§Ù„
    4. **Ø¯Ø¹Ù… ÙƒØ§Ù…Ù„**: ÙŠØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
    5. **ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ ÙƒØ§Ù…Ù„**: ÙŠÙˆÙ„Ø¯ ÙƒÙˆØ¯ SPSS Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ´ØºÙŠÙ„
    
    ### ğŸ“Š ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
    1. **Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª** (Excel Ø£Ùˆ CSV)
    2. **Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©** (Word Ø£Ùˆ Text)
    3. **Ø§Ù†Ù‚Ø± Ø¹Ù„Ù‰ "ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒØ§Ù…Ù„"**
    4. **ØªØ­Ù…ÙŠÙ„ ÙƒÙˆØ¯ SPSS** Ø§Ù„Ø¬Ø§Ù‡Ø²
    """)
    
    if data_file and analyze_btn:
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
                tmp.write(data_file.getvalue())
                data_path = tmp.name
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if data_file.name.lower().endswith('.csv'):
                df = pd.read_csv(data_path)
            else:
                df = pd.read_excel(data_path)
            
            os.unlink(data_path)
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
            questions_text = ""
            if questions_file:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.tmp') as tmp:
                    tmp.write(questions_file.getvalue())
                    questions_path = tmp.name
                
                if questions_file.name.lower().endswith(('.docx', '.doc')):
                    try:
                        doc = Document(questions_path)
                        questions_text = "\n".join([para.text for para in doc.paragraphs])
                    except:
                        st.warning("âš ï¸ ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù WordØŒ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ…Ù„Ù Ù†ØµÙŠ")
                        with open(questions_path, 'r', encoding='utf-8', errors='ignore') as f:
                            questions_text = f.read()
                else:
                    with open(questions_path, 'r', encoding='utf-8', errors='ignore') as f:
                        questions_text = f.read()
                
                os.unlink(questions_path)
                st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(questions_text.split())} ÙƒÙ„Ù…Ø© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©")
            else:
                st.info("â„¹ï¸ Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù Ø£Ø³Ø¦Ù„Ø©ØŒ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©")
                questions_text = ""
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ù„Ù„
            with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø©..."):
                analyzer = DynamicSPSSAnalyzer(df, questions_text)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª", len(df.columns))
                with col2:
                    st.metric("Ø§Ù„Ø­Ø§Ù„Ø§Øª", len(df))
                with col3:
                    st.metric("Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", len(analyzer.questions))
                
                # Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
                with st.expander("ğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"):
                    var_data = []
                    for var_name, info in analyzer.variable_info.items():
                        row = {
                            'Ø§Ù„Ù…ØªØºÙŠØ±': var_name,
                            'Ø§Ù„Ù…Ø¹Ù†Ù‰': info.get('inferred_meaning', 'unknown'),
                            'Ø§Ù„Ù†ÙˆØ¹': info['stat_type'],
                            'Ø§Ù„Ù…Ø³ØªÙˆÙ‰': info['measurement_level'],
                            'Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©': info['n_unique']
                        }
                        var_data.append(row)
                    st.table(pd.DataFrame(var_data))
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§
                with st.expander("ğŸ“ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"):
                    if analyzer.questions:
                        for q in analyzer.questions:
                            st.markdown(f"**{q['number']}. {q['text']}**")
                            st.caption(f"ğŸ“Š Ø§Ù„Ù†ÙˆØ¹: {q['detected_type']}")
                            st.caption(f"âš™ï¸ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©: {q['analysis_method']}")
                            if q['variables']:
                                st.caption(f"ğŸ”§ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª: {', '.join(q['variables'])}")
                            st.markdown("---")
                    else:
                        st.info("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù")
                
                # ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS
                st.markdown("---")
                st.subheader("âš™ï¸ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ")
                
                with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø­Ù„ Ø§Ù„ÙƒØ§Ù…Ù„..."):
                    spss_code = analyzer.generate_spss_syntax()
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯
                    st.code(spss_code, language='spss')
                    
                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯
                    st.download_button(
                        label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù SPSS (.sps)",
                        data=spss_code,
                        file_name="Dynamic_SPSS_Solution.sps",
                        mime="text/plain",
                        use_container_width=True
                    )
                    
                    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ù† Ø§Ù„ÙƒÙˆØ¯
                    lines_count = spss_code.count('\n')
                    char_count = len(spss_code)
                    
                    st.info(f"""
                    **Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØªÙˆÙ„Ø¯:**
                    - ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø·Ø±: {lines_count}
                    - ğŸ”¤ Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø±ÙˆÙ: {char_count}
                    - â“ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©: {len(analyzer.questions)}
                    - âœ… Ø§Ù„Ø­Ø§Ù„Ø©: Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ´ØºÙŠÙ„ ÙÙŠ SPSS
                    """)
        
        except Exception as e:
            st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
    
    elif not data_file and analyze_btn:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹")
    
    else:
        # Ø¹Ø±Ø¶ Ø£Ù…Ø«Ù„Ø©
        with st.expander("ğŸ” Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©"):
            st.markdown("""
            ### Ù…Ø«Ø§Ù„ 1: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ù†ÙˆÙƒ
            ```
            X1 = Account Balance
            X2 = ATM Transactions
            X3 = Services Used
            X4 = Debit Card (0=No, 1=Yes)
            X5 = Interest (0=No, 1=Yes)
            X6 = City (1,2,3,4)
            ```
            
            ### Ù…Ø«Ø§Ù„ 2: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØ³Ø¨ÙˆÙ„
            ```
            Team, League, Built Year, Stadium Size, Salary, Attendance, Wins
            ```
            
            ### Ù…Ø«Ø§Ù„ 3: Ø¨ÙŠØ§Ù†Ø§Øª OECD
            ```
            Country, G7 Member, Area, Population, GDP, Labor Force, Region
            ```
            
            ### Ù…Ø«Ø§Ù„ 4: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù†
            ```
            Gender, Race, Salary, Region, Happiness, Age, Education, Occupation
            ```
            """)

if __name__ == "__main__":
    main()
