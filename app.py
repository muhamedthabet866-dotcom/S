import streamlit as st
import pandas as pd
import numpy as np
import re
import math

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="SPSS Universal Solver", layout="wide", page_icon="ğŸ§ ")
st.title("ğŸ“ Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø­Ù…Ø¯ - Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ø­Ù„ Ø§Ù…ØªØ­Ø§Ù†Ø§Øª SPSS")
st.markdown("### ğŸ”“ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­Ù„Ù„ Ø£ÙŠ Ù…Ù„Ù Ø¥ÙƒØ³ÙŠÙ„ Ù…Ø¹ Ø£ÙŠ Ø£Ø³Ø¦Ù„Ø© Ø¯ÙˆÙ† ØªØ¬Ù‡ÙŠØ² Ù…Ø³Ø¨Ù‚.")

# --- 1. Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ø§Ù…Ø© (Fallback Rules) ---
# Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ØªØ¹Ù…Ù„ Ø¥Ø°Ø§ Ù„Ù… ØªØ±ÙØ¹ Ù…Ù„Ù rules.csv
DEFAULT_RULES = [
    {"keyword": "frequency", "template": "FREQUENCIES VARIABLES={var} /FORMAT=AVALUE /STATISTICS=MEAN MEDIAN MODE STDDEV /HISTOGRAM."},
    {"keyword": "descriptive", "template": "DESCRIPTIVES VARIABLES={var} /STATISTICS=MEAN STDDEV MIN MAX KURTOSIS SKEWNESS."},
    {"keyword": "bar chart", "template": "GRAPH /BAR(SIMPLE)=MEAN({y}) BY {group}."},
    {"keyword": "pie chart", "template": "GRAPH /PIE=COUNT BY {group}."},
    {"keyword": "histogram", "template": "GRAPH /HISTOGRAM(NORMAL)={var}."},
    {"keyword": "normality", "template": "EXAMINE VARIABLES={var} /PLOT NPPLOT /STATISTICS DESCRIPTIVES."},
    {"keyword": "regression", "template": "REGRESSION /DEPENDENT {y} /METHOD=ENTER {x_list} /STATISTICS COEFF OUTS R ANOVA."},
    {"keyword": "correlation", "template": "CORRELATIONS /VARIABLES={var} /PRINT=TWOTAIL NOSIG."},
    {"keyword": "t-test", "template": "T-TEST GROUPS={group}(0 1) /VARIABLES={var}."},
    {"keyword": "anova", "template": "ONEWAY {var} BY {group} /STATISTICS DESCRIPTIVES /POSTHOC=TUKEY."},
    {"keyword": "outlier", "template": "EXAMINE VARIABLES={var} /PLOT BOXPLOT."},
    {"keyword": "confidence", "template": "EXAMINE VARIABLES={var} /CINTERVAL 95."},
]

# --- 2. Ø¯ÙˆØ§Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ ---

def detect_variable_type(series):
    """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØºÙŠØ± (Scale/Nominal) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    if pd.api.types.is_numeric_dtype(series):
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ù‚Ù…ÙŠ Ù„Ù‡ Ù‚ÙŠÙ… ÙØ±ÙŠØ¯Ø© Ù‚Ù„ÙŠÙ„Ø© (Ø£Ù‚Ù„ Ù…Ù† 10) Ù†Ø¹ØªØ¨Ø±Ù‡ ÙØ¦Ø§Øª (Nominal)
        if series.nunique() <= 10: 
            return 'Nominal'
        return 'Scale'
    return 'Nominal' # Ø§Ù„Ù†ØµÙˆØµ ØªØ¹ØªØ¨Ø± Nominal

def find_matching_columns(question_text, df_columns):
    """
    Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ: ØªØ±Ø¨Ø· ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥ÙƒØ³ÙŠÙ„
    """
    matches = []
    q_lower = question_text.lower()
    
    for col in df_columns:
        col_clean = col.strip().lower()
        # 1. ØªØ·Ø§Ø¨Ù‚ ØªØ§Ù…
        if col_clean in q_lower:
            matches.append(col)
        # 2. ØªØ·Ø§Ø¨Ù‚ Ø¬Ø²Ø¦ÙŠ (Ù„Ùˆ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Salary_2020 ÙˆØ§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠÙ‡ Salary)
        else:
            parts = col_clean.split('_') # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø¹Ù‚Ø¯
            for part in parts:
                if len(part) > 2 and part in q_lower: # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø©
                    matches.append(col)
                    break
    return list(set(matches)) # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±

def sturges_recode(col_name, series):
    """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Recode ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Sturges Rule"""
    n = len(series.dropna())
    if n == 0: return "", col_name
    
    k = math.ceil(1 + 3.322 * math.log10(n))
    min_v = math.floor(series.min())
    max_v = math.ceil(series.max())
    
    if max_v == min_v: width = 1
    else: width = (max_v - min_v) / k
    
    new_var = f"{col_name}_Cat"
    # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ù„ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ SPSS
    new_var = re.sub(r'\W+', '', new_var) 
    
    syntax = f"\n* --- RECODE (Sturges Rule: k={k}) for {col_name} ---.\n"
    syntax += f"RECODE {col_name} "
    
    curr = min_v
    for i in range(1, k+1):
        end = curr + width
        syntax += f"({curr:.2f} THRU {end:.2f}={i}) "
        curr = end
        
    syntax += f"INTO {new_var}.\nEXECUTE.\n"
    return syntax, new_var

# --- 3. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ---

with st.sidebar:
    st.header("1. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£Ù‡Ù…)")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³ÙŠÙ„ (Ù„Ø£ÙŠ Ø§Ù…ØªØ­Ø§Ù†)", type=['xlsx', 'csv'])
    
    df = None
    col_info = {} # Ù„ØªØ®Ø²ÙŠÙ† Ù†ÙˆØ¹ ÙƒÙ„ Ø¹Ù…ÙˆØ¯
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'): df = pd.read_csv(uploaded_file)
            else: df = pd.read_excel(uploaded_file)
            
            # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª)
            df.columns = [c.strip() for c in df.columns]
            
            st.success(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {len(df)} ØµÙ Ùˆ {len(df.columns)} Ø¹Ù…ÙˆØ¯.")
            
            st.write("---")
            st.write("**Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙƒØªØ´ÙØ©:**")
            for col in df.columns:
                v_type = detect_variable_type(df[col])
                col_info[col] = v_type
                icon = "ğŸ”¢" if v_type == 'Scale' else "ğŸ”¤"
                st.caption(f"{icon} {col} ({v_type})")
                
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù„Ù: {e}")

    st.write("---")
    st.header("2. Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    rules_file = st.file_uploader("Ù…Ù„Ù rules.csv", type=['csv'])
    rules_data = DEFAULT_RULES
    if rules_file:
        try:
            rdf = pd.read_csv(rules_file)
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ø³Ù…Ø§Ø¦Ù‡Ø§
            rdf.columns = [c.lower().strip() for c in rdf.columns]
            # ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø¯ÙƒØ´Ù†Ø±ÙŠ
            rules_data = []
            for _, row in rdf.iterrows():
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ keyword Ø£Ùˆ template
                k = row.get('keyword', row.get('keyword ', ''))
                t = row.get('syntax_template', row.get('template', ''))
                if k and t:
                    rules_data.append({"keyword": str(k).lower(), "template": str(t)})
            st.success("ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©.")
        except:
            st.warning("ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ØŒ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©.")

# --- 4. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---

st.subheader("ğŸ“ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Ø§Ù†Ø³Ø® Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙƒÙ…Ø§ Ù‡ÙŠ)")
questions_text = st.text_area("Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:", height=200, placeholder="Ex: Analyze the salary. Draw histogram for Age...")

if st.button("ğŸš€ Ø­Ù„ Ø§Ù„Ø§Ù…ØªØ­Ø§Ù†"):
    if df is None:
        st.error("âš ï¸ ÙŠØ¬Ø¨ Ø±ÙØ¹ Ù…Ù„Ù Ø¥ÙƒØ³ÙŠÙ„ Ø£ÙˆÙ„Ø§Ù‹ Ù„ÙŠØ¹Ù…Ù„ Ø§Ù„Ù…Ø­Ø±Ùƒ.")
    elif not questions_text:
        st.warning("âš ï¸ Ø§ÙƒØªØ¨ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©.")
    else:
        final_syntax = ["* Encoding: UTF-8.", "SET SEED=12345.", "OUTPUT MODIFY /SELECT ALL /REPORT PRINT LOG.", ""]
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        questions = re.split(r'(?:\n|\d+\.\s)', questions_text)
        
        q_idx = 0
        for q in questions:
            q = q.strip()
            if len(q) < 3: continue
            q_idx += 1
            q_lower = q.lower()
            
            final_syntax.append(f"\n* ---------------- Q{q_idx}: {q} ----------------.")
            
            # A) Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„
            matched_cols = find_matching_columns(q, df.columns)
            
            if not matched_cols:
                final_syntax.append(f"* Warning: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ ÙŠØ·Ø§Ø¨Ù‚ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø³Ø¤Ø§Ù„.")
                final_syntax.append(f"* Columns available: {', '.join(df.columns)}")
                continue
                
            # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
            scale_vars = [c for c in matched_cols if col_info[c] == 'Scale']
            nom_vars = [c for c in matched_cols if col_info[c] == 'Nominal']
            
            # B) Ù‡Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ·Ù„Ø¨ ØªÙ‚Ø³ÙŠÙ… (Split)ØŸ
            split_block_start = ""
            split_block_end = ""
            split_var = None
            if any(x in q_lower for x in ['for each', 'per ', 'by city', 'by gender']):
                # Ù†Ø¨Ø­Ø« Ø¹Ù† Ù…ØªØºÙŠØ± Ø§Ø³Ù…ÙŠ ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„ÙŠÙƒÙˆÙ† Ù‡Ùˆ Ø§Ù„Ù…Ù‚Ø³Ù…
                if nom_vars:
                    split_var = nom_vars[0]
                    split_block_start = f"SORT CASES BY {split_var}.\nSPLIT FILE SEPARATE BY {split_var}."
                    split_block_end = "SPLIT FILE OFF."

            # C) Ù‡Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ·Ù„Ø¨ ÙØ¦Ø§Øª (Classes/Recode)ØŸ
            recode_syntax = ""
            active_vars = matched_cols.copy() # Ù†Ø³Ø®Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
            
            if any(x in q_lower for x in ['class', 'group', 'intervals']):
                if scale_vars:
                    target = scale_vars[0] # Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ Ù…ØªØºÙŠØ± Ø±Ù‚Ù…ÙŠ
                    rec_code, new_var_name = sturges_recode(target, df[target])
                    recode_syntax = rec_code
                    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
                    active_vars = [new_var_name if x == target else x for x in active_vars]
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙƒÙ€ Nominal (Ù„Ø£Ù†Ù‡ Ø£ØµØ¨Ø­ ÙØ¦Ø§Øª)
                    nom_vars.append(new_var_name)

            # D) ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
            rule_found = False
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø§Ù„Ø£Ø·ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹ (Ù„ØªØ¬Ù†Ø¨ ØªØ¯Ø§Ø®Ù„ chart Ù…Ø¹ bar chart)
            sorted_rules = sorted(rules_data, key=lambda x: len(x['keyword']), reverse=True)
            
            for rule in sorted_rules:
                if rule['keyword'] in q_lower:
                    template = rule['template']
                    
                    # Ù…Ù„Ø¡ Ø§Ù„Ù‚Ø§Ù„Ø¨ (Template Filling Logic)
                    cmd = template
                    
                    # {var} -> ÙƒÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
                    if '{var}' in cmd: cmd = cmd.replace('{var}', " ".join(active_vars))
                    if '=var' in cmd: cmd = cmd.replace('=var', f"={' '.join(active_vars)}")
                    
                    # {group} -> Ù…ØªØºÙŠØ± Ø§Ø³Ù…ÙŠ
                    if '{group}' in cmd:
                        g_var = split_var if split_var else (nom_vars[0] if nom_vars else "MISSING_GROUP")
                        cmd = cmd.replace('{group}', g_var)
                    
                    # {y} Ùˆ {x} Ù„Ù„Ø§Ù†Ø­Ø¯Ø§Ø±
                    if '{y}' in cmd:
                        # Ø§Ù„ØªØ§Ø¨Ø¹ Ù‡Ùˆ Ø§Ù„Ø±Ù‚Ù…ÙŠ
                        y_val = scale_vars[0] if scale_vars else active_vars[0]
                        cmd = cmd.replace('{y}', y_val)
                        # Ø§Ù„Ø¨Ø§Ù‚ÙŠ Ù‡Ùˆ Ø§Ù„Ù…Ø³ØªÙ‚Ù„
                        x_vals = [v for v in active_vars if v != y_val]
                        if '{x_list}' in cmd: cmd = cmd.replace('{x_list}', " ".join(x_vals))
                    
                    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø³Ø¤Ø§Ù„
                    if split_block_start: final_syntax.append(split_block_start)
                    if recode_syntax: final_syntax.append(recode_syntax)
                    
                    final_syntax.append(f"* Rule Applied: {rule['keyword']}")
                    final_syntax.append(cmd)
                    
                    if split_block_end: final_syntax.append(split_block_end)
                    
                    rule_found = True
                    break
            
            if not rule_found:
                # Fallback: ÙˆØµÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
                final_syntax.append("* No specific rule matched. Running Descriptives:")
                final_syntax.append(f"DESCRIPTIVES VARIABLES={' '.join(active_vars)} /STATISTICS=MEAN STDDEV MIN MAX.")

        st.success("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ù†Ø¬Ø§Ø­!")
        st.code("\n".join(final_syntax), language='spss')
