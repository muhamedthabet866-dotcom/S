import streamlit as st
import pandas as pd
import requests
from io import BytesIO
import re

st.set_page_config(page_title="MBA SPSS Solver Pro", layout="wide")
st.title("ğŸ“ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ - Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø­Ù…Ø¯")

# Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø¹Ø¯ÙˆØ§Ù†ÙŠØ© Ù„Ù„Ù†ØµÙˆØµ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
def ultra_clean(text):
    if not text or pd.isna(text): return ""
    # ØªØ­ÙˆÙŠÙ„ Ù„ØµØºÙŠØ± + Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø±Ù…ÙˆØ² ÙˆØªØ±Ù‚ÙŠÙ… + ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
    text = str(text).lower()
    text = re.sub(r'[^a-z0-9\s]', ' ', text)
    return " ".join(text.split())

# --- Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù†Ù‡Ø¬ Ù…Ù† GitHub ---
GITHUB_URL = "https://raw.githubusercontent.com/YOUR_USERNAME/YOUR_REPO/main/spss_rules.csv"

@st.cache_data
def load_rules(url):
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV Ø§Ù„Ù…Ø±ÙÙˆØ¹ (Ù†Ø¸Ø±Ø§Ù‹ Ù„Ø£Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙ‚ CSV)
        res = requests.get(url, timeout=15)
        return pd.read_csv(BytesIO(res.content))
    except: return None

rules_df = load_rules(GITHUB_URL)

with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    mapping_input = st.text_area("ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª (X1=name):", 
        value="X1=account balance\nX2=ATM transactions\nX4=debit card\nX5=interest\nX6
