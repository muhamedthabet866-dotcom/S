import pandas as pd
import docx
import re
import os
import streamlit as st
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# ØªÙ‡ÙŠØ¦Ø© Streamlit
st.set_page_config(page_title="SPSS v26 Syntax Generator", layout="wide")
st.title("ğŸ“Š SPSS v26 Syntax Generator")
st.markdown("### ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ù…Ù„ÙØ§Øª Excel ÙˆWord")

class SPSSv26SyntaxGenerator:
    def __init__(self, excel_path: str, word_path: str):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…ÙˆÙ„Ø¯ ÙƒÙˆØ¯ SPSS v26
        """
        self.excel_path = excel_path
        self.word_path = word_path
        self.dataset_name = os.path.basename(excel_path).split('.')[0]
        self.data = pd.DataFrame()
        self.data_types = {}
        self.variable_map = {}
        self.questions = []
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self._load_data()
    
    def _load_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Excel"""
        try:
            if os.path.exists(self.excel_path):
                self.data = pd.read_excel(self.excel_path, sheet_name=0)
                
                # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                self.data.columns = [str(col).strip() for col in self.data.columns]
                
                # ØªØ­Ù„ÙŠÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                self.data_types = {}
                for col in self.data.columns:
                    if self.data[col].dtype == 'object':
                        self.data_types[col] = 'STRING'
                    elif len(self.data[col].dropna().unique()) < 10:
                        self.data_types[col] = 'CATEGORICAL'
                    else:
                        self.data_types[col] = 'SCALE'
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
                self._create_variable_mapping()
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
                self._extract_questions()
            else:
                st.error(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {self.excel_path}")
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            self.data = pd.DataFrame()
    
    def _create_variable_mapping(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª"""
        self.variable_map = {}
        
        for col in self.data.columns:
            var_info = {
                'name': col,
                'label': col,
                'type': self.data_types.get(col, 'SCALE'),
                'values': {}
            }
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØºÙŠØ± ÙØ¦ÙˆÙŠØŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©
            if var_info['type'] == 'CATEGORICAL' and not self.data.empty:
                unique_vals = self.data[col].dropna().unique()[:10]
                for val in unique_vals:
                    var_info['values'][str(val)] = f"Value {val}"
            
            self.variable_map[col] = var_info
    
    def _extract_questions(self):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ù…Ù„Ù Word"""
        self.questions = []
        
        if not os.path.exists(self.word_path):
            st.warning(f"Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {self.word_path}")
            return
        
        try:
            doc = docx.Document(self.word_path)
            current_question = None
            
            for para in doc.paragraphs:
                text = para.text.strip()
                
                if not text:
                    continue
                
                # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù…Ø±Ù‚Ù…Ø§Ù‹
                match = re.match(r'^(\d+)[\.\)]\s*(.*)', text)
                if match:
                    if current_question:
                        self.questions.append(current_question)
                    
                    q_num = int(match.group(1))
                    q_text = match.group(2)
                    current_question = {
                        'number': q_num,
                        'text': q_text,
                        'full_text': text
                    }
                elif current_question and text:
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ
                    current_question['full_text'] += " " + text
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£Ø®ÙŠØ±
            if current_question:
                self.questions.append(current_question)
                
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Word: {e}")
    
    def generate_dataset_setup(self) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ÙƒÙˆØ¯ Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if self.data.empty:
            return "* No data loaded\n"
        
        syntax = f"* === SPSS v26 Dataset Setup ===\n"
        syntax += f"* File: {self.dataset_name}\n"
        syntax += f"* Variables: {len(self.data.columns)}\n"
        syntax += f"* Cases: {len(self.data)}\n"
        syntax += f"* Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\n\n"
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        syntax += "DATASET NAME DataSet1 WINDOW=FRONT.\n"
        syntax += "DATASET ACTIVATE DataSet1.\n\n"
        
        # Ø¥Ø¶Ø§ÙØ© ØªØ³Ù…ÙŠØ§Øª Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª
        syntax += "* Variable Labels\n"
        for var_name, var_info in self.variable_map.items():
            syntax += f'VARIABLE LABELS {var_name} "{var_info["label"]}".\n'
        
        syntax += "\n"
        
        # ØªØ­Ø¯ÙŠØ¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        syntax += "* Define Variable Types\n"
        for var_name, var_info in self.variable_map.items():
            if var_info['type'] == 'SCALE':
                syntax += f'VARIABLE LEVEL {var_name} (SCALE).\n'
            elif var_info['type'] in ['CATEGORICAL', 'STRING']:
                syntax += f'VARIABLE LEVEL {var_name} (NOMINAL).\n'
        
        syntax += "\nEXECUTE.\n"
        syntax += "*" * 60 + "\n\n"
        
        return syntax
    
    def detect_analysis_type(self, question_text: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨"""
        text_lower = question_text.lower()
        
        analysis_patterns = {
            'frequency': ['frequency table', 'Ø¬Ø¯ÙˆÙ„ ØªÙƒØ±Ø§Ø±ÙŠ', 'ØªÙˆØ²ÙŠØ¹ ØªÙƒØ±Ø§Ø±ÙŠ'],
            'descriptive': ['mean', 'median', 'mode', 'standard deviation', 'Ù…Ù‚Ø§ÙŠÙŠØ³'],
            'bar_chart': ['bar chart', 'Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¹Ù…ÙˆØ¯ÙŠ', 'Ù…Ø®Ø·Ø· Ø¹Ù…ÙˆØ¯ÙŠ'],
            'pie_chart': ['pie chart', 'Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±ÙŠ', 'Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ'],
            'histogram': ['histogram', 'Ù…Ø¯Ø±Ø¬ ØªÙƒØ±Ø§Ø±ÙŠ'],
            'confidence': ['confidence interval', 'ÙØªØ±Ø© Ø«Ù‚Ø©'],
            'ttest': ['test the hypothesis', 't-test', 'Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙØ±Ø¶ÙŠØ©'],
            'anova': ['anova', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†', 'significant difference'],
            'correlation': ['correlation', 'Ø§Ø±ØªØ¨Ø§Ø·'],
            'regression': ['regression', 'Ø§Ù†Ø­Ø¯Ø§Ø±', 'linear model'],
            'normality': ['normality', 'empirical rule', 'chebycheve'],
            'outliers': ['outliers', 'extreme value', 'Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ©']
        }
        
        for analysis_type, keywords in analysis_patterns.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return analysis_type
        
        return 'descriptive'
    
    def extract_variables_from_question(self, question_text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„"""
        if self.data.empty:
            return []
        
        found_vars = []
        question_lower = question_text.lower()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„
        for var_name in self.variable_map.keys():
            var_lower = var_name.lower()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„
            if var_lower in question_lower:
                found_vars.append(var_name)
            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
            elif 'salary' in question_lower and 'salary' in var_lower:
                found_vars.append(var_name)
            elif 'age' in question_lower and 'age' in var_lower:
                found_vars.append(var_name)
            elif 'gender' in question_lower and 'gender' in var_lower:
                found_vars.append(var_name)
        
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ØªØºÙŠØ±Ø§ØªØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
        if not found_vars and not self.data.empty:
            found_vars = list(self.data.columns[:min(3, len(self.data.columns))])
        
        return found_vars
    
    def generate_analysis_syntax(self, question: Dict) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ÙŠÙ†"""
        q_num = question['number']
        q_text = question['text']
        full_text = question['full_text']
        
        syntax = f"* Question {q_num}: {q_text}\n"
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        analysis_type = self.detect_analysis_type(full_text)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        variables = self.extract_variables_from_question(full_text)
        
        syntax += f"* Analysis Type: {analysis_type}\n"
        syntax += f"* Variables: {variables}\n"
        syntax += "*" * 50 + "\n"
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        if analysis_type == 'frequency':
            syntax += self._generate_frequency_table(variables)
        elif analysis_type == 'descriptive':
            syntax += self._generate_descriptive_stats(variables)
        elif analysis_type == 'bar_chart':
            syntax += self._generate_bar_chart(variables)
        elif analysis_type == 'pie_chart':
            syntax += self._generate_pie_chart(variables)
        else:
            syntax += f"* Using descriptive statistics for {analysis_type}\n"
            syntax += self._generate_descriptive_stats(variables)
        
        syntax += "\n"
        return syntax
    
    def _generate_frequency_table(self, variables: List[str]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ ØªÙƒØ±Ø§Ø±ÙŠ"""
        syntax = "FREQUENCIES VARIABLES="
        syntax += " ".join(variables) + "\n"
        syntax += "  /BARCHART FREQ\n"
        syntax += "  /ORDER=ANALYSIS.\n"
        syntax += "EXECUTE.\n"
        return syntax
    
    def _generate_descriptive_stats(self, variables: List[str]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø­ØµØ§Ø¡Ø§Øª ÙˆØµÙÙŠØ©"""
        syntax = "DESCRIPTIVES VARIABLES="
        syntax += " ".join(variables) + "\n"
        syntax += "  /STATISTICS=MEAN STDDEV MIN MAX.\n"
        syntax += "EXECUTE.\n"
        return syntax
    
    def _generate_bar_chart(self, variables: List[str]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¹Ù…ÙˆØ¯ÙŠ"""
        if len(variables) == 0:
            return "* No variables for bar chart\n"
        
        if len(variables) == 1:
            syntax = "GRAPH\n"
            syntax += f"  /BAR(SIMPLE)=COUNT BY {variables[0]}\n"
            syntax += "  /TITLE='Bar Chart'.\n"
            syntax += "EXECUTE.\n"
        else:
            syntax = "GRAPH\n"
            syntax += f"  /BAR(GROUPED)=MEAN({variables[1]}) BY {variables[0]}\n"
            syntax += "  /TITLE='Grouped Bar Chart'.\n"
            syntax += "EXECUTE.\n"
        
        return syntax
    
    def _generate_pie_chart(self, variables: List[str]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¯Ø§Ø¦Ø±ÙŠ"""
        if len(variables) == 0:
            return "* No variables for pie chart\n"
        
        syntax = "GRAPH\n"
        syntax += f"  /PIE=PCT BY {variables[0]}\n"
        syntax += "  /TITLE='Pie Chart'.\n"
        syntax += "EXECUTE.\n"
        return syntax
    
    def process_all_questions(self) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ¥Ù†Ø´Ø§Ø¡ ÙƒÙˆØ¯ SPSS ÙƒØ§Ù…Ù„"""
        if not self.questions:
            return "* No questions found in the document\n"
        
        if self.data.empty:
            return "* No data loaded\n"
        
        # Ø¨Ø¯Ø¡ ÙƒÙˆØ¯ SPSS
        spss_syntax = self.generate_dataset_setup()
        
        spss_syntax += "* === Analysis for Each Question ===\n\n"
        
        for question in self.questions:
            try:
                spss_syntax += self.generate_analysis_syntax(question)
            except Exception as e:
                spss_syntax += f"* Error processing question {question['number']}: {str(e)[:100]}...\n\n"
        
        # Ø¥Ø¶Ø§ÙØ© Ù‚Ø³Ù… Ù„Ù„ØªÙ†Ø¸ÙŠÙ
        spss_syntax += "* === Cleanup ===\n"
        spss_syntax += "DATASET CLOSE ALL.\n"
        spss_syntax += "EXECUTE.\n"
        
        return spss_syntax

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
def main():
    """Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚"""
    
    # Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„ØªØ­ÙƒÙ…
    with st.sidebar:
        st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        
        # Ø§Ø®ØªÙŠØ§Ø± ÙˆØ¶Ø¹ Ø§Ù„ØªØ´ØºÙŠÙ„
        mode = st.radio(
            "Ø§Ø®ØªØ± ÙˆØ¶Ø¹ Ø§Ù„ØªØ´ØºÙŠÙ„:",
            ["ğŸ“ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª", "ğŸ“Š Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ"]
        )
        
        if mode == "ğŸ“ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª":
            st.subheader("Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª")
            
            # Ø±ÙØ¹ Ù…Ù„Ù Excel
            excel_file = st.file_uploader(
                "Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)",
                type=['xls', 'xlsx']
            )
            
            # Ø±ÙØ¹ Ù…Ù„Ù Word
            word_file = st.file_uploader(
                "Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Word)",
                type=['doc', 'docx']
            )
            
            if excel_file and word_file:
                # Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
                excel_path = f"temp_{excel_file.name}"
                word_path = f"temp_{word_file.name}"
                
                with open(excel_path, "wb") as f:
                    f.write(excel_file.getbuffer())
                
                with open(word_path, "wb") as f:
                    f.write(word_file.getbuffer())
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆÙ„Ø¯
                generator = SPSSv26SyntaxGenerator(excel_path, word_path)
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
                if os.path.exists(excel_path):
                    os.remove(excel_path)
                if os.path.exists(word_path):
                    os.remove(word_path)
                
                return generator
            else:
                return None
        
        else:  # Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ
            st.subheader("Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø«Ø§Ù„
            try:
                # Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø¨ÙŠØ¦Ø© Streamlit Cloud
                excel_path = "Data set 2.xls"
                word_path = "SPSS questioins For data set 2.doc"
                
                if os.path.exists(excel_path) and os.path.exists(word_path):
                    generator = SPSSv26SyntaxGenerator(excel_path, word_path)
                    return generator
                else:
                    st.warning("Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø«Ø§Ù„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©. ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ.")
                    return None
            except:
                st.info("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù„Ù„Ø¨Ø¯Ø¡")
                return None
    
    # Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    st.markdown("---")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆÙ„Ø¯
    generator = main()
    
    if generator:
        if not generator.data.empty:
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ğŸ“Š Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª", len(generator.data.columns))
            
            with col2:
                st.metric("ğŸ“ˆ Ø§Ù„Ø­Ø§Ù„Ø§Øª", len(generator.data))
            
            with col3:
                st.metric("â“ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", len(generator.questions))
            
            # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with st.expander("ğŸ” Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
                st.dataframe(generator.data.head())
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
            with st.expander("ğŸ“‹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙˆØ£Ù†ÙˆØ§Ø¹Ù‡Ø§"):
                var_info = []
                for var_name, var_info_obj in generator.variable_map.items():
                    var_info.append({
                        'Ø§Ù„Ù…ØªØºÙŠØ±': var_name,
                        'Ø§Ù„Ù†ÙˆØ¹': var_info_obj['type'],
                        'Ø§Ù„ØªØ³Ù…ÙŠØ©': var_info_obj['label']
                    })
                st.table(pd.DataFrame(var_info))
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
            with st.expander("ğŸ“ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©"):
                for i, question in enumerate(generator.questions[:10], 1):
                    st.markdown(f"**{i}. {question['text']}**")
                    st.caption(f"Ø§Ù„Ù†ÙˆØ¹: {generator.detect_analysis_type(question['full_text'])}")
            
            # ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS
            st.markdown("---")
            st.subheader("ğŸ”„ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS")
            
            if st.button("ğŸš€ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS", type="primary"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS..."):
                    spss_code = generator.process_all_questions()
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯
                    st.subheader("ğŸ“œ ÙƒÙˆØ¯ SPSS Ø§Ù„Ù…ØªÙˆÙ„Ø¯")
                    st.code(spss_code, language='spss')
                    
                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
                    st.download_button(
                        label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù SPSS (.sps)",
                        data=spss_code,
                        file_name=f"SPSS_{generator.dataset_name}.sps",
                        mime="text/plain"
                    )
        else:
            st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­")
    else:
        # Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ÙŠØ©
        st.markdown("""
        ## ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ Ù…ÙˆÙ„Ø¯ ÙƒÙˆØ¯ SPSS v26
        
        ### ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
        1. **ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ** â† Ø§Ø®ØªØ± "Ø±ÙØ¹ Ù…Ù„ÙØ§Øª"
        2. **Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel** ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ
        3. **Ø§Ø±ÙØ¹ Ù…Ù„Ù Word** ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        4. **Ø§Ù†Ù‚Ø± Ø¹Ù„Ù‰ "ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS"**
        
        ### Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
        - âœ… ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS v26 ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        - ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª Excel
        - ğŸ“ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ù…Ù„ÙØ§Øª Word
        - ğŸ”„ ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        - ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø¬Ø§Ù‡Ø²Ø§Ù‹ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        
        ### Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:
        - Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        - Ø§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
        - Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© (Ø£Ø¹Ù…Ø¯Ø©ØŒ Ø¯ÙˆØ§Ø¦Ø±)
        - Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙØ±Ø¶ÙŠØ§Øª
        - ÙˆØ§Ù„Ø¹Ø¯ÙŠØ¯ ØºÙŠØ±Ù‡Ø§...
        """)

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if __name__ == "__main__":
    main()
