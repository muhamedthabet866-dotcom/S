import streamlit as st
import pandas as pd
import numpy as np
from docx import Document
import tempfile
import os
import re
import base64
from io import BytesIO

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="SPSS Exam Solver Pro",
    page_icon="ğŸ¯",
    layout="wide"
)

st.title("ğŸ¯ SPSS Exam Solver Pro")
st.markdown("### Ø­Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒØ§Ù…Ù„ Ù„Ù„Ø§Ù…ØªØ­Ø§Ù†Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©")

# ===== ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© =====

def extract_questions_from_docx(docx_path):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ù…Ù„Ù Word Ø¨Ø´ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚"""
    questions = []
    try:
        doc = Document(docx_path)
        
        # Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ„ Ø§Ù„ÙÙ‚Ø±Ø§Øª
        paragraphs = [para.text.strip() for para in doc.paragraphs if para.text.strip()]
        full_text = "\n".join(paragraphs)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø±Ù‚Ù…Ø©
        # Ù†Ù…Ø· 1: "1. Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„"
        # Ù†Ù…Ø· 2: "1) Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„"
        # Ù†Ù…Ø· 3: Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ
        patterns = [
            r'(\d+)[\.\)]\s*(.*?)(?=\d+[\.\)]|$)',  # Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø±Ù‚Ù…Ø©
            r'(\d+)\.\s*(.*?)(?=\n\d+\.|\n\n|$)',   # Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø¹ Ù†Ù‚Ø§Ø·
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, full_text, re.DOTALL | re.IGNORECASE)
            for match in matches:
                q_num = match.group(1).strip()
                q_text = match.group(2).strip()
                
                # ØªÙ†Ø¸ÙŠÙ Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„
                q_text = re.sub(r'\s+', ' ', q_text)
                
                if q_text and len(q_text) > 5:
                    questions.append({
                        'number': int(q_num),
                        'text': q_text[:200],  # Ø£ÙˆÙ„ 200 Ø­Ø±Ù ÙÙ‚Ø·
                        'full_text': q_text
                    })
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø£Ø³Ø¦Ù„Ø© Ù…Ø±Ù‚Ù…Ø©ØŒ Ù†Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
        if not questions:
            for para in paragraphs:
                if len(para) > 20:
                    # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ©
                    stats_keywords = ['construct', 'calculate', 'draw', 'test', 'find', 
                                     'Ø¬Ø¯ÙˆÙ„', 'Ø§Ø­Ø³Ø¨', 'Ø§Ø±Ø³Ù…', 'Ø§Ø®ØªØ¨Ø§Ø±', 'Ø£ÙˆØ¬Ø¯']
                    if any(keyword in para.lower() for keyword in stats_keywords):
                        questions.append({
                            'number': len(questions) + 1,
                            'text': para[:150],
                            'full_text': para
                        })
        
        return questions
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Word: {e}")
        return []

def analyze_variables(df):
    """ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª"""
    variable_info = {}
    
    # Ø§Ù„ØªØ¹Ø±ÙŠÙØ§Øª Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
    definitions = {
        'X1': 'Account Balance in $',
        'X2': 'Number of ATM transactions in the month',
        'X3': 'Number of other bank services used',
        'X4': 'Has a debit card (1 = yes, 0 = no)',
        'X5': 'Receive interest on the account (1 = yes, 0 = no)',
        'X6': 'City where banking is done'
    }
    
    for col in df.columns:
        col_str = str(col).strip()
        var_data = df[col].dropna()
        
        info = {
            'name': col_str,
            'original_name': col_str,
            'dtype': str(df[col].dtype),
            'n_unique': len(var_data.unique()),
            'missing': df[col].isna().sum(),
            'total': len(df[col]),
            'unique_values': sorted(var_data.unique().tolist()) if len(var_data.unique()) <= 20 else []
        }
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ
        if df[col].dtype in ['int64', 'float64', 'int32', 'float32']:
            if info['n_unique'] <= 10 and max(var_data.unique()) <= 10:
                info['stat_type'] = 'CATEGORICAL'
            else:
                info['stat_type'] = 'CONTINUOUS'
                info['stats'] = {
                    'mean': float(var_data.mean()),
                    'std': float(var_data.std()),
                    'min': float(var_data.min()),
                    'max': float(var_data.max()),
                    'median': float(var_data.median())
                }
        else:
            info['stat_type'] = 'STRING'
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ¹Ø±ÙŠÙ Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯
        if col_str in definitions:
            info['definition'] = definitions[col_str]
        elif col_str.upper() in definitions:
            info['definition'] = definitions[col_str.upper()]
        
        # ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù‚ÙŠÙ… Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©
        if info['stat_type'] == 'CATEGORICAL' and info['unique_values']:
            info['value_labels'] = {}
            for val in info['unique_values']:
                if col_str == 'X4':  # Debit card
                    if val == 0:
                        info['value_labels'][val] = "No debit card"
                    elif val == 1:
                        info['value_labels'][val] = "Has debit card"
                elif col_str == 'X5':  # Interest
                    if val == 0:
                        info['value_labels'][val] = "No interest"
                    elif val == 1:
                        info['value_labels'][val] = "Receives interest"
                elif col_str == 'X6':  # City
                    city_names = {1: "City A", 2: "City B", 3: "City C", 4: "City D"}
                    info['value_labels'][val] = city_names.get(val, f"City {val}")
                else:
                    info['value_labels'][val] = f"Value {val}"
        
        variable_info[col_str] = info
    
    return variable_info

def detect_analysis_type(question_text):
    """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ù† Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„"""
    text = question_text.lower()
    
    if re.search(r'frequency table|Ø¬Ø¯ÙˆÙ„ ØªÙƒØ±Ø§Ø±ÙŠ|construct.*frequency', text):
        return 'FREQUENCY'
    elif re.search(r'mean.*median.*mode|Ø§Ù„Ù…ØªÙˆØ³Ø·.*Ø§Ù„ÙˆØ³ÙŠØ·|calculate.*mean', text):
        return 'DESCRIPTIVE'
    elif re.search(r'histogram|Ù…Ø¯Ø±Ø¬ ØªÙƒØ±Ø§Ø±ÙŠ|draw.*histogram', text):
        return 'HISTOGRAM'
    elif re.search(r'bar chart|Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¹Ù…ÙˆØ¯ÙŠ|draw.*bar', text):
        return 'BAR_CHART'
    elif re.search(r'pie chart|Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±ÙŠ|draw.*pie', text):
        return 'PIE_CHART'
    elif re.search(r'confidence interval|ÙØªØ±Ø© Ø«Ù‚Ø©|confidence.*95%', text):
        return 'CONFIDENCE_INTERVAL'
    elif re.search(r'skewness|Ø§Ù†Ø­Ø±Ø§Ù|type of skewness', text):
        return 'SKEWNESS_ANALYSIS'
    elif re.search(r'outliers|extremes|Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ©', text):
        return 'OUTLIERS'
    elif re.search(r'empirical rule|chebycheve|Ù‚Ø§Ø¹Ø¯Ø©', text):
        return 'EMPIRICAL_RULE'
    elif re.search(r'for each city|Ù„ÙƒÙ„ Ù…Ø¯ÙŠÙ†Ø©', text):
        return 'BY_GROUP'
    else:
        return 'DESCRIPTIVE'

def extract_variables_from_question(question_text, variable_info):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„"""
    text = question_text.lower()
    found_vars = []
    
    # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„ÙƒÙ„ Ù…ØªØºÙŠØ±
    var_keywords = {
        'X1': ['account balance', 'balance', 'x1', 'Ø±ØµÙŠØ¯'],
        'X2': ['atm transactions', 'transactions', 'x2', 'Ù…Ø¹Ø§Ù…Ù„Ø§Øª'],
        'X3': ['other services', 'services', 'x3', 'Ø®Ø¯Ù…Ø§Øª'],
        'X4': ['debit card', 'debit', 'x4', 'Ø¨Ø·Ø§Ù‚Ø©'],
        'X5': ['interest', 'receive interest', 'x5', 'ÙØ§Ø¦Ø¯Ø©'],
        'X6': ['city', 'banking done', 'x6', 'Ù…Ø¯ÙŠÙ†Ø©']
    }
    
    for var_name, var_info in variable_info.items():
        var_lower = var_name.lower()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
        if var_lower in text:
            found_vars.append(var_name)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        elif var_name in var_keywords:
            for keyword in var_keywords[var_name]:
                if keyword in text:
                    found_vars.append(var_name)
                    break
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ØªØ¹Ø±ÙŠÙ
        if 'definition' in var_info:
            if any(word in var_info['definition'].lower() for word in text.split()):
                found_vars.append(var_name)
    
    return list(set(found_vars))

def generate_spss_syntax_for_dataset(df, questions, variable_info):
    """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS ÙƒØ§Ù…Ù„"""
    
    syntax = f"""* ====================================================
* SPSS SYNTAX - COMPLETE EXAM SOLUTION
* Dataset: Data set 1
* Variables: {len(df.columns)}
* Cases: {len(df)}
* Questions: {len(questions)}
* Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
* ====================================================

* ----------------------------------------------------
* STEP 1: DATA PREPARATION AND VARIABLE DEFINITION
* ----------------------------------------------------

DATASET NAME BankingData WINDOW=FRONT.
DATASET ACTIVATE BankingData.

* Variable definitions based on the exam instructions:"""

    # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
    for var_name, info in variable_info.items():
        if 'definition' in info:
            syntax += f"\nVARIABLE LABELS {var_name} '{info['definition']}'."
        else:
            syntax += f"\nVARIABLE LABELS {var_name} '{var_name}'."
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù‚ÙŠØ§Ø³
        if info['stat_type'] == 'CONTINUOUS':
            syntax += f"\nVARIABLE LEVEL {var_name} (SCALE)."
        elif info['stat_type'] == 'CATEGORICAL':
            syntax += f"\nVARIABLE LEVEL {var_name} (NOMINAL)."
        
        # ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù‚ÙŠÙ… Ù„Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©
        if 'value_labels' in info and info['value_labels']:
            syntax += f"\nVALUE LABELS {var_name}"
            for val, label in info['value_labels'].items():
                syntax += f"\n  {val} '{label}'"
            syntax += "\n."
    
    syntax += "\n\nEXECUTE."
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø´ØªÙ‚Ø©
    syntax += """

* ----------------------------------------------------
* STEP 2: CREATING DERIVED VARIABLES
* ----------------------------------------------------

* Create categorical groups for account balance (for frequency tables)
RECODE X1 (Lowest thru 1000=1) (1000 thru 2000=2) (2000 thru Highest=3) INTO Balance_Group.
VARIABLE LABELS Balance_Group 'Account Balance Groups'.
VALUE LABELS Balance_Group
  1 'Low Balance (<1000)'
  2 'Medium Balance (1000-2000)'
  3 'High Balance (>2000)'.
EXECUTE.

* Create groups for ATM transactions
RECODE X2 (Lowest thru 5=1) (5 thru 10=2) (10 thru Highest=3) INTO ATM_Group.
VARIABLE LABELS ATM_Group 'ATM Transactions Groups'.
VALUE LABELS ATM_Group
  1 'Low Transactions (<5)'
  2 'Medium Transactions (5-10)'
  3 'High Transactions (>10)'.
EXECUTE.

* ----------------------------------------------------
* STEP 3: QUESTION-BY-QUESTION SOLUTION
* ----------------------------------------------------"""
    
    # Ø­Ù„ ÙƒÙ„ Ø³Ø¤Ø§Ù„
    for q in sorted(questions, key=lambda x: x['number']):
        syntax += f"\n\n* QUESTION {q['number']}: {q['text'][:100]}..."
        
        analysis_type = detect_analysis_type(q['full_text'])
        variables = extract_variables_from_question(q['full_text'], variable_info)
        
        if not variables:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¤Ø§Ù„
            if 'account balance' in q['full_text'].lower():
                variables = ['X1']
            elif 'atm' in q['full_text'].lower():
                variables = ['X2']
            elif 'debit card' in q['full_text'].lower():
                variables = ['X4']
            elif 'interest' in q['full_text'].lower():
                variables = ['X5']
            elif 'city' in q['full_text'].lower():
                variables = ['X6']
            else:
                variables = ['X1', 'X2']  # Ø¥ÙØªØ±Ø§Ø¶ÙŠ
        
        syntax += f"\n* Analysis Type: {analysis_type}"
        syntax += f"\n* Variables: {', '.join(variables)}"
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        syntax += generate_analysis_code(analysis_type, variables, q, variable_info)
    
    # ØªØ­Ù„ÙŠÙ„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    syntax += """
    
* ----------------------------------------------------
* STEP 4: ADDITIONAL COMPREHENSIVE ANALYSES
* ----------------------------------------------------

* Comprehensive descriptive statistics
DESCRIPTIVES VARIABLES=X1 X2 X3
  /SAVE
  /STATISTICS=MEAN STDDEV MIN MAX SEMEAN KURTOSIS SKEWNESS.

* Correlation analysis
CORRELATIONS
  /VARIABLES=X1 X2 X3
  /PRINT=TWOTAIL NOSIG
  /MISSING=PAIRWISE.

* Normality tests
EXAMINE VARIABLES=X1 X2
  /PLOT HISTOGRAM NPPLOT
  /COMPARE GROUP
  /STATISTICS DESCRIPTIVES
  /CINTERVAL 95
  /MISSING LISTWISE
  /NOTOTAL.

* ----------------------------------------------------
* STEP 5: SAVE AND CLEANUP
* ----------------------------------------------------

SAVE OUTFILE='Banking_Analysis_Complete.sav'
  /COMPRESSED.
DATASET CLOSE ALL.
EXECUTE.

* ==================== END OF SYNTAX ====================
"""
    
    return syntax

def generate_analysis_code(analysis_type, variables, question, variable_info):
    """ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ ØªØ­Ù„ÙŠÙ„ Ù…Ø­Ø¯Ø¯"""
    code = ""
    
    if analysis_type == 'FREQUENCY':
        code += f"\nFREQUENCIES VARIABLES={' '.join(variables)}"
        code += "\n  /FORMAT=NOTABLE"
        if 'X4' in variables or 'X5' in variables or 'X6' in variables:
            code += "\n  /BARCHART FREQ"
            code += "\n  /PIECHART FREQ"
        code += "\n  /ORDER=ANALYSIS."
    
    elif analysis_type == 'DESCRIPTIVE':
        code += f"\nDESCRIPTIVES VARIABLES={' '.join(variables)}"
        code += "\n  /STATISTICS=MEAN MEDIAN MODE STDDEV VARIANCE RANGE MIN MAX SKEWNESS SESKEW."
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØªØ¹Ù„Ù‚ Ø¨Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
        if 'for each' in question['full_text'].lower() or 'Ù„ÙƒÙ„' in question['full_text'].lower():
            group_var = 'X6' if 'city' in question['full_text'].lower() else 'X4'
            code += f"\n\nSORT CASES BY {group_var}."
            code += f"\nSPLIT FILE LAYERED BY {group_var}."
            code += f"\nDESCRIPTIVES VARIABLES={' '.join([v for v in variables if v != group_var])}"
            code += "\n  /STATISTICS=MEAN STDDEV MIN MAX."
            code += "\nSPLIT FILE OFF."
    
    elif analysis_type == 'HISTOGRAM':
        for var in variables:
            if variable_info[var]['stat_type'] == 'CONTINUOUS':
                code += f"\nGRAPH"
                code += f"\n  /HISTOGRAM={var}"
                code += f"\n  /NORMAL"
                code += f"\n  /TITLE='Histogram of {var}'."
    
    elif analysis_type == 'BAR_CHART':
        if len(variables) >= 2:
            # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù…Ø¬Ù…Ø¹
            code += f"\nGRAPH"
            code += f"\n  /BAR(GROUPED)=MEAN({variables[1]}) BY {variables[0]}"
            code += "\n  /MISSING=REPORT"
            code += f"\n  /TITLE='Bar Chart: {variables[1]} by {variables[0]}'."
        else:
            code += f"\nGRAPH"
            code += f"\n  /BAR(SIMPLE)=COUNT BY {variables[0]}"
            code += "\n  /MISSING=REPORT"
            code += f"\n  /TITLE='Bar Chart of {variables[0]}'."
    
    elif analysis_type == 'PIE_CHART':
        code += f"\nGRAPH"
        code += f"\n  /PIE=PCT BY {variables[0]}"
        code += "\n  /MISSING=REPORT"
        code += f"\n  /TITLE='Pie Chart of {variables[0]}'."
    
    elif analysis_type == 'CONFIDENCE_INTERVAL':
        for var in variables:
            if variable_info[var]['stat_type'] == 'CONTINUOUS':
                code += f"\nEXAMINE VARIABLES={var}"
                code += "\n  /PLOT NONE"
                code += "\n  /STATISTICS DESCRIPTIVES"
                code += "\n  /CINTERVAL 95 99"
                code += "\n  /MISSING LISTWISE."
    
    elif analysis_type == 'OUTLIERS':
        for var in variables:
            if variable_info[var]['stat_type'] == 'CONTINUOUS':
                code += f"\nEXAMINE VARIABLES={var}"
                code += "\n  /PLOT=BOXPLOT"
                code += "\n  /COMPARE VARIABLE"
                code += "\n  /STATISTICS=EXTREME"
                code += "\n  /CINTERVAL 95"
                code += "\n  /MISSING LISTWISE"
                code += "\n  /NOTOTAL."
    
    elif analysis_type == 'SKEWNESS_ANALYSIS':
        for var in variables:
            if variable_info[var]['stat_type'] == 'CONTINUOUS':
                code += f"\nEXAMINE VARIABLES={var}"
                code += "\n  /PLOT=BOXPLOT HISTOGRAM NPPLOT"
                code += "\n  /COMPARE VARIABLE"
                code += "\n  /STATISTICS=SKEWNESS"
                code += "\n  /CINTERVAL 95"
                code += "\n  /MISSING LISTWISE"
                code += "\n  /NOTOTAL."
    
    elif analysis_type == 'EMPIRICAL_RULE':
        for var in variables:
            if variable_info[var]['stat_type'] == 'CONTINUOUS':
                code += f"\n* Empirical Rule analysis for {var}"
                code += f"\nCOMPUTE {var}_Z = ({var} - MEAN({var})) / SD({var})."
                code += f"\nFREQUENCIES VARIABLES={var}_Z"
                code += f"\n  /FORMAT=NOTABLE"
                code += f"\n  /HISTOGRAM NORMAL"
                code += f"\n  /PERCENTILES=2.5 16 50 84 97.5."
    
    else:
        code += f"\nDESCRIPTIVES VARIABLES={' '.join(variables[:3])}"
        code += "\n  /STATISTICS=MEAN STDDEV MIN MAX."
    
    code += "\nEXECUTE."
    return code

# ===== ÙˆØ§Ø¬Ù‡Ø© Streamlit =====

def main():
    # Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.header("ğŸ“ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ø§Ù…ØªØ­Ø§Ù†")
        
        excel_file = st.file_uploader(
            "Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)",
            type=['xls', 'xlsx'],
            help="Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
        )
        
        word_file = st.file_uploader(
            "Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Word)",
            type=['docx', 'doc'],
            help="Ø§Ø±ÙØ¹ Ù…Ù„Ù Word ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"
        )
        
        st.markdown("---")
        
        if st.button("ğŸ¯ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø­Ù„ Ø§Ù„ÙƒØ§Ù…Ù„", type="primary", use_container_width=True):
            st.session_state['generate'] = True
        else:
            st.session_state['generate'] = False
    
    # Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    if not excel_file:
        st.info("ğŸ‘ˆ Ø§Ø¨Ø¯Ø£ Ø¨Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ")
        
        # Ø¹Ø±Ø¶ Ù…Ø«Ø§Ù„
        st.markdown("""
        ### ğŸ“‹ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:
        
        **Ø§Ù„Ø³Ø¤Ø§Ù„ 1:** Construct a frequency table for has a debit card
        ```spss
        FREQUENCIES VARIABLES=X4
          /BARCHART FREQ
          /ORDER=ANALYSIS.
        ```
        
        **Ø§Ù„Ø³Ø¤Ø§Ù„ 4:** Calculate mean, median, mode for account balance
        ```spss
        DESCRIPTIVES VARIABLES=X1
          /STATISTICS=MEAN MEDIAN MODE STDDEV MIN MAX.
        ```
        
        **Ø§Ù„Ø³Ø¤Ø§Ù„ 9:** Bar chart showing average balance for each city
        ```spss
        MEANS TABLES=X1 BY X6
          /CELLS=MEAN COUNT STDDEV.
        
        GRAPH
          /BAR(SIMPLE)=MEAN(X1) BY X6.
        ```
        """)
    
    elif excel_file and st.session_state.get('generate', False):
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
                tmp.write(excel_file.getvalue())
                excel_path = tmp.name
            
            df = pd.read_excel(excel_path)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
            questions = []
            if word_file:
                with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:
                    tmp.write(word_file.getvalue())
                    word_path = tmp.name
                
                questions = extract_questions_from_docx(word_path)
                os.unlink(word_path)
            
            os.unlink(excel_path)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
            variable_info = analyze_variables(df)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} ØµÙ Ùˆ {len(df.columns)} Ø¹Ù…ÙˆØ¯")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª", len(df.columns))
            with col2:
                st.metric("Ø§Ù„Ø­Ø§Ù„Ø§Øª", len(df))
            with col3:
                st.metric("Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", len(questions))
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with st.expander("ğŸ“Š Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
                st.dataframe(df.head(10))
            
            # Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
            with st.expander("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"):
                for var_name, info in variable_info.items():
                    st.markdown(f"**{var_name}**: {info.get('definition', 'No definition')}")
                    st.markdown(f"- Ø§Ù„Ù†ÙˆØ¹: {info['stat_type']}")
                    st.markdown(f"- Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©: {info['n_unique']}")
                    if info['stat_type'] == 'CONTINUOUS' and 'stats' in info:
                        st.markdown(f"- Ø§Ù„Ù…ØªÙˆØ³Ø·: {info['stats']['mean']:.2f}")
                        st.markdown(f"- Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {info['stats']['std']:.2f}")
                    st.markdown("---")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
            with st.expander("ğŸ“ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©"):
                if questions:
                    for q in questions:
                        st.markdown(f"**{q['number']}. {q['text']}**")
                        analysis_type = detect_analysis_type(q['full_text'])
                        variables = extract_variables_from_question(q['full_text'], variable_info)
                        st.caption(f"Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {analysis_type} | Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª: {variables}")
                else:
                    st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ù…Ø±Ù‚Ù…Ø©. Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©...")
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                    questions = [
                        {'number': 1, 'text': 'Construct frequency tables for categorical variables', 'full_text': 'Construct frequency tables'},
                        {'number': 2, 'text': 'Calculate descriptive statistics for account balance', 'full_text': 'Calculate mean median mode'},
                        {'number': 3, 'text': 'Draw histograms for account balance', 'full_text': 'Draw histogram'},
                        {'number': 4, 'text': 'Analyze skewness of distributions', 'full_text': 'Skewness analysis'},
                        {'number': 5, 'text': 'Create bar charts by city', 'full_text': 'Bar chart by city'},
                        {'number': 6, 'text': 'Calculate confidence intervals', 'full_text': 'Confidence intervals'},
                        {'number': 7, 'text': 'Detect outliers', 'full_text': 'Outliers detection'},
                        {'number': 8, 'text': 'Apply empirical rule', 'full_text': 'Empirical rule'}
                    ]
            
            # ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ SPSS
            st.markdown("---")
            st.subheader("ğŸ”„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø­Ù„ Ø§Ù„ÙƒØ§Ù…Ù„")
            
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø­Ù„ SPSS ÙƒØ§Ù…Ù„..."):
                spss_syntax = generate_spss_syntax_for_dataset(df, questions, variable_info)
                
                # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙˆØ¯
                st.subheader("ğŸ“œ ÙƒÙˆØ¯ SPSS Ø§Ù„ÙƒØ§Ù…Ù„")
                st.code(spss_syntax, language='spss')
                
                # Ø²Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„
                st.download_button(
                    label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù SPSS (.sps)",
                    data=spss_syntax,
                    file_name="SPSS_Exam_Solution.sps",
                    mime="text/plain",
                    use_container_width=True
                )
                
                # Ø¹Ø±Ø¶ Ø´Ø±Ø­ Ù„Ù„ÙƒÙˆØ¯
                with st.expander("ğŸ“– Ø´Ø±Ø­ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØªÙˆÙ„Ø¯"):
                    st.markdown("""
                    ### Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø­Ù„ Ø§Ù„Ù…ØªÙˆÙ„Ø¯:
                    
                    1. **Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙˆØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù‚ÙŠÙ…
                    2. **Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø´ØªÙ‚Ø©**: ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ ÙØ¦Ø§Øª
                    3. **Ø­Ù„ ÙƒÙ„ Ø³Ø¤Ø§Ù„**: ÙƒÙˆØ¯ SPSS Ø®Ø§Øµ Ù„ÙƒÙ„ Ø³Ø¤Ø§Ù„
                    4. **ØªØ­Ù„ÙŠÙ„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©**: ØªØ­Ù„ÙŠÙ„Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    5. **Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬**: Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ
                    
                    ### ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ SPSS:
                    1. Ø§ÙØªØ­ SPSS
                    2. Ø£Ø¯Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø£Ùˆ Ø§ÙØªØ­ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    3. Ø§Ù†Ø³Ø® Ø§Ù„ÙƒÙˆØ¯ ÙˆØ§Ù„ØµÙ‚Ù‡ ÙÙŠ Ù†Ø§ÙØ°Ø© Syntax
                    4. Ø§Ø¶ØºØ· Ctrl+A Ø«Ù… Ctrl+R Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯
                    5. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù†Ø§ÙØ°Ø© Output
                    """)
        
        except Exception as e:
            st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if __name__ == "__main__":
    main()
